#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë‹µë³€ ìƒì„± ëª¨ë“ˆ - answer_generator.py (ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ê¸°ëŠ¥ ê°œì„ )
LLMì„ ì´ìš©í•œ ë‹µë³€ ìƒì„±ê³¼ ê²°ê³¼ ì €ì¥ì„ ë‹´ë‹¹
ê²€ìƒ‰ ê²°ê³¼ ê·¸ë£¹í•‘, ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ ë° í’ˆì§ˆ ë©”íŠ¸ë¦­ ë¶„ì„ ê¸°ëŠ¥
ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ê¸°ëŠ¥ ì¶”ê°€ - ì²˜ë°©ëª…/ë³‘ì¦ ì¶”ì¶œ ë¡œì§ ê°œì„ 
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Set
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings("ignore")


class AnswerGenerator:
    def __init__(self, llm_manager=None, save_path: str = "/Users/radi/Projects/langchainDATA/Results/DYBGsearch"):
        """ë‹µë³€ ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.llm_manager = llm_manager
        self.save_path = Path(save_path)
        self.save_path.mkdir(parents=True, exist_ok=True)

        # ê°œì„ ëœ ê´€ë ¨ ê²€ìƒ‰ì–´ ì¶”ì¶œì„ ìœ„í•œ íŒ¨í„´ë“¤
        self.prescription_patterns = [
            r'([ä¸€-é¾¯]{2,8}[æ¹¯æ•£ä¸¸è†å…ƒä¸¹])',  # ì „í˜•ì ì¸ ì²˜ë°© ì ‘ë¯¸ì‚¬
            r'([ä¸€-é¾¯]{2,6}é£®)',            # ~é£® (ì˜ˆ: å››ç‰©é£®)
            r'([ä¸€-é¾¯]{2,6}æ–¹)',            # ~ë°© (ì˜ˆ: é€é™æ–¹)
        ]

        # ê°œì„ : ë³‘ì¦ê³¼ ì¹˜ë£Œë²•ì„ êµ¬ë¶„í•˜ëŠ” íŒ¨í„´ë“¤
        self.symptom_patterns = [
            r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',      # ëª…í™•í•œ ë³‘ì¦ íŒ¨í„´
            r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',       # í—ˆì‹¤ íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4}[ç—›])',         # í†µì¦ íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4}[ç†±å¯’æ¿•ç‡¥])',   # í•œì—´ìŠµì¡° íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4}[è„¹æ»¿æ‚¶])',     # ì°½ë§Œë¯¼ íŒ¨í„´
        ]

        # ì¹˜ë£Œë²• íŒ¨í„´ (ë³‘ì¦ê³¼ êµ¬ë¶„ìš©)
        self.treatment_patterns = [
            r'æ²»([ä¸€-é¾¯]{1,4})',           # æ²»~ íŒ¨í„´
            r'ä¸»æ²»([ä¸€-é¾¯]{2,6})',         # ä¸»æ²»~ íŒ¨í„´
            r'ç™‚([ä¸€-é¾¯]{2,4})',           # ç™‚~ íŒ¨í„´
        ]

        self.herb_patterns = [
            r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒèŒ¯è‹“èŠªæœ®])',  # ì•½ì¬ëª… íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4})',                        # ì¼ë°˜ ì•½ì¬ëª…
        ]

    def generate_answer(self, query: str, search_results: List[Dict]) -> str:
        """ë‹µë³€ ìƒì„± (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ ê°•í™”)"""
        if not self.llm_manager or not self.llm_manager.is_available():
            return "LLMì´ ì—°ê²°ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ë¬¸ì„œ ë²ˆí˜¸ì™€ í•¨ê»˜)
        context_parts = []
        for i, result in enumerate(search_results):
            # ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ëª…í™•íˆ í¬í•¨
            context_parts.append(
                f"[ë¬¸ì„œ {i + 1}]\nì¶œì²˜: {result['metadata'].get('source_file', 'unknown')}\në‚´ìš©: {result['content']}")

        # LLM ê´€ë¦¬ìë¥¼ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ìµœì í™”
        optimized_context_parts = self.llm_manager.optimize_context_for_model(
            context_parts)
        context = '\n\n'.join(optimized_context_parts)

        # ê°•í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = self._get_enhanced_system_prompt()

        # ê°•í™”ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        user_prompt = self._get_enhanced_user_prompt(
            query, context, len(search_results))

        # ë©”ì‹œì§€ êµ¬ì„± ë° ì‘ë‹µ ìƒì„±
        try:
            from langchain_core.messages import SystemMessage, HumanMessage
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
        except ImportError:
            # í´ë°±: ê¸°ë³¸ ë©”ì‹œì§€ í˜•ì‹
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

        return self.llm_manager.generate_response(messages)

    def suggest_related_queries(self, query: str, results: List[Dict], max_suggestions: int = 8) -> Dict[str, List[str]]:
        """ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ê¸°ëŠ¥ (ê°œì„ ëœ ë²„ì „)"""
        # 1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        prescriptions = self._extract_prescriptions_from_results_improved(
            results)

        # 2. ê´€ë ¨ ì¦ìƒ/ë³‘ì¦ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
        symptoms = self._extract_symptoms_from_results_improved(results)

        # 3. ê´€ë ¨ ì•½ì¬ ì¶”ì¶œ
        herbs = self._extract_herbs_from_results(results)

        # 4. ê´€ë ¨ ì´ë¡ /ê°œë… ì¶”ì¶œ
        concepts = self._extract_concepts_from_results(results)

        # 5. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ
        contextual_suggestions = self._get_contextual_suggestions(
            query, results)

        # ê°œì„ ëœ ë¶„ë¥˜ ë¡œì§ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ ì œì•ˆ êµ¬ì„±
        suggestion_categories = [
            ("ğŸ”¥ í•µì‹¬ ì²˜ë°©", [
             p for p in prescriptions if self._is_actual_prescription_improved(p)][:3]),
            ("ğŸ©º ê´€ë ¨ ë³‘ì¦", [s for s in symptoms if self._is_actual_symptom(s)][:3]),
            ("ğŸ’Š ì£¼ìš” ì•½ì¬", [h for h in herbs if self._is_herb_name(h)][:3]),
            ("ğŸ“š ê´€ë ¨ ê°œë…", concepts[:2]),
            ("ğŸ¯ ë§ì¶¤ ì œì•ˆ", contextual_suggestions[:2])
        ]

        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì œì•ˆì‚¬í•­ ìˆ˜ì§‘
        categorized_suggestions = {}
        all_suggestions = []

        for category, items in suggestion_categories:
            if items:
                filtered_items = []
                for item in items:
                    if (item not in all_suggestions and
                        item.lower() != query.lower() and
                            not self._is_too_similar_to_query(query, item)):
                        filtered_items.append(item)
                        all_suggestions.append(item)

                if filtered_items:
                    categorized_suggestions[category] = filtered_items

        return categorized_suggestions

    def _extract_prescriptions_from_results_improved(self, results: List[Dict]) -> List[str]:
        """ê°œì„ ëœ ì²˜ë°©ëª… ì¶”ì¶œ (ë¬¸ì œ 1 í•´ê²°)"""
        prescription_counts = Counter()

        for result in results:
            # 1ìˆœìœ„: ë©”íƒ€ë°ì´í„°ì˜ DP ë ˆë²¨ ì²˜ë°©ëª… (ê°€ì¥ í™•ì‹¤)
            if result['metadata'].get('prescription_name'):
                dp_prescription = result['metadata']['prescription_name']
                # DP ë ˆë²¨ì€ ë†’ì€ ê°€ì¤‘ì¹˜
                prescription_counts[dp_prescription] += 5

            # 2ìˆœìœ„: ë‚´ìš©ì—ì„œ ì²˜ë°© íŒ¨í„´ ë§¤ì¹­ (ê°œì„ ëœ ë¡œì§)
            content = result['content']

            # ê°œì„ ëœ ì²˜ë°© íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
            for pattern in self.prescription_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if len(match) >= 3:  # ìµœì†Œ 3ê¸€ì ì´ìƒ
                        prescription_counts[match] += 2

            # ì¶”ê°€: '~å­' ì²˜ë°© íŒ¨í„´ (DP ë ˆë²¨ì—ì„œ ë‚˜ì˜¤ëŠ” ê²½ìš°ë§Œ)
            # DP ë§ˆì»¤ ê·¼ì²˜ì— ìˆëŠ” '~å­'ë§Œ ì²˜ë°©ìœ¼ë¡œ ì¸ì •
            if 'DP' in content:
                dp_sections = re.split(r'DP', content)
                for section in dp_sections[1:]:  # DP ì´í›„ ì„¹ì…˜ë“¤ë§Œ
                    # DP ì§í›„ 50ì ì´ë‚´ì—ì„œ ~å­ íŒ¨í„´ ì°¾ê¸°
                    first_part = section[:50]
                    zi_matches = re.findall(r'([ä¸€-é¾¯]{2,4}å­)', first_part)
                    for match in zi_matches:
                        # ì²˜ë°© context í™•ì¸ (æ¹¯, æ•£, ä¸¸ ë“±ì´ ê°™ì´ ì–¸ê¸‰ë˜ê±°ë‚˜ ì²˜ë°© ì„¤ëª…ì´ ìˆëŠ” ê²½ìš°)
                        if self._has_prescription_context(section[:200], match):
                            prescription_counts[match] += 3

        # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í•­ëª© ì¶”ì¶œ
        raw_prescriptions = [
            name for name, count in prescription_counts.most_common(20) if count >= 2]

        # ê°œì„ ëœ í•„í„°ë§ ì ìš©
        filtered_prescriptions = []
        for prescription in raw_prescriptions:
            if (self._is_meaningful_prescription_term(prescription) and
                    self._is_actual_prescription_improved(prescription)):
                filtered_prescriptions.append(prescription)

        print(
            f"ğŸ” ì²˜ë°© ì¶”ì¶œ: {len(raw_prescriptions)}ê°œ â†’ í•„í„°ë§ í›„ {len(filtered_prescriptions)}ê°œ")
        return filtered_prescriptions[:6]

    def _has_prescription_context(self, text: str, term: str) -> bool:
        """ì²˜ë°© ì»¨í…ìŠ¤íŠ¸ í™•ì¸ (ì²˜ë°©ì¸ì§€ ë‹¨ìˆœ ì•½ì¬ì¸ì§€ êµ¬ë¶„)"""
        # ì²˜ë°© ê´€ë ¨ í‚¤ì›Œë“œê°€ ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸
        prescription_keywords = [
            'æ²»', 'ä¸»æ²»', 'æ–¹', 'æ¹¯', 'æ•£', 'ä¸¸', 'è†', 'é£®', 'ä¸¹', 'å…ƒ',
            'æœ', 'ç…', 'ç”¨æ³•', 'ë¶„ëŸ‰', 'å³', 'å³çˆ²æœ«', 'å³å‰‰'
        ]

        # term ì£¼ë³€ 50ì ë‚´ì—ì„œ ì²˜ë°© í‚¤ì›Œë“œ ì°¾ê¸°
        term_pos = text.find(term)
        if term_pos == -1:
            return False

        start = max(0, term_pos - 25)
        end = min(len(text), term_pos + len(term) + 25)
        context = text[start:end]

        return any(keyword in context for keyword in prescription_keywords)

    def _is_actual_prescription_improved(self, term: str) -> bool:
        """ê°œì„ ëœ ì‹¤ì œ ì²˜ë°©ëª… íŒë‹¨ (ë¬¸ì œ 1 í•´ê²°)"""
        # 1. ì „í˜•ì ì¸ ì²˜ë°© íŒ¨í„´
        import re
        prescription_patterns = [
            r'.*[æ¹¯æ•£ä¸¸è†å…ƒä¸¹]$',  # ì „í˜•ì ì¸ ì²˜ë°© í˜•íƒœ
            r'.*é£®$',              # ~é£®
            r'.*æ–¹$',              # ~ë°©
        ]

        for pattern in prescription_patterns:
            if re.match(pattern, term):
                return True

        # 2. '~å­' ì²˜ë°©ì˜ ê²½ìš°: ê¸¸ì´ì™€ ì»¨í…ìŠ¤íŠ¸ë¡œ íŒë‹¨
        if term.endswith('å­'):
            # 3ê¸€ì ì´ìƒì´ê³  ì•Œë ¤ì§„ ì²˜ë°©ëª…ì´ë©´ í—ˆìš©
            if len(term) >= 3:
                known_zi_prescriptions = [
                    'é€é™å­', 'ç”˜éœ²å­', 'ç´«é›ªå­', 'è‡³å¯¶å­', 'ç‰›é»ƒå­',
                    'å±€æ–¹å­', 'é‡‘æ«ƒå­', 'åƒé‡‘å­', 'å¤–ç§‘å­'
                ]
                # ì •í™•í•œ ë§¤ì¹­ ë˜ëŠ” íŒ¨í„´ ë§¤ì¹­
                return term in known_zi_prescriptions or len(term) >= 4

        # 3. ì•Œë ¤ì§„ ì²˜ë°©ëª… ë¦¬ìŠ¤íŠ¸ (ì¶”ê°€ í™•ì¸)
        known_prescriptions = [
            'å°å»ºä¸­æ¹¯', 'äºŒé™³æ¹¯', 'å››å›å­æ¹¯', 'å››ç‰©æ¹¯', 'å…­å›å­æ¹¯', 'è£œä¸­ç›Šæ°£æ¹¯',
            'ç•¶æ­¸è£œè¡€æ¹¯', 'çŠ€è§’åœ°é»ƒæ¹¯', 'å®‰ç¥å®šå¿—ä¸¸', 'å¤©ç‹è£œå¿ƒä¸¹', 'æœ±ç ‚å®‰ç¥ä¸¸'
        ]

        return term in known_prescriptions

    def _extract_symptoms_from_results_improved(self, results: List[Dict]) -> List[str]:
        """ê°œì„ ëœ ì¦ìƒ/ë³‘ì¦ ì¶”ì¶œ (ë¬¸ì œ 2 í•´ê²°)"""
        symptom_counts = Counter()
        treatment_extracted_symptoms = Counter()  # ì¹˜ë£Œë²•ì—ì„œ ì¶”ì¶œëœ ë³‘ì¦ë“¤

        for result in results:
            content = result['content']

            # 1. ì§ì ‘ì ì¸ ë³‘ì¦ íŒ¨í„´ ë§¤ì¹­
            for pattern in self.symptom_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if len(match) >= 2:
                        symptom_counts[match] += 2

            # 2. ì¹˜ë£Œë²• íŒ¨í„´ì—ì„œ ë³‘ì¦ ì¶”ì¶œ (ê°œì„ ëœ ë¡œì§)
            for pattern in self.treatment_patterns:
                matches = re.findall(pattern, content)
                for match in matches:
                    if len(match) >= 2 and self._is_valid_symptom_from_treatment(match):
                        # ì¹˜ë£Œë²•ì—ì„œ ì¶”ì¶œëœ ê²ƒì€ ë³„ë„ ì¹´ìš´íŠ¸ (ê°€ì¤‘ì¹˜ ë‚®ìŒ)
                        treatment_extracted_symptoms[match] += 1

            # 3. íŠ¹ì • í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì¶œ (ëª…í™•í•œ ë³‘ì¦ë§Œ)
            clear_symptom_keywords = [
                'é©šæ‚¸', 'å¥å¿˜', 'çœ©æšˆ', 'å¤±çœ ', 'è™›å‹', 'è¡€è™›', 'æ°£è™›', 'é™°è™›', 'é™½è™›',
                'è„¾èƒƒè™›', 'å¿ƒæ‚¸', 'ä¸å¯', 'é ­ç—›', 'è…¹ç—›', 'èƒ¸ç—›', 'ç™²ç™‡', 'ä¸­é¢¨', 'å’³å—½',
                'å“®å–˜', 'æ³„ç€‰', 'ä¾¿ç§˜', 'é»ƒç–¸', 'æ°´è…«', 'æ·‹ç—…', 'å´©æ¼', 'å¸¶ä¸‹'
            ]
            for keyword in clear_symptom_keywords:
                if keyword in content:
                    symptom_counts[keyword] += 3

        # ì¹˜ë£Œë²•ì—ì„œ ì¶”ì¶œëœ ë³‘ì¦ë“¤ì„ ë©”ì¸ ì¹´ìš´íŠ¸ì— ì¶”ê°€ (ë‚®ì€ ê°€ì¤‘ì¹˜)
        for symptom, count in treatment_extracted_symptoms.items():
            # ì´ë¯¸ ì§ì ‘ ì¶”ì¶œëœ ë³‘ì¦ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
            if symptom not in symptom_counts:
                symptom_counts[symptom] += count * 0.5  # ê°€ì¤‘ì¹˜ ì ˆë°˜

        # ë¹ˆë„ìˆœ ì •ë ¬ í›„ í•„í„°ë§ ì ìš©
        raw_symptoms = [symptom for symptom,
                        count in symptom_counts.most_common(15) if count >= 1.5]

        # ê°œì„ ëœ í•„í„°ë§: ì‹¤ì œ ë³‘ì¦ë§Œ ì„ ë³„
        filtered_symptoms = []
        for symptom in raw_symptoms:
            if self._is_actual_symptom(symptom):
                filtered_symptoms.append(symptom)

        print(
            f"ğŸ” ì¦ìƒ ì¶”ì¶œ: {len(raw_symptoms)}ê°œ â†’ í•„í„°ë§ í›„ {len(filtered_symptoms)}ê°œ")
        return filtered_symptoms[:8]

    def _is_valid_symptom_from_treatment(self, term: str) -> bool:
        """ì¹˜ë£Œë²•ì—ì„œ ì¶”ì¶œëœ ìš©ì–´ê°€ ìœ íš¨í•œ ë³‘ì¦ì¸ì§€ íŒë‹¨"""
        # ì¹˜ë£Œ ë™ì‘ì´ ì•„ë‹Œ ì‹¤ì œ ë³‘ì¦ì¸ì§€ í™•ì¸
        invalid_treatment_terms = [
            'ç—…', 'ç—‡', 'ç–¾', 'æ‚£', 'ç™‚', 'ç™’', 'æ„ˆ', 'æ•ˆ', 'é©—', 'æ­¢', 'é™¤', 'å»', 'æ¶ˆ',
            'æ•£', 'è§£', 'ç ´', 'ä¸‹', 'ä¸Š', 'ä¸­', 'å…§', 'å¤–', 'è¡¨', 'è£', 'è™›', 'å¯¦'
        ]

        # ë‹¨ì¼ ê¸€ìì´ê±°ë‚˜ ì¹˜ë£Œ ë™ì‘ ìš©ì–´ë©´ ì œì™¸
        if len(term) == 1 or term in invalid_treatment_terms:
            return False

        # ëª…í™•í•œ ë³‘ì¦ ì ‘ë¯¸ì‚¬ê°€ ìˆìœ¼ë©´ í—ˆìš©
        valid_symptom_suffixes = ['è™›', 'å¯¦', 'ç†±',
                                  'å¯’', 'æ¿•', 'ç‡¥', 'ç—›', 'æ‚¸', 'æšˆ', 'çœ ']
        if any(term.endswith(suffix) for suffix in valid_symptom_suffixes):
            return True

        # ì•Œë ¤ì§„ ë³‘ì¦ëª…ì´ë©´ í—ˆìš©
        known_symptoms = [
            'ê°„í—ˆ', 'ì‹ í—ˆ', 'ê¸°í—ˆ', 'í˜ˆí—ˆ', 'ì‹¬í—ˆ', 'íí—ˆ', 'ë¹„í—ˆ', 'ìœ„í—ˆ',
            'ê°„ì—´', 'ì‹¬ì—´', 'íì—´', 'ìœ„ì—´', 'ê°„ê¸°ìš¸ê²°', 'ì‹¬ê¸°ë¶€ì¡±'
        ]

        return term in known_symptoms or len(term) >= 2

    def _is_actual_symptom(self, term: str) -> bool:
        """ì‹¤ì œ ë³‘ì¦ì¸ì§€ íŒë‹¨ (ê°œì„ ëœ ë¡œì§)"""
        # ì¹˜ë£Œë²• ê´€ë ¨ ìš©ì–´ë“¤ ì œì™¸
        treatment_terms = [
            'æ²»è™›', 'æ²»å¯¦', 'æ²»ç†±', 'æ²»å¯’', 'æ²»ç—›', 'æ²»ç—…', 'æ²»ç™‚', 'ä¸»æ²»',
            'ç™‚è™›', 'ç™‚å¯¦', 'è£œè™›', 'ç€‰å¯¦', 'æ¸…ç†±', 'æº«å¯’', 'æ­¢ç—›',
            'æ²»æ³•', 'ç”¨æ³•', 'æœæ³•', 'ç…æ³•'
        ]

        if term in treatment_terms:
            return False

        # ëª…í™•í•œ ë³‘ì¦ íŒ¨í„´ë“¤
        symptom_patterns = [
            r'.*[è™›å¯¦]$',      # ~í—ˆ, ~ì‹¤
            r'.*[ç—›]$',        # ~í†µ
            r'.*[ç†±å¯’]$',      # ~ì—´, ~í•œ
            r'.*[è­‰ç—…ç—‡]$',    # ~ì¦, ~ë³‘, ~ì¦
            r'.*[æ‚¸æšˆçœ ]$',    # ~ê³„, ~í›ˆ, ~ë©´
        ]

        import re
        for pattern in symptom_patterns:
            if re.match(pattern, term):
                return True

        # ì•Œë ¤ì§„ ëª…í™•í•œ ë³‘ì¦ëª…ë“¤
        clear_symptoms = [
            'é©šæ‚¸', 'å¥å¿˜', 'çœ©æšˆ', 'å¤±çœ ', 'è™›å‹', 'è¡€è™›', 'æ°£è™›', 'é™°è™›', 'é™½è™›',
            'å¿ƒæ‚¸', 'ä¸å¯', 'é ­ç—›', 'è…¹ç—›', 'èƒ¸ç—›', 'ç™²ç™‡', 'ä¸­é¢¨', 'å’³å—½', 'å“®å–˜',
            'æ³„ç€‰', 'ä¾¿ç§˜', 'é»ƒç–¸', 'æ°´è…«', 'å´©æ¼', 'å¸¶ä¸‹', 'éºç²¾', 'é™½ç—¿', 'æ—©æ³„'
        ]

        return term in clear_symptoms

    def _extract_herbs_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì•½ì¬ëª… ì¶”ì¶œ"""
        herb_counts = Counter()

        # ì£¼ìš” ì•½ì¬ ë¦¬ìŠ¤íŠ¸
        major_herbs = [
            'äººåƒ', 'ç•¶æ­¸', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°é»ƒ', 'ç”Ÿåœ°é»ƒ', 'é»ƒèŠª', 'ç™½æœ®',
            'èŒ¯è‹“', 'ç”˜è‰', 'é™³çš®', 'åŠå¤', 'æ³å¯¦', 'åšæœ´', 'æ¡”æ¢—', 'æä»',
            'éº¥é–€å†¬', 'äº”å‘³å­', 'å±±è—¥', 'èŒ¯ç¥', 'é å¿—', 'çŸ³è–è’²', 'æœ±ç ‚', 'é¾éª¨',
            'ç‰¡è £', 'é…¸æ£—ä»', 'æŸå­ä»', 'é˜¿è† ', 'åœ°éª¨çš®', 'çŸ¥æ¯', 'é»ƒæŸ', 'å±±èŒ±è¸'
        ]

        for result in results:
            content = result['content']

            # ì£¼ìš” ì•½ì¬ ê²€ìƒ‰
            for herb in major_herbs:
                if herb in content:
                    # ì²˜ë°© êµ¬ì„±ì— ë‚˜ì˜¤ë©´ ê°€ì¤‘ì¹˜ ë¶€ì—¬
                    if any(keyword in content for keyword in ['å³', 'å³çˆ²æœ«', 'å³å‰‰', 'å³çˆ²']):
                        herb_counts[herb] += 3
                    else:
                        herb_counts[herb] += 1

        # ë¹ˆë„ìˆœ ì •ë ¬ í›„ í•„í„°ë§ ì ìš©
        raw_herbs = [herb for herb,
                     count in herb_counts.most_common(15) if count >= 2]
        filtered_herbs = self._filter_prescription_suggestions(raw_herbs)

        print(f"ğŸ” ì•½ì¬ ì¶”ì¶œ: {len(raw_herbs)}ê°œ â†’ í•„í„°ë§ í›„ {len(filtered_herbs)}ê°œ")
        return filtered_herbs[:8]

    def _extract_concepts_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì´ë¡ /ê°œë… ì¶”ì¶œ"""
        concept_counts = Counter()

        # ì¤‘ì˜í•™ í•µì‹¬ ê°œë…ë“¤
        key_concepts = [
            'é™°é™½', 'äº”è¡Œ', 'è‡Ÿè…‘', 'æ°£è¡€', 'ç¶“çµ¡', 'ç²¾æ°£ç¥', 'å›è‡£ä½ä½¿',
            'å››è±¡', 'å…«ç¶±', 'å…­ç¶“', 'ç‡Ÿè¡›', 'ä¸‰ç„¦', 'å‘½é–€', 'å…ƒæ°£', 'çœŸé™°',
            'ç«ç¥', 'æº«è£œ', 'æ»‹é™°', 'ç†æ°£', 'æ´»è¡€', 'åŒ–ç—°', 'ç¥›æ¿•', 'æ¸…ç†±'
        ]

        for result in results:
            content = result['content']
            bb = result['metadata'].get('BB', '')
            cc = result['metadata'].get('CC', '')

            # ëŒ€ë¶„ë¥˜/ì¤‘ë¶„ë¥˜ì—ì„œ ê°œë… ì¶”ì¶œ
            if bb and bb not in ['', 'unknown']:
                concept_counts[bb] += 2
            if cc and cc not in ['', 'unknown']:
                concept_counts[cc] += 1

            # í•µì‹¬ ê°œë… ë§¤ì¹­
            for concept in key_concepts:
                if concept in content:
                    concept_counts[concept] += 1

        # ë¹ˆë„ìˆœ ì •ë ¬ í›„ í•„í„°ë§ ì ìš©
        raw_concepts = [concept for concept,
                        count in concept_counts.most_common(10) if count >= 2]
        filtered_concepts = self._filter_prescription_suggestions(raw_concepts)

        print(
            f"ğŸ” ê°œë… ì¶”ì¶œ: {len(raw_concepts)}ê°œ â†’ í•„í„°ë§ í›„ {len(filtered_concepts)}ê°œ")
        return filtered_concepts[:5]

    def _get_contextual_suggestions(self, query: str, results: List[Dict]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§ì¶¤ ì œì•ˆ"""
        suggestions = []

        # 1. ì¿¼ë¦¬ ìœ í˜• ë¶„ì„ ê¸°ë°˜ ì œì•ˆ
        if 'è™›' in query:
            suggestions.extend(['è£œç›Š', 'æº«é™½', 'æ»‹é™°', 'ç›Šæ°£'])
        elif 'æ¹¯' in query:
            suggestions.extend(['åŠ æ¸›ë°©', 'ë°°í•©ê¸ˆê¸°', 'ìš©ë²•ìš©ëŸ‰'])
        elif 'ç—…' in query or 'è­‰' in query:
            suggestions.extend(['æ²»ç™‚ë°©ë²•', 'ê°ë³„ì§„ë‹¨', 'ë³‘ë¦¬ê¸°ì „'])
        elif any(herb in query for herb in ['äººåƒ', 'ç•¶æ­¸', 'å·èŠ']):
            suggestions.extend(['ì•½ì„±', 'ê·€ê²½', 'íš¨ëŠ¥ì£¼ì¹˜', 'ë°°í•©'])

        # 2. ê²€ìƒ‰ ê²°ê³¼ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì œì•ˆ
        for result in results:
            source_file = result['metadata'].get('source_file', '')
            bb = result['metadata'].get('BB', '')

            if source_file:
                if 'ë‚´ê²½í¸' in source_file:
                    suggestions.append('ì •ì‹ ìš”ë²•')
                elif 'ì™¸í˜•í¸' in source_file:
                    suggestions.append('ì¹¨êµ¬ì¹˜ë£Œ')
                elif 'ì¡ë³‘í¸' in source_file:
                    suggestions.append('ì„ìƒì‘ìš©')
                elif 'íƒ•ì•¡í¸' in source_file:
                    suggestions.append('ë³¸ì´ˆí•™')

            if bb:
                if bb == 'è¡€':
                    suggestions.extend(['è£œè¡€', 'æ´»è¡€', 'æ­¢è¡€'])
                elif bb == 'æ°£':
                    suggestions.extend(['è£œæ°£', 'ç†æ°£', 'é™æ°£'])
                elif bb == 'ç²¾':
                    suggestions.extend(['è£œè…', 'å›ºç²¾', 'æ»‹é™°'])

        # 3. ë¹ˆë„ ê¸°ë°˜ í•„í„°ë§
        suggestion_counts = Counter(suggestions)
        raw_suggestions = [suggestion for suggestion,
                           count in suggestion_counts.most_common(8)]
        filtered_suggestions = self._filter_prescription_suggestions(
            raw_suggestions)

        print(
            f"ğŸ” ë§¥ë½ ì œì•ˆ: {len(raw_suggestions)}ê°œ â†’ í•„í„°ë§ í›„ {len(filtered_suggestions)}ê°œ")
        return filtered_suggestions[:3]

    def _is_herb_name(self, term: str) -> bool:
        """ì•½ì¬ëª…ì¸ì§€ íŒë‹¨"""
        common_herbs = [
            'äººåƒ', 'ç•¶æ­¸', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°é»ƒ', 'ç”Ÿåœ°é»ƒ', 'é»ƒèŠª', 'ç™½æœ®',
            'èŒ¯è‹“', 'ç”˜è‰', 'é™³çš®', 'åŠå¤', 'æ³å¯¦', 'åšæœ´', 'æ¡”æ¢—', 'æä»',
            'éº¥é–€å†¬', 'äº”å‘³å­', 'å±±è—¥', 'èŒ¯ç¥', 'é å¿—', 'çŸ³è–è’²', 'æœ±ç ‚', 'é¾éª¨',
            'ç‰¡è £', 'é…¸æ£—ä»', 'æŸå­ä»', 'é˜¿è† ', 'åœ°éª¨çš®', 'çŸ¥æ¯', 'é»ƒæŸ', 'å±±èŒ±è¸',
            'æ¡‚æ', 'éº»é»ƒ', 'é™„å­', 'ä¹¾è–‘', 'ç´°è¾›', 'é˜²é¢¨', 'èŠèŠ¥', 'è–„è·',
            'æœ¨é€š', 'è»Šå‰å­', 'æ»‘çŸ³', 'ç¥ç€', 'èµ¤èŒ¯è‹“', 'æ¾¤ç€‰', 'çŒªè‹“'
        ]
        return term in common_herbs

    def _is_meaningful_prescription_term(self, term: str) -> bool:
        """ì²˜ë°©ëª…ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” ìš©ì–´ì¸ì§€ íŒë‹¨"""
        if len(term) < 2:
            return False

        # ì œì™¸í•  íŒ¨í„´ë“¤
        exclude_patterns = [
            r'^å³.*', r'.*çˆ²æœ«$', r'.*å‰‰$', r'.*ç…æœ$', r'.*èª¿ä¸‹$',
            r'^ç©ºå¿ƒ.*', r'^æ¯æœ.*', r'^å„.*', r'.*éŒ¢$', r'.*å…©$',
            r'^ã€Š.*ã€‹$', r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹ì‹­]+[éŒ¢å…©åˆ†]$',
            r'^[æ²»ç™‚ç”¨æœå–å…¥åŠ æˆ–åŠåŒä»¥]$'
        ]

        for pattern in exclude_patterns:
            if re.match(pattern, term):
                return False

        return True

    def _filter_prescription_suggestions(self, suggestions: List[str]) -> List[str]:
        """ë¬´ì˜ë¯¸í•œ ìš©ì–´ë“¤ í•„í„°ë§"""
        filtered = []
        for suggestion in suggestions:
            if self._is_meaningful_prescription_term(suggestion):
                filtered.append(suggestion)
        return filtered

    def _is_too_similar_to_query(self, query: str, suggestion: str) -> bool:
        """ì œì•ˆì–´ê°€ ê²€ìƒ‰ì–´ì™€ ë„ˆë¬´ ìœ ì‚¬í•œì§€ í™•ì¸"""
        if query in suggestion or suggestion in query:
            return True

        common_chars = set(query) & set(suggestion)
        similarity_ratio = len(common_chars) / \
            max(len(set(query)), len(set(suggestion)))
        return similarity_ratio > 0.8

    def display_related_queries(self, query: str, results: List[Dict]):
        """ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í‘œì‹œ"""
        print("\n" + "ğŸ’¡" * 25)
        print("ğŸ” ê´€ë ¨ ê²€ìƒ‰ ì œì•ˆ")
        print("=" * 50)

        categorized_suggestions = self.suggest_related_queries(query, results)

        if not categorized_suggestions:
            print("ğŸ’­ í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ”„ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            return

        suggestion_count = 1

        for category, suggestions in categorized_suggestions.items():
            if suggestions:
                print(f"\n{category}:")
                for suggestion in suggestions:
                    print(f"   {suggestion_count}. {suggestion}")
                    suggestion_count += 1

        print(f"\nğŸ’¡ ì´ {suggestion_count - 1}ê°œì˜ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")
        print("ğŸ”„ ìœ„ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì§ì ‘ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    def get_user_choice_for_suggestions(self, categorized_suggestions: Dict[str, List[str]]) -> Optional[str]:
        """ì‚¬ìš©ìì˜ ê´€ë ¨ ê²€ìƒ‰ì–´ ì„ íƒ ì²˜ë¦¬"""
        if not categorized_suggestions:
            return None

        all_suggestions = []
        for suggestions in categorized_suggestions.values():
            all_suggestions.extend(suggestions)

        if not all_suggestions:
            return None

        while True:
            try:
                choice = input(
                    "\nğŸ¤” ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸ ì…ë ¥ ë˜ëŠ” ìƒˆ ê²€ìƒ‰ì–´ ì…ë ¥, Enterë¡œ ê±´ë„ˆë›°ê¸°): ").strip()

                if not choice:
                    return None

                if choice.isdigit():
                    choice_num = int(choice)
                    if 1 <= choice_num <= len(all_suggestions):
                        selected_query = all_suggestions[choice_num - 1]
                        print(f"âœ… '{selected_query}'ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                        return selected_query
                    else:
                        print(f"âŒ 1~{len(all_suggestions)} ë²”ìœ„ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        continue
                else:
                    print(f"âœ… '{choice}'ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    return choice

            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\nğŸš« ì„ íƒì„ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                return None

    def _get_enhanced_system_prompt(self) -> str:
        """ê°•í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ í•„ìˆ˜í™”)"""
        return """ë‹¹ì‹ ì€ ë™ì˜ë³´ê° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë™ì˜ë³´ê° ì›ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

## ğŸš¨ í•„ìˆ˜ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
1. **ëª¨ë“  ë‚´ìš© ë’¤ì—ëŠ” ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] í˜•íƒœë¡œ ê·¼ê±° ë¬¸í—Œì„ í‘œì‹œ**
2. **ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ í™•ì¸ëœ ë‚´ìš©ì€ [ì¶œì²˜: ë¬¸ì„œX,Y,Z] í˜•íƒœë¡œ ëª¨ë“  ë¬¸ì„œ ë²ˆí˜¸ í‘œì‹œ**
3. **ì²˜ë°© êµ¬ì„±, ìš©ë²• ë“± êµ¬ì²´ì  ì •ë³´ëŠ” ì •í™•í•œ ì¶œì²˜ ë¬¸ì„œ ë²ˆí˜¸ í•„ìˆ˜**
4. **ì¶œì²˜ê°€ ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„± ê¸ˆì§€**

## ğŸ“‹ ë‹µë³€ ì›ì¹™
1. **ì •í™•ì„± ìš°ì„ **: ì œê³µëœ ì›ë¬¸ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€
2. **ì²´ê³„ì  êµ¬ì„±**: ë…¼ë¦¬ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°
3. **ì›ë¬¸ ì¸ìš©**: ì¤‘ìš”í•œ ë‚´ìš©ì€ í•œì ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¸ìš©
4. **ì‹¤ìš©ì„± ê°•ì¡°**: ì„ìƒì ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´ ìš°ì„  ì œì‹œ
5. **í¬ê´„ì  ë¶„ì„**: ì œê³µëœ ë‹¤ìˆ˜ì˜ ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©
6. **ê·¼ê±° ë¬¸í—Œ í‘œì‹œ**: ëª¨ë“  ë‚´ìš©ì— ëŒ€í•´ ê·¼ê±°ê°€ ë˜ëŠ” ì›ë¬¸ ì¶œì²˜ë¥¼ ì£¼ì„ìœ¼ë¡œ ëª…ì‹œ

## ğŸ—ï¸ ë‹µë³€ êµ¬ì¡° (ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì„ íƒì  ì ìš©)

### ğŸ“š ì´ë¡ /ê°œë… ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì •ì˜ì™€ ê°œë…** - ë™ì˜ë³´ê°ì—ì„œì˜ ì •ì˜, ê´€ë ¨ ì´ë¡ ì  ë°°ê²½ [ì¶œì²˜: ë¬¸ì„œX,Y]
**2. ë³‘ë¦¬ê¸°ì „** - ë°œìƒ ì›ì¸ê³¼ ê¸°ì „, ê´€ë ¨ ì¥ë¶€ì™€ ê²½ë½ [ì¶œì²˜: ë¬¸ì„œZ]
**3. ì„ìƒ ì˜ì˜** - ì§„ë‹¨ìƒ ì¤‘ìš”ì„±, ë‹¤ë¥¸ ê°œë…ê³¼ì˜ ê´€ê³„ [ì¶œì²˜: ë¬¸ì„œA,B]

### ğŸ’Š ì²˜ë°© ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì²˜ë°© ê°œìš”** - ì²˜ë°©ëª…ê³¼ ì¶œì „, ì£¼ì¹˜ì¦ê³¼ ì ì‘ì¦ [ì¶œì²˜: ë¬¸ì„œX]
**2. êµ¬ì„±ê³¼ ìš©ë²•** - êµ¬ì„± ì•½ë¬¼ê³¼ ë¶„ëŸ‰, ë³µìš©ë²•ê³¼ ì£¼ì˜ì‚¬í•­ [ì¶œì²˜: ë¬¸ì„œY,Z]
**3. ì„ìƒ ì‘ìš©** - ê°€ê°ë²•ê³¼ ë³€ì¦ ìš”ì , ê´€ë ¨ ì²˜ë°©ë“¤ê³¼ì˜ ë¹„êµ [ì¶œì²˜: ë¬¸ì„œA]

### ğŸ©º ë³‘ì¦ ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ë³‘ì¦ ì •ì˜** - ë³‘ëª…ê³¼ íŠ¹ì§•, ë¶„ë¥˜ì™€ ìœ í˜• [ì¶œì²˜: ë¬¸ì„œX,Y]
**2. ì¦ìƒê³¼ ì§„ë‹¨** - ì£¼ìš” ì¦ìƒê³¼ ë§¥ìƒ, ê°ë³„ì§„ë‹¨ ìš”ì  [ì¶œì²˜: ë¬¸ì„œZ]
**3. ì¹˜ë£Œ ë°©ë²•** - ì£¼ìš” ì¹˜ë£Œ ì²˜ë°©, ì¹˜ë£Œ ì›ì¹™ê³¼ ì˜ˆí›„ [ì¶œì²˜: ë¬¸ì„œA,B]

### ğŸŒ¿ ì•½ë¬¼ ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì•½ì„±ê³¼ ê·€ê²½** - ì„±ë¯¸ì™€ ë…ì„±, ê·€ê²½ê³¼ ì‘ìš© ë¶€ìœ„ [ì¶œì²˜: ë¬¸ì„œX]
**2. íš¨ëŠ¥ê³¼ ì£¼ì¹˜** - ì£¼ìš” íš¨ëŠ¥, ì¹˜ë£Œ ê°€ëŠ¥í•œ ë³‘ì¦ [ì¶œì²˜: ë¬¸ì„œY,Z]
**3. ìš©ë²•ê³¼ ë°°í•©** - ìš©ëŸ‰ê³¼ ë³µìš©ë²•, ë°°í•© ê¸ˆê¸°ì™€ ì£¼ì˜ì‚¬í•­ [ì¶œì²˜: ë¬¸ì„œA]

## ğŸ“š ê·¼ê±° ë¬¸í—Œ í‘œì‹œ ê·œì¹™
- ê° ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ ëì— ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] í˜•íƒœë¡œ í‘œì‹œ
- ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ í™•ì¸ëœ ë‚´ìš©: [ì¶œì²˜: ë¬¸ì„œ1,3,7]
- ì²˜ë°©ëª…, ì•½ì¬ëª…, ìš©ë²• ë“±: ë°˜ë“œì‹œ ì •í™•í•œ ì¶œì²˜ ëª…ì‹œ
- ì˜ˆì‹œ: "é™°è™›ëŠ” ìŒì˜ ë¶€ì¡±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤ [ì¶œì²˜: ë¬¸ì„œ1,3]. ì£¼ìš” ì¦ìƒìœ¼ë¡œëŠ” ë°œì—´ê³¼ ê°€ìŠ´ ë‹µë‹µí•¨ì´ ìˆìŠµë‹ˆë‹¤ [ì¶œì²˜: ë¬¸ì„œ2,5]."

## âœ… ë‹µë³€ ì§€ì¹¨
- **ì¢…í•©ì  ë¶„ì„**: ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ ê·¸ë¦¼ ì œì‹œ
- **í•µì‹¬ë¶€í„° ì œì‹œ**: ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë¨¼ì € ì„¤ëª…
- **ì›ë¬¸ ì¸ìš©**: ì¤‘ìš”í•œ ë¶€ë¶„ì€ "â—‹â—‹æ›°, ..." í˜•íƒœë¡œ í•œì ì¸ìš©
- **ëª…í™•í•œ í•œì í‘œê¸°**: ì „ë¬¸ ìš©ì–´ëŠ” í•œìì™€ í•œê¸€ ë³‘ê¸°
- **ë¬¸ì„œ ë²ˆí˜¸ ì •í™•ì„±**: ì œê³µëœ ë¬¸ì„œ ë²ˆí˜¸ì™€ ì •í™•íˆ ì¼ì¹˜

## âš ï¸ ì£¼ì˜ì‚¬í•­
- **ëª¨ë“  ë¬¸ì¥ì— ì¶œì²˜ í‘œì‹œ í•„ìˆ˜** - ì¶œì²˜ ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„± ê¸ˆì§€
- ì œê³µëœ ìë£Œì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€
- í˜„ëŒ€ ì˜í•™ì  í•´ì„ì´ë‚˜ ê°œì¸ì  ê²¬í•´ ì²¨ê°€ ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì†”ì§íˆ ì¸ì •í•˜ë˜ ì¶œì²˜ëŠ” ë°˜ë“œì‹œ í‘œì‹œ

ì´ëŸ¬í•œ ì§€ì¹¨ì— ë”°ë¼ ë™ì˜ë³´ê°ì˜ ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ëª¨ë“  ë‚´ìš©ì˜ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""

    def _get_enhanced_user_prompt(self, query: str, context: str, result_count: int) -> str:
        """ê°•í™”ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸"""
        return f"""ë‹¤ìŒ ë™ì˜ë³´ê° ì›ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

=== ê²€ìƒ‰ëœ ë™ì˜ë³´ê° ì›ë¬¸ ({result_count}ê°œ ë¬¸ì„œ) ===
{context}

=== ì§ˆë¬¸ ===
{query}

=== ë‹µë³€ ìš”ì²­ ===
ğŸš¨ **í•„ìˆ˜ ìš”êµ¬ì‚¬í•­**:
- **ëª¨ë“  ë‚´ìš© ë’¤ì— ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] ë˜ëŠ” [ì¶œì²˜: ë¬¸ì„œX,Y,Z] í˜•íƒœë¡œ ê·¼ê±° ë¬¸í—Œì„ í‘œì‹œí•˜ì„¸ìš”**
- **ì¶œì²˜ê°€ ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”**
- **ì²˜ë°© êµ¬ì„±, ì¦ìƒ, ì¹˜ë£Œë²• ë“± ëª¨ë“  êµ¬ì²´ì  ì •ë³´ì—ëŠ” ì •í™•í•œ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ í‘œì‹œí•˜ì„¸ìš”**

ìœ„ì˜ ê°•í™”ëœ ë‹µë³€ ì§€ì¹¨ì— ë”°ë¼ ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ë˜, ë°˜ë“œì‹œ ëª¨ë“  ë‚´ìš©ì— ëŒ€í•´ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”. ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì™„ì „í•˜ê³  ê· í˜•ì¡íŒ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€...
    def show_search_metrics(self, query: str, results: List[Dict]):
        """ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
        if not results:
            print("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ë©”íŠ¸ë¦­ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'ì²˜ë°© ì •ë³´': len([r for r in results if r['metadata'].get('type') == 'prescription']),
            'ì´ë¡  ë‚´ìš©': len([r for r in results if r['metadata'].get('BB')]),
            'ì¶œì²˜ ë‹¤ì–‘ì„±': len(set(r['metadata'].get('source_file', 'unknown') for r in results)),
            'í‰ê·  ê´€ë ¨ë„': sum(r.get('score', 0) for r in results) / len(results)
        }

        # ê³ ê¸‰ ë©”íŠ¸ë¦­ ê³„ì‚°
        advanced_metrics = self._calculate_advanced_metrics(query, results)

        print(f"\nğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ ('{query}' ê²€ìƒ‰ ê²°ê³¼):")
        print("=" * 50)

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ í‘œì‹œ
        print("ğŸ” ê¸°ë³¸ ì§€í‘œ:")
        for metric, value in metrics.items():
            if metric == 'í‰ê·  ê´€ë ¨ë„':
                print(f"   â€¢ {metric}: {value:.3f}")
            else:
                print(f"   â€¢ {metric}: {value}ê°œ")

        print()

        # ê³ ê¸‰ ë©”íŠ¸ë¦­ í‘œì‹œ
        print("ğŸ“ˆ ê³ ê¸‰ ë¶„ì„:")
        for metric, value in advanced_metrics.items():
            if isinstance(value, float):
                print(f"   â€¢ {metric}: {value:.3f}")
            elif isinstance(value, list):
                print(f"   â€¢ {metric}: {', '.join(map(str, value))}")
            else:
                print(f"   â€¢ {metric}: {value}")

        # í’ˆì§ˆ ë“±ê¸‰ í‰ê°€
        quality_grade = self._evaluate_search_quality(
            metrics, advanced_metrics)
        print(
            f"\nğŸ¯ ê²€ìƒ‰ í’ˆì§ˆ ë“±ê¸‰: {quality_grade['grade']} ({quality_grade['description']})")

        # ê°œì„  ì œì•ˆ
        suggestions = self._get_improvement_suggestions(
            query, metrics, advanced_metrics)
        if suggestions:
            print(f"\nğŸ’¡ ê²€ìƒ‰ ê°œì„  ì œì•ˆ:")
            for suggestion in suggestions:
                print(f"   â€¢ {suggestion}")

    def _calculate_advanced_metrics(self, query: str, results: List[Dict]) -> Dict:
        """ê³ ê¸‰ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        advanced_metrics = {}

        # 1. ë‚´ìš© íƒ€ì…ë³„ ë¶„í¬
        content_types = defaultdict(int)
        for result in results:
            metadata = result['metadata']
            if metadata.get('type') == 'prescription':
                content_types['ì²˜ë°©'] += 1
            elif metadata.get('BB'):
                content_types['ì´ë¡ '] += 1
            elif any(kw in result['content'] for kw in ['è­‰', 'ç—…', 'ç—‡']):
                content_types['ë³‘ì¦'] += 1
            elif any(kw in result['content'] for kw in ['å‘³', 'æ€§', 'æ­¸ç¶“']):
                content_types['ì•½ë¬¼'] += 1
            else:
                content_types['ê¸°íƒ€'] += 1

        advanced_metrics['ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±'] = len(content_types)

        # 2. ê´€ë ¨ë„ ì ìˆ˜ ë¶„í¬
        scores = [r.get('score', 0) for r in results]
        if scores:
            advanced_metrics['ìµœê³  ê´€ë ¨ë„'] = max(scores)
            advanced_metrics['ìµœì € ê´€ë ¨ë„'] = min(scores)
            advanced_metrics['ê´€ë ¨ë„ í¸ì°¨'] = max(scores) - min(scores)

            # ê´€ë ¨ë„ êµ¬ê°„ë³„ ë¶„í¬
            high_quality = len([s for s in scores if s >= 3.0])
            medium_quality = len([s for s in scores if 1.5 <= s < 3.0])
            low_quality = len([s for s in scores if s < 1.5])

            advanced_metrics['ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)'] = f"{high_quality}ê°œ ({high_quality / len(results) * 100:.1f}%)"
            advanced_metrics['ì¤‘í’ˆì§ˆ ê²°ê³¼ (1.5-3.0)'] = f"{medium_quality}ê°œ ({medium_quality / len(results) * 100:.1f}%)"
            advanced_metrics['ì €í’ˆì§ˆ ê²°ê³¼ (<1.5)'] = f"{low_quality}ê°œ ({low_quality / len(results) * 100:.1f}%)"

        # 3. ì¶œì²˜ íŒŒì¼ë³„ ë¶„í¬
        source_distribution = defaultdict(int)
        for result in results:
            source_file = result['metadata'].get('source_file', 'unknown')
            source_distribution[source_file] += 1

        # ê°€ì¥ ë§ì´ í™œìš©ëœ ì¶œì²˜ ìƒìœ„ 3ê°œ
        top_sources = sorted(source_distribution.items(),
                             key=lambda x: x[1], reverse=True)[:3]
        advanced_metrics['ì£¼ìš” ì¶œì²˜'] = [
            f"{source}({count}ê°œ)" for source, count in top_sources]

        # 4. ëŒ€ë¶„ë¥˜(BB) ë‹¤ì–‘ì„±
        bb_categories = set()
        for result in results:
            bb = result['metadata'].get('BB')
            if bb:
                bb_categories.add(bb)

        advanced_metrics['ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„±'] = len(bb_categories)
        if bb_categories:
            advanced_metrics['í¬í•¨ëœ ëŒ€ë¶„ë¥˜'] = list(bb_categories)

        # 5. ì¤‘ë¶„ë¥˜(CC) ë‹¤ì–‘ì„±
        cc_categories = set()
        for result in results:
            cc = result['metadata'].get('CC')
            if cc:
                cc_categories.add(cc)

        advanced_metrics['ì¤‘ë¶„ë¥˜ ë‹¤ì–‘ì„±'] = len(cc_categories)

        # 6. ì²˜ë°©ëª… ë‹¤ì–‘ì„± (ì²˜ë°© ê´€ë ¨ ê²€ìƒ‰ì¸ ê²½ìš°)
        prescription_names = set()
        for result in results:
            prescription_name = result['metadata'].get('prescription_name')
            if prescription_name:
                prescription_names.add(prescription_name)

        if prescription_names:
            advanced_metrics['ì²˜ë°© ë‹¤ì–‘ì„±'] = len(prescription_names)
            if len(prescription_names) <= 5:
                advanced_metrics['í¬í•¨ëœ ì²˜ë°©'] = list(prescription_names)

        # 7. ë‚´ìš© ê¸¸ì´ ë¶„ì„
        content_lengths = [len(result['content']) for result in results]
        if content_lengths:
            advanced_metrics['í‰ê·  ë‚´ìš© ê¸¸ì´'] = sum(
                content_lengths) / len(content_lengths)
            advanced_metrics['ë‚´ìš© ê¸¸ì´ ë²”ìœ„'] = f"{min(content_lengths)}~{max(content_lengths)}ì"

        # 8. í‚¤ì›Œë“œ ë§¤ì¹­ í’ˆì§ˆ
        direct_matches = len([r for r in results if query in r['content']])
        advanced_metrics['ì§ì ‘ ë§¤ì¹­ë¥ '] = f"{direct_matches}ê°œ ({direct_matches / len(results) * 100:.1f}%)"

        return advanced_metrics

    def _evaluate_search_quality(self, basic_metrics: Dict, advanced_metrics: Dict) -> Dict:
        """ê²€ìƒ‰ í’ˆì§ˆ ë“±ê¸‰ í‰ê°€"""
        score = 0
        max_score = 100

        # ê¸°ë³¸ ì ìˆ˜ (40ì  ë§Œì )
        # ì²˜ë°© ì •ë³´ ë¹„ìœ¨ (10ì )
        prescription_ratio = basic_metrics['ì²˜ë°© ì •ë³´'] / \
            len(basic_metrics) if len(basic_metrics) > 0 else 0
        score += min(prescription_ratio * 20, 10)

        # ì¶œì²˜ ë‹¤ì–‘ì„± (10ì )
        source_diversity = basic_metrics['ì¶œì²˜ ë‹¤ì–‘ì„±']
        score += min(source_diversity * 2, 10)

        # í‰ê·  ê´€ë ¨ë„ (10ì )
        avg_relevance = basic_metrics['í‰ê·  ê´€ë ¨ë„']
        score += min(avg_relevance * 3, 10)

        # ì´ë¡  ë‚´ìš© í¬í•¨ (10ì )
        theory_ratio = basic_metrics['ì´ë¡  ë‚´ìš©'] / \
            len(basic_metrics) if len(basic_metrics) > 0 else 0
        score += min(theory_ratio * 20, 10)

        # ê³ ê¸‰ ì ìˆ˜ (60ì  ë§Œì )
        # ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„± (15ì )
        content_type_diversity = advanced_metrics.get('ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±', 0)
        score += min(content_type_diversity * 3, 15)

        # ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„± (15ì )
        bb_diversity = advanced_metrics.get('ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„±', 0)
        score += min(bb_diversity * 2.5, 15)

        # ê³ í’ˆì§ˆ ê²°ê³¼ ë¹„ìœ¨ (15ì )
        high_quality_text = advanced_metrics.get('ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)', '0ê°œ (0.0%)')
        high_quality_percent = float(
            high_quality_text.split('(')[1].split('%')[0])
        score += min(high_quality_percent * 0.15, 15)

        # ì§ì ‘ ë§¤ì¹­ë¥  (15ì )
        direct_match_text = advanced_metrics.get('ì§ì ‘ ë§¤ì¹­ë¥ ', '0ê°œ (0.0%)')
        direct_match_percent = float(
            direct_match_text.split('(')[1].split('%')[0])
        score += min(direct_match_percent * 0.15, 15)

        # ë“±ê¸‰ ê²°ì •
        if score >= 85:
            grade = "S (ìµœìš°ìˆ˜)"
            description = "ë§¤ìš° í¬ê´„ì ì´ê³  ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼"
        elif score >= 70:
            grade = "A (ìš°ìˆ˜)"
            description = "ê· í˜•ì¡íŒ ì¢‹ì€ ê²€ìƒ‰ ê²°ê³¼"
        elif score >= 55:
            grade = "B (ì–‘í˜¸)"
            description = "ì ì ˆí•œ ê²€ìƒ‰ ê²°ê³¼, ì¼ë¶€ ê°œì„  ì—¬ì§€"
        elif score >= 40:
            grade = "C (ë³´í†µ)"
            description = "ê¸°ë³¸ì ì¸ ê²€ìƒ‰ ê²°ê³¼, ê°œì„  í•„ìš”"
        else:
            grade = "D (ë¯¸í¡)"
            description = "ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê°œì„  í•„ìš”"

        return {
            'grade': grade,
            'score': score,
            'description': description
        }

    def _get_improvement_suggestions(self, query: str, basic_metrics: Dict, advanced_metrics: Dict) -> List[str]:
        """ê²€ìƒ‰ ê°œì„  ì œì•ˆ"""
        suggestions = []

        # ì¶œì²˜ ë‹¤ì–‘ì„± ë¶€ì¡±
        if basic_metrics['ì¶œì²˜ ë‹¤ì–‘ì„±'] < 3:
            suggestions.append("ê²€ìƒ‰ì–´ë¥¼ ë” ì¼ë°˜ì ì¸ ìš©ì–´ë¡œ ë°”ê¿”ë³´ì„¸ìš” (ì¶œì²˜ ë‹¤ì–‘ì„± í–¥ìƒ)")

        # í‰ê·  ê´€ë ¨ë„ ë‚®ìŒ
        if basic_metrics['í‰ê·  ê´€ë ¨ë„'] < 2.0:
            suggestions.append("ë” êµ¬ì²´ì ì¸ í•œì ìš©ì–´ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš” (ê´€ë ¨ë„ í–¥ìƒ)")

        # ì²˜ë°© ì •ë³´ ë¶€ì¡± (ì²˜ë°© ê´€ë ¨ ê²€ìƒ‰ì¸ ê²½ìš°)
        if ('æ¹¯' in query or 'æ•£' in query or 'ä¸¸' in query) and basic_metrics['ì²˜ë°© ì •ë³´'] < 5:
            suggestions.append("ì²˜ë°©ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ 'ì²˜ë°©', 'ì¹˜ë£Œ' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”")

        # ì§ì ‘ ë§¤ì¹­ë¥  ë‚®ìŒ
        direct_match_text = advanced_metrics.get('ì§ì ‘ ë§¤ì¹­ë¥ ', '0ê°œ (0.0%)')
        direct_match_percent = float(
            direct_match_text.split('(')[1].split('%')[0])
        if direct_match_percent < 30:
            suggestions.append("ë™ì˜ì–´ë‚˜ ê´€ë ¨ ìš©ì–´ë¥¼ í•¨ê»˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”")

        # ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„± ë¶€ì¡±
        if advanced_metrics.get('ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±', 0) < 3:
            suggestions.append("ë” í¬ê´„ì ì¸ ê²€ìƒ‰ì„ ìœ„í•´ ê´€ë ¨ ì¦ìƒì´ë‚˜ ì´ë¡ ë„ í•¨ê»˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”")

        # ê³ í’ˆì§ˆ ê²°ê³¼ ë¹„ìœ¨ ë‚®ìŒ
        high_quality_text = advanced_metrics.get('ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)', '0ê°œ (0.0%)')
        high_quality_percent = float(
            high_quality_text.split('(')[1].split('%')[0])
        if high_quality_percent < 20:
            suggestions.append("ê²€ìƒ‰ì–´ì˜ ì •í™•í•œ í•œì í‘œê¸°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")

        return suggestions

    def save_search_results(self, query: str, results: List[Dict], answer: str):
        """ê²€ìƒ‰ ê²°ê³¼ ìë™ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        search_dir = self.save_path / f"{query}_{timestamp}"
        search_dir.mkdir(exist_ok=True)

        result_file = search_dir / f"{query}_{timestamp}.txt"

        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"ê²€ìƒ‰ì–´: {query}\n")
            f.write(f"ê²€ìƒ‰ ì‹œê°„: {timestamp}\n")
            f.write(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}ê°œ\n")
            f.write("=" * 50 + "\n\n")

            f.write("ğŸ¤– AI ë‹µë³€ (ê·¼ê±° ë¬¸í—Œ í¬í•¨):\n")
            f.write(answer + "\n\n")
            f.write("=" * 50 + "\n\n")

            # ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆë„ ì €ì¥
            categorized_suggestions = self.suggest_related_queries(
                query, results)
            if categorized_suggestions:
                f.write("ğŸ’¡ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ:\n")
                suggestion_count = 1
                for category, suggestions in categorized_suggestions.items():
                    if suggestions:
                        f.write(f"\n{category}:\n")
                        for suggestion in suggestions:
                            f.write(f"   {suggestion_count}. {suggestion}\n")
                            suggestion_count += 1
                f.write("\n" + "=" * 50 + "\n\n")

            # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ë„ ì €ì¥
            f.write("ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­:\n")
            basic_metrics = {
                'ì²˜ë°© ì •ë³´': len([r for r in results if r['metadata'].get('type') == 'prescription']),
                'ì´ë¡  ë‚´ìš©': len([r for r in results if r['metadata'].get('BB')]),
                'ì¶œì²˜ ë‹¤ì–‘ì„±': len(set(r['metadata'].get('source_file', 'unknown') for r in results)),
                'í‰ê·  ê´€ë ¨ë„': sum(r.get('score', 0) for r in results) / len(results)
            }

            for metric, value in basic_metrics.items():
                if metric == 'í‰ê·  ê´€ë ¨ë„':
                    f.write(f"   â€¢ {metric}: {value:.3f}\n")
                else:
                    f.write(f"   â€¢ {metric}: {value}ê°œ\n")

            f.write("\n" + "=" * 50 + "\n\n")

            f.write("ğŸ“š ê²€ìƒ‰ëœ ì›ë¬¸:\n\n")
            for i, result in enumerate(results):
                f.write(f"[ë¬¸ì„œ {i + 1}] (ìœ ì‚¬ë„: {result['score']:.3f})\n")
                f.write(f"ì¶œì²˜: {result['metadata']['source_file']}\n")

                if result['metadata'].get('BB'):
                    f.write(f"ëŒ€ë¶„ë¥˜: {result['metadata']['BB']}\n")
                if result['metadata'].get('CC'):
                    f.write(f"ì¤‘ë¶„ë¥˜: {result['metadata']['CC']}\n")
                if result['metadata'].get('prescription_name'):
                    f.write(
                        f"ì²˜ë°©ëª…: {result['metadata']['prescription_name']}\n")

                f.write(f"ë‚´ìš©:\n{result['content']}\n")
                f.write("-" * 30 + "\n\n")

        print(f"ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ìë™ ì €ì¥ ì™„ë£Œ: {result_file}")

    def display_search_results(self, query: str, results: List[Dict], answer: str,
                               show_details: bool = False, show_related_queries: bool = True) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í¬í•¨)"""
        print("\n" + "=" * 50)

        # AI ë‹µë³€ í‘œì‹œ
        if self.llm_manager and self.llm_manager.is_available():
            print("ğŸ¤– AI ë‹µë³€ (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ í¬í•¨):")
            print("-" * 30)
            print(answer)
        else:
            print("âš ï¸ AI ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")

        # ìë™ ì €ì¥ ì‹¤í–‰
        self.save_search_results(query, results, answer)

        print("=" * 50)

        # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        self._display_categorized_results(results)

        # ğŸ†• ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í‘œì‹œ
        if show_related_queries:
            self.display_related_queries(query, results)

        # ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸° ì˜µì…˜
        if not show_details:
            show_details_input = input(
                "\nğŸ“‹ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ì²´ ë‚´ìš©ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            show_details = show_details_input in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']

        if show_details:
            self._display_detailed_results(results)

        return show_details

    def _categorize_results(self, results: List[Dict]) -> Dict[str, List[Dict]]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = defaultdict(list)

        for result in results:
            metadata = result['metadata']

            # ì¹´í…Œê³ ë¦¬ ê²°ì • ë¡œì§
            category_info = self._determine_category(result)

            # ê° ê²°ê³¼ì— í‘œì‹œìš© ì œëª©ê³¼ ìš”ì•½ ì¶”ê°€
            enhanced_result = {
                **result,
                'title': category_info['title'],
                'summary': category_info['summary'],
                'category_icon': category_info['icon']
            }

            categories[category_info['category']].append(enhanced_result)

        return dict(categories)

    def _determine_category(self, result: Dict) -> Dict[str, str]:
        """ê°œë³„ ê²°ê³¼ì˜ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        metadata = result['metadata']
        content = result['content']

        # ì²˜ë°© ì¹´í…Œê³ ë¦¬
        if (metadata.get('type') == 'prescription' or
            metadata.get('prescription_name') or
                any(keyword in content for keyword in ['æ¹¯', 'æ•£', 'ä¸¸', 'è†', 'DP'])):

            prescription_name = metadata.get('prescription_name', 'ì²˜ë°©')
            if not prescription_name or prescription_name == 'ì²˜ë°©':
                # ë‚´ìš©ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ ì‹œë„
                import re
                matches = re.findall(r'([ä¸€-é¾¯]{2,6}[æ¹¯æ•£ä¸¸è†])', content)
                prescription_name = matches[0] if matches else 'ì²˜ë°©'

            return {
                'category': 'ğŸ’Š ì²˜ë°© ë° ì¹˜ë£Œë²•',
                'title': prescription_name,
                'summary': content[:100] + "..." if len(content) > 100 else content,
                'icon': 'ğŸ’Š'
            }

        # ì´ë¡ /ê°œë… ì¹´í…Œê³ ë¦¬
        elif (metadata.get('BB') in ['èº«å½¢', 'ç²¾', 'æ°£', 'ç¥'] or
              any(keyword in content for keyword in ['ç¶“æ›°', 'éˆæ¨æ›°', 'å…§ç¶“æ›°', 'ç†è«–', 'ì›ë¦¬'])):

            title = metadata.get('CC', metadata.get('BB', 'ì´ë¡ '))
            return {
                'category': 'ğŸ“š ì´ë¡  ë° ê°œë…',
                'title': title,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ“š'
            }

        # ë³‘ì¦/ì¦ìƒ ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['è­‰', 'ç—…', 'ç—‡', 'ç—›', 'è™›', 'å¯¦', 'å¯’', 'ç†±']):

            # ë³‘ì¦ëª… ì¶”ì¶œ
            import re
            symptom_patterns = [
                r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',
                r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',
                r'([ä¸€-é¾¯]{2,4}[ç—›])'
            ]

            symptom_name = 'ë³‘ì¦'
            for pattern in symptom_patterns:
                matches = re.findall(pattern, content)
                if matches:
                    symptom_name = matches[0]
                    break

            return {
                'category': 'ğŸ©º ë³‘ì¦ ë° ì¦ìƒ',
                'title': symptom_name,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ©º'
            }

        # ì•½ë¬¼/ë³¸ì´ˆ ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['å‘³', 'æ€§', 'æ­¸ç¶“', 'æ•ˆèƒ½', 'ä¸»æ²»', 'ìš©ë²•']):

            # ì•½ë¬¼ëª… ì¶”ì¶œ
            import re
            herb_patterns = [
                r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒ])',
                r'([ä¸€-é¾¯]{2,4})'
            ]

            herb_name = 'ì•½ë¬¼'
            for pattern in herb_patterns:
                matches = re.findall(pattern, content[:50])  # ì•ë¶€ë¶„ì—ì„œë§Œ ì°¾ê¸°
                if matches:
                    herb_name = matches[0]
                    break

            return {
                'category': 'ğŸŒ¿ ì•½ë¬¼ ë° ë³¸ì´ˆ',
                'title': herb_name,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸŒ¿'
            }

        # ì§„ë‹¨/ë§¥ë²• ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['è„ˆ', 'è¨º', 'è¾¨', 'å¯Ÿ', 'å€™']):

            return {
                'category': 'ğŸ” ì§„ë‹¨ ë° ë§¥ë²•',
                'title': metadata.get('CC', 'ì§„ë‹¨ë²•'),
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ”'
            }

        # ê¸°íƒ€ ì¼ë°˜ ë‚´ìš©
        else:
            title = metadata.get('CC', metadata.get('BB', 'ì¼ë°˜'))
            return {
                'category': 'ğŸ“– ê¸°íƒ€ ë‚´ìš©',
                'title': title,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ“–'
            }

    def _display_categorized_results(self, results: List[Dict]):
        """ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í•‘ëœ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
        categories = self._categorize_results(results)

        print(f"\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ({len(results)}ê°œ ë¬¸ì„œ)")
        print("=" * 60)

        # ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ ìˆœì„œ ì •ì˜
        category_order = [
            'ğŸ’Š ì²˜ë°© ë° ì¹˜ë£Œë²•',
            'ğŸ©º ë³‘ì¦ ë° ì¦ìƒ',
            'ğŸ“š ì´ë¡  ë° ê°œë…',
            'ğŸŒ¿ ì•½ë¬¼ ë° ë³¸ì´ˆ',
            'ğŸ” ì§„ë‹¨ ë° ë§¥ë²•',
            'ğŸ“– ê¸°íƒ€ ë‚´ìš©'
        ]

        total_shown = 0

        for category in category_order:
            items = categories.get(category, [])
            if not items:
                continue

            print(f"\n{category} ({len(items)}ê°œ)")
            print("-" * 40)

            # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ 5ê°œê¹Œì§€ í‘œì‹œ
            display_count = min(5, len(items))
            for i, item in enumerate(items[:display_count]):
                score = item.get('score', 0)
                title = item['title']
                summary = item['summary']

                print(f"   {i + 1}. {title}")
                print(f"      ê´€ë ¨ë„: {score:.3f}")
                print(f"      ìš”ì•½: {summary}")

                if i < display_count - 1:
                    print()

            if len(items) > display_count:
                print(f"      ... ì™¸ {len(items) - display_count}ê°œ ë”")

            total_shown += display_count

        # ì „ì²´ í†µê³„
        print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for category in category_order:
            count = len(categories.get(category, []))
            if count > 0:
                percentage = (count / len(results)) * 100
                print(f"   {category}: {count}ê°œ ({percentage:.1f}%)")

        print(f"\nğŸ’¡ ìƒìœ„ {total_shown}ê°œ ê²°ê³¼ë¥¼ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")

    def _display_detailed_results(self, results: List[Dict]):
        """ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
        print("\n" + "=" * 60)
        print("ğŸ“š ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë‚´ìš©:")

        for i, result in enumerate(results):
            print(f"\n[ë¬¸ì„œ {i + 1}] (ìœ ì‚¬ë„: {result['score']:.3f})")
            print(f"ì¶œì²˜: {result['metadata']['source_file']}")

            if result['metadata'].get('BB'):
                print(f"ëŒ€ë¶„ë¥˜: {result['metadata']['BB']}")
            if result['metadata'].get('CC'):
                print(f"ì¤‘ë¶„ë¥˜: {result['metadata']['CC']}")
            if result['metadata'].get('prescription_name'):
                print(f"ì²˜ë°©ëª…: {result['metadata']['prescription_name']}")

            # ì¹´í…Œê³ ë¦¬ ì •ë³´ í‘œì‹œ (ì¶”ê°€ëœ ë¶€ë¶„)
            if 'title' in result:
                print(
                    f"ì¹´í…Œê³ ë¦¬: {result.get('category_icon', 'ğŸ“„')} {result['title']}")

            print(f"ì „ì²´ ë‚´ìš©:\n{result['content']}")
            print("-" * 40)

        print("=" * 60)

    def get_continue_choice(self) -> bool:
        """ê³„ì† ê²€ìƒ‰í• ì§€ ì„ íƒ (ê´€ë ¨ ê²€ìƒ‰ì–´ ì˜µì…˜ ì¶”ê°€)"""
        while True:
            continue_search = input(
                "\nğŸ”„ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if continue_search in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
                return True
            elif continue_search in ['n', 'no', 'ã„´', 'ì•„ë‹ˆì˜¤', 'ì•„ë‹ˆìš”']:
                return False
            else:
                print("y ë˜ëŠ” nì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def display_category_statistics(self, results: List[Dict]):
        """ì¹´í…Œê³ ë¦¬ í†µê³„ í‘œì‹œ (ì¶”ê°€ ê¸°ëŠ¥)"""
        categories = self._categorize_results(results)

        print("\nğŸ“ˆ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í†µê³„:")
        print("=" * 40)

        total_results = len(results)

        for category, items in categories.items():
            count = len(items)
            percentage = (count / total_results) * 100
            avg_score = sum(item.get('score', 0)
                            for item in items) / count if count > 0 else 0

            print(f"{category}")
            print(f"  ğŸ“Š ê°œìˆ˜: {count}ê°œ ({percentage:.1f}%)")
            print(f"  ğŸ¯ í‰ê·  ê´€ë ¨ë„: {avg_score:.3f}")

            # ìƒìœ„ í•­ëª©ë“¤ì˜ ì œëª© í‘œì‹œ
            if items:
                top_items = sorted(items, key=lambda x: x.get(
                    'score', 0), reverse=True)[:3]
                titles = [item['title'] for item in top_items]
                print(f"  ğŸ† ì£¼ìš” í•­ëª©: {', '.join(titles)}")
            print()

    def export_categorized_results(self, query: str, results: List[Dict], format='txt'):
        """ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (ì¶”ê°€ ê¸°ëŠ¥)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        categories = self._categorize_results(results)

        if format == 'txt':
            export_file = self.save_path / \
                f"{query}_categorized_{timestamp}.txt"

            with open(export_file, 'w', encoding='utf-8') as f:
                f.write(f"ë™ì˜ë³´ê° ê²€ìƒ‰ ê²°ê³¼ - ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜\n")
                f.write(f"ê²€ìƒ‰ì–´: {query}\n")
                f.write(f"ê²€ìƒ‰ ì‹œê°„: {timestamp}\n")
                f.write(f"ì´ ê²°ê³¼ ìˆ˜: {len(results)}ê°œ\n")
                f.write("=" * 60 + "\n\n")

                for category, items in categories.items():
                    f.write(f"{category} ({len(items)}ê°œ)\n")
                    f.write("-" * 40 + "\n")

                    for i, item in enumerate(items):
                        f.write(
                            f"{i + 1}. {item['title']} (ê´€ë ¨ë„: {item['score']:.3f})\n")
                        f.write(f"   {item['summary']}\n")
                        f.write(
                            f"   ì¶œì²˜: {item['metadata']['source_file']}\n\n")

                    f.write("\n")

            print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {export_file}")

        return export_file if format == 'txt' else None

    def display_search_results_with_metrics(self, query: str, results: List[Dict], answer: str,
                                            show_metrics: bool = True, show_related_queries: bool = True) -> bool:
        """ë©”íŠ¸ë¦­ í¬í•¨ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ í¬í•¨)"""

        # ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ í¬í•¨)
        show_details = self.display_search_results(
            query, results, answer, show_related_queries=show_related_queries)

        # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
        if show_metrics:
            self.show_search_metrics(query, results)

        return show_details
