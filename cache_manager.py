#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ï∫êÏãú Í¥ÄÎ¶¨ Î™®Îìà - cache_manager.py
ÏãúÏä§ÌÖú Îç∞Ïù¥ÌÑ∞ Ï∫êÏã±Í≥º Î°úÎî©ÏùÑ Îã¥Îãπ
"""

import pickle
import numpy as np
import faiss
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import warnings
warnings.filterwarnings("ignore")


class CacheManager:
    def __init__(self, cache_path: str = "/Users/radi/Projects/langchainDATA/RAWDATA/DYBG/cache"):
        """Ï∫êÏãú Í¥ÄÎ¶¨Ïûê Ï¥àÍ∏∞Ìôî"""
        self.cache_path = Path(cache_path)
        self.cache_path.mkdir(parents=True, exist_ok=True)

    def save_cache(self, data_hash: str, chunks: List[Dict], embeddings: np.ndarray, faiss_index):
        """Ï∫êÏãú Ï†ÄÏû•"""
        print("üíæ Ï∫êÏãú Ï†ÄÏû• Ï§ë...")

        cache_data = {
            'data_hash': data_hash,
            'chunks': chunks,
            'timestamp': datetime.now().isoformat()
        }

        # Ï≤≠ÌÅ¨ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
        chunks_file = self.cache_path / 'chunks.pkl'
        with open(chunks_file, 'wb') as f:
            pickle.dump(cache_data, f)

        # ÏûÑÎ≤†Îî© Ï†ÄÏû•
        embeddings_file = self.cache_path / 'embeddings.npy'
        np.save(embeddings_file, embeddings)

        # FAISS Ïù∏Îç±Ïä§ Ï†ÄÏû•
        faiss_file = self.cache_path / 'faiss_index.index'
        faiss.write_index(faiss_index, str(faiss_file))

        print("‚úÖ Ï∫êÏãú Ï†ÄÏû• ÏôÑÎ£å")

    def load_cache(self, current_data_hash: str) -> Tuple[bool, Optional[Dict]]:
        """Ï∫êÏãú Î°úÎìú"""
        chunks_file = self.cache_path / 'chunks.pkl'
        embeddings_file = self.cache_path / 'embeddings.npy'
        faiss_file = self.cache_path / 'faiss_index.index'

        if not all([chunks_file.exists(), embeddings_file.exists(), faiss_file.exists()]):
            print("üìù Ï∫êÏãú ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§. ÏÉàÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.")
            return False, None

        try:
            print("üîÑ Ï∫êÏãúÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë...")

            # Ï≤≠ÌÅ¨ Îç∞Ïù¥ÌÑ∞ Î°úÎìú
            with open(chunks_file, 'rb') as f:
                cache_data = pickle.load(f)

            # Îç∞Ïù¥ÌÑ∞ Ìï¥Ïãú ÎπÑÍµê
            if cache_data['data_hash'] != current_data_hash:
                print("üìù ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞Í∞Ä Î≥ÄÍ≤ΩÎêòÏóàÏäµÎãàÎã§. ÏÉàÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.")
                return False, None

            # ÎÇòÎ®∏ÏßÄ Îç∞Ïù¥ÌÑ∞ Î°úÎìú
            embeddings = np.load(embeddings_file)
            faiss_index = faiss.read_index(str(faiss_file))

            result = {
                'data_hash': cache_data['data_hash'],
                'chunks': cache_data['chunks'],
                'embeddings': embeddings,
                'faiss_index': faiss_index,
                'timestamp': cache_data['timestamp']
            }

            print(f"‚úÖ Ï∫êÏãú Î°úÎìú ÏôÑÎ£å! (ÏÉùÏÑ±: {cache_data['timestamp']})")
            print(
                f"üìä Î°úÎìúÎêú Îç∞Ïù¥ÌÑ∞: {len(cache_data['chunks'])}Í∞ú Ï≤≠ÌÅ¨, {embeddings.shape} ÏûÑÎ≤†Îî©")
            return True, result

        except Exception as e:
            print(f"‚ö†Ô∏è Ï∫êÏãú Î°úÎìú Ïã§Ìå®: {e}")
            print("üìù ÏÉàÎ°ú ÏÉùÏÑ±Ìï©ÎãàÎã§.")
            return False, None

    def clear_cache(self):
        """Ï∫êÏãú ÏÇ≠Ï†ú"""
        try:
            cache_files = [
                self.cache_path / 'chunks.pkl',
                self.cache_path / 'embeddings.npy',
                self.cache_path / 'faiss_index.index'
            ]

            for file in cache_files:
                if file.exists():
                    file.unlink()

            print("üóëÔ∏è Ï∫êÏãúÍ∞Ä ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.")
        except Exception as e:
            print(f"‚ö†Ô∏è Ï∫êÏãú ÏÇ≠Ï†ú Ïã§Ìå®: {e}")

    def get_cache_info(self) -> Dict:
        """Ï∫êÏãú Ï†ïÎ≥¥ Ï°∞Ìöå"""
        chunks_file = self.cache_path / 'chunks.pkl'
        embeddings_file = self.cache_path / 'embeddings.npy'
        faiss_file = self.cache_path / 'faiss_index.index'

        cache_info = {
            'chunks_exists': chunks_file.exists(),
            'embeddings_exists': embeddings_file.exists(),
            'faiss_exists': faiss_file.exists(),
            'cache_complete': False,
            'size_info': {}
        }

        if all([chunks_file.exists(), embeddings_file.exists(), faiss_file.exists()]):
            cache_info['cache_complete'] = True

            try:
                # ÌååÏùº ÌÅ¨Í∏∞ Ï†ïÎ≥¥
                cache_info['size_info'] = {
                    'chunks_size_mb': chunks_file.stat().st_size / (1024 * 1024),
                    'embeddings_size_mb': embeddings_file.stat().st_size / (1024 * 1024),
                    'faiss_size_mb': faiss_file.stat().st_size / (1024 * 1024)
                }

                # Ï≤≠ÌÅ¨ Í∞úÏàò Ï†ïÎ≥¥
                with open(chunks_file, 'rb') as f:
                    cache_data = pickle.load(f)
                    cache_info['chunks_count'] = len(cache_data['chunks'])
                    cache_info['timestamp'] = cache_data['timestamp']
                    cache_info['data_hash'] = cache_data['data_hash']

            except Exception as e:
                cache_info['error'] = str(e)

        return cache_info
