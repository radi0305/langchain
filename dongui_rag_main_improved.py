#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ ë©”ì¸ ëª¨ë“ˆ - dongui_rag_main_improved.py (ì™„ì „ ê°œì„ ëœ ë²„ì „)
í•˜ë“œì½”ë”© ì œê±° ë° í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „ ì „í™˜
ê²€ìƒ‰ ê²°ê³¼ ê·¸ë£¹í•‘, ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ ë° ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆì„ í¬í•¨í•œ í†µí•© ì‹¤í–‰ ëª¨ë“ˆ
"""

import sys
from pathlib import Path
from typing import Optional, List, Dict
import warnings
warnings.filterwarnings("ignore")

# ê°œì„ ëœ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from document_processor_improved import DocumentProcessor
    from search_engine_improved import SearchEngine
    from cache_manager import CacheManager
    from answer_generator_improved import AnswerGenerator
    from medical_terms_manager_improved import MedicalTermsManager
    from llm_manager import LLMManager
except ImportError as e:
    print(f"í•„ìˆ˜ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤: {e}")
    print("ë‹¤ìŒ ê°œì„ ëœ íŒŒì¼ë“¤ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:")
    print("- document_processor_improved.py")
    print("- search_engine_improved.py")
    print("- answer_generator_improved.py")
    print("- medical_terms_manager_improved.py")
    print("- cache_manager.py")
    print("- llm_manager.py")
    sys.exit(1)


class DonguiRAGSystemImproved:
    """ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""

    def __init__(self,
                 data_path: str = "/Users/radi/Projects/langchainDATA/RAWDATA/DYBG",
                 cache_path: str = "/Users/radi/Projects/langchainDATA/RAWDATA/DYBG/cache",
                 save_path: str = "/Users/radi/Projects/langchainDATA/Results/DYBGsearch"):
        """ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""
        self.data_path = Path(data_path)
        self.cache_path = Path(cache_path)
        self.save_path = Path(save_path)

        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.data_path.mkdir(parents=True, exist_ok=True)
        self.cache_path.mkdir(parents=True, exist_ok=True)
        self.save_path.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ“‚ ë°ì´í„° ê²½ë¡œ: {self.data_path}")
        print(f"ğŸ’¾ ìºì‹œ ê²½ë¡œ: {self.cache_path}")
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {self.save_path}")

        # LLM ê´€ë¦¬ì ì´ˆê¸°í™”
        print("ğŸ”§ OpenAI ì—°ê²° ì¤‘...")
        self.llm_manager = LLMManager()

        if not self.llm_manager.is_available():
            print("âŒ OpenAI ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ API í‚¤ ì„¤ì • í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            sys.exit(1)

        # ì‹œìŠ¤í…œ ëª¨ë“ˆ ì´ˆê¸°í™”
        print("ğŸ”§ ì™„ì „ ê°œì„ ëœ ì‹œìŠ¤í…œ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘...")

        # 1. ê³ ê¸‰ í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì (ê°€ì¥ ë¨¼ì € ì´ˆê¸°í™”)
        try:
            print("ğŸ“š ê³ ê¸‰ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê´€ë¦¬ì ì´ˆê¸°í™” ì¤‘...")
            self.terms_manager = MedicalTermsManager(
                cache_path=str(self.cache_path)
            )

            # ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦
            validation = self.terms_manager.validate_system_integrity()
            if not validation['basic_indexes_ok']:
                print("âš ï¸ í‘œì¤€ìš©ì–´ì§‘ ì‹œìŠ¤í…œì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.")
                for error in validation['errors']:
                    print(f"   - {error}")
            else:
                stats = self.terms_manager.get_statistics()
                print(f"âœ… ê³ ê¸‰ í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
                print(f"   ğŸ“Š ì´ ìš©ì–´: {stats.get('total_terms', 0):,}ê°œ")
                print(
                    f"   ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„: {stats.get('relationship_graph_nodes', 0):,}ê°œ ë…¸ë“œ")
                print(f"   ğŸ”¬ ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {stats.get('semantic_clusters', 0)}ê°œ")

        except Exception as e:
            print(f"âš ï¸ ê³ ê¸‰ í‘œì¤€ìš©ì–´ì§‘ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ“š ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            self.terms_manager = None

        # 2. ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ê¸°
        self.document_processor = DocumentProcessor(
            data_path=str(self.data_path),
            terms_manager=self.terms_manager
        )

        # ì²˜ë¦¬ í†µê³„ ì¶œë ¥
        proc_stats = self.document_processor.get_processing_statistics()
        print(f"âœ… ê°œì„ ëœ ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ğŸ“Š ë™ì  TCM ìš©ì–´: {proc_stats.get('dynamic_terms_count', 0)}ê°œ")
        print(
            f"   ğŸ” ì²˜ë°© íŒ¨í„´: {proc_stats.get('prescription_patterns_count', 0)}ê°œ")
        print(f"   ğŸŒ¿ ì•½ì¬ íŒ¨í„´: {proc_stats.get('herb_patterns_count', 0)}ê°œ")

        # 3. ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„
        self.search_engine = SearchEngine()
        self.search_engine.set_terms_manager(self.terms_manager)

        # íŒ¨í„´ ìºì‹œ ì •ë³´ ì¶œë ¥
        pattern_info = self.search_engine.get_pattern_cache_info()
        print(f"âœ… ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
        print(
            f"   ğŸ” ë™ì  íŒ¨í„´: {pattern_info.get('prescription_suffixes_count', 0) + pattern_info.get('symptom_suffixes_count', 0)}ê°œ")
        print(f"   ğŸŒ¿ ì•½ì¬ íŒ¨í„´: {pattern_info.get('major_herbs_count', 0)}ê°œ")

        # 4. ìºì‹œ ê´€ë¦¬ì
        self.cache_manager = CacheManager(cache_path=str(self.cache_path))
        print("âœ… ìºì‹œ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")

        # 5. ê³ ê¸‰ ë‹µë³€ ìƒì„±ê¸°
        self.answer_generator = AnswerGenerator(
            llm_manager=self.llm_manager,
            save_path=str(self.save_path),
            terms_manager=self.terms_manager  # í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°
        )
        print("âœ… ê³ ê¸‰ ë‹µë³€ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ (í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ)")

        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_initialized = False
        self.data_hash = None

        # ì‹œìŠ¤í…œ í’ˆì§ˆ ê²€ì¦
        self._validate_system_quality()

    def _validate_system_quality(self):
        """ì‹œìŠ¤í…œ í’ˆì§ˆ ê²€ì¦"""
        print("\nğŸ” ì‹œìŠ¤í…œ í’ˆì§ˆ ê²€ì¦ ì¤‘...")

        quality_score = 0
        max_score = 100

        # í‘œì¤€ìš©ì–´ì§‘ ì—°ê²° (30ì )
        if self.terms_manager:
            validation = self.terms_manager.validate_system_integrity()
            if validation['basic_indexes_ok']:
                quality_score += 30
                print("   âœ… í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°: ì™„ì „ (30/30)")
            else:
                quality_score += 15
                print("   âš ï¸ í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°: ë¶€ë¶„ (15/30)")
        else:
            print("   âŒ í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°: ì—†ìŒ (0/30)")

        # ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ (25ì )
        pattern_info = self.search_engine.get_pattern_cache_info()
        if pattern_info.get('terms_manager_connected', False):
            pattern_count = (pattern_info.get('prescription_suffixes_count', 0) +
                             pattern_info.get('symptom_suffixes_count', 0) +
                             pattern_info.get('major_herbs_count', 0))
            if pattern_count > 50:
                quality_score += 25
                print("   âœ… ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: ì™„ì „ (25/25)")
            elif pattern_count > 20:
                quality_score += 15
                print("   âš ï¸ ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: ì–‘í˜¸ (15/25)")
            else:
                quality_score += 5
                print("   âš ï¸ ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: ê¸°ë³¸ (5/25)")
        else:
            print("   âŒ ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: ì—°ê²° ì•ˆë¨ (0/25)")

        # LLM ì—°ê²° (20ì )
        if self.llm_manager.is_available():
            quality_score += 20
            print("   âœ… LLM ì—°ê²°: ì™„ì „ (20/20)")
        else:
            print("   âŒ LLM ì—°ê²°: ì‹¤íŒ¨ (0/20)")

        # ë¬¸ì„œ ì²˜ë¦¬ í’ˆì§ˆ (15ì )
        proc_stats = self.document_processor.get_processing_statistics()
        if not proc_stats.get('fallback_mode', True):
            quality_score += 15
            print("   âœ… ë¬¸ì„œ ì²˜ë¦¬: ê³ ê¸‰ ëª¨ë“œ (15/15)")
        else:
            quality_score += 8
            print("   âš ï¸ ë¬¸ì„œ ì²˜ë¦¬: ê¸°ë³¸ ëª¨ë“œ (8/15)")

        # ìºì‹œ ì‹œìŠ¤í…œ (10ì )
        cache_info = self.cache_manager.get_cache_info()
        if cache_info.get('cache_complete', False):
            quality_score += 10
            print("   âœ… ìºì‹œ ì‹œìŠ¤í…œ: ì™„ì „ (10/10)")
        else:
            quality_score += 5
            print("   âš ï¸ ìºì‹œ ì‹œìŠ¤í…œ: ë¶€ë¶„ (5/10)")

        # í’ˆì§ˆ ë“±ê¸‰ ê²°ì •
        if quality_score >= 90:
            grade = "S+ (ìµœê³ ê¸‰)"
            color = "ğŸŸ¢"
        elif quality_score >= 80:
            grade = "S (ìš°ìˆ˜)"
            color = "ğŸŸ¢"
        elif quality_score >= 70:
            grade = "A (ì–‘í˜¸)"
            color = "ğŸŸ¡"
        elif quality_score >= 60:
            grade = "B (ë³´í†µ)"
            color = "ğŸŸ¡"
        else:
            grade = "C (ê°œì„  í•„ìš”)"
            color = "ğŸ”´"

        print(f"\n{color} ì‹œìŠ¤í…œ í’ˆì§ˆ ë“±ê¸‰: {grade} ({quality_score}/100ì )")

        if quality_score < 70:
            print("\nğŸ’¡ í’ˆì§ˆ ê°œì„  ì œì•ˆ:")
            if not self.terms_manager:
                print("   - í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ íŒŒì¼ í™•ì¸ ë° ì„¤ì¹˜")
            if not pattern_info.get('terms_manager_connected', False):
                print("   - ìš©ì–´ì§‘-ê²€ìƒ‰ì—”ì§„ ì—°ê²° í™•ì¸")
            if proc_stats.get('fallback_mode', True):
                print("   - ë¬¸ì„œ ì²˜ë¦¬ê¸° ìš©ì–´ì§‘ ì—°ê²° í™•ì¸")

    def initialize_system(self, force_rebuild: bool = False):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ê°œì„ ëœ ë²„ì „)"""
        print("\nğŸš€ ì™„ì „ ê°œì„ ëœ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        # ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
        if not self.check_directory_structure():
            print("âŒ í•„ìˆ˜ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

        # í˜„ì¬ ë°ì´í„° í•´ì‹œ ê³„ì‚°
        self.data_hash = self.document_processor.calculate_data_hash()

        if not force_rebuild:
            # ìºì‹œ ë¡œë“œ ì‹œë„
            cache_loaded, cache_data = self.cache_manager.load_cache(
                self.data_hash)

            if cache_loaded and cache_data:
                # ìºì‹œì—ì„œ ë³µì›
                chunks = cache_data['chunks']
                embeddings = cache_data['embeddings']
                faiss_index = cache_data['faiss_index']

                # ê²€ìƒ‰ ì—”ì§„ ì„¤ì •
                self.search_engine.setup(chunks, embeddings)
                self.search_engine.faiss_index = faiss_index

                self.is_initialized = True
                print("ğŸ‰ ê³ ê¸‰ ìºì‹œì—ì„œ ë¹ ë¥´ê²Œ ë¡œë“œ ì™„ë£Œ!")

                # ì‹œìŠ¤í…œ ê²€ì¦
                self._post_initialization_validation(chunks)
                return

        # ìƒˆë¡œ ë°ì´í„° ì²˜ë¦¬
        print("ğŸ“š ê°œì„ ëœ ì‹œìŠ¤í…œìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤...")

        # 1. ë¬¸ì„œ ë¡œë“œ ë° ê³ ê¸‰ ì²­í‚¹
        print("   ğŸ“„ ê³ ê¸‰ ë¬¸ì„œ ì²˜ë¦¬ ë° ì²­í‚¹ ì¤‘...")
        chunks = self.document_processor.load_documents()

        # ì²­í¬ ìœ íš¨ì„± ê²€ì¦
        validation_result = self.document_processor.validate_chunks(chunks)
        print(f"   ğŸ“Š ì²­í¬ ê²€ì¦: ìœ íš¨ {validation_result['valid_chunks']}ê°œ, "
              f"ì˜¤ë¥˜ {validation_result['invalid_chunks']}ê°œ")

        if validation_result['invalid_chunks'] > 0:
            print(
                f"   âš ï¸ {validation_result['invalid_chunks']}ê°œ ì²­í¬ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            for error in validation_result['errors'][:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                print(f"      - {error}")

        # ëª¨ë¸ë³„ ìµœì í™”
        model_info = self.llm_manager.get_model_info()
        if model_info['name'] in ['gpt-4o-mini', 'gpt-4']:
            optimized_chunks = self.document_processor.optimize_chunks_for_model(
                chunks, model_info['name'])
            chunks = optimized_chunks

        # 2. ê³ ê¸‰ ì„ë² ë”© ìƒì„± ë° ì¸ë±ìŠ¤ êµ¬ì¶•
        print("   ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ì—”ì§„ ì„¤ì • ì¤‘...")
        self.search_engine.setup(chunks)

        # 3. ìºì‹œ ì €ì¥
        self.cache_manager.save_cache(
            self.data_hash,
            chunks,
            self.search_engine.embeddings,
            self.search_engine.faiss_index
        )

        self.is_initialized = True
        print("âœ… ì™„ì „ ê°œì„ ëœ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")

        # ì‹œìŠ¤í…œ ê²€ì¦
        self._post_initialization_validation(chunks)

    def _post_initialization_validation(self, chunks: List[Dict]):
        """ì´ˆê¸°í™” í›„ ì‹œìŠ¤í…œ ê²€ì¦"""
        print("\nğŸ” ì´ˆê¸°í™” í›„ ì‹œìŠ¤í…œ ê²€ì¦ ì¤‘...")

        # ì²­í¬ í†µê³„
        total_chunks = len(chunks)
        prescription_chunks = len(
            [c for c in chunks if c['metadata'].get('type') == 'prescription'])
        avg_chunk_size = sum(c['metadata'].get('token_count', 0)
                             for c in chunks) / total_chunks if total_chunks > 0 else 0

        print(f"   ğŸ“Š ì´ ì²­í¬: {total_chunks:,}ê°œ")
        print(
            f"   ğŸ’Š ì²˜ë°© ì²­í¬: {prescription_chunks}ê°œ ({prescription_chunks / total_chunks * 100:.1f}%)")
        print(f"   ğŸ“ í‰ê·  í† í°: {avg_chunk_size:.0f}ê°œ")

        # ê²€ìƒ‰ ì—”ì§„ ê²€ì¦
        if hasattr(self.search_engine, 'embeddings') and self.search_engine.embeddings is not None:
            embedding_shape = self.search_engine.embeddings.shape
            print(f"   ğŸ”¢ ì„ë² ë”© ì°¨ì›: {embedding_shape}")

        # í‘œì¤€ìš©ì–´ì§‘ ì—°ê²° ê²€ì¦
        if self.terms_manager:
            terms_stats = self.terms_manager.get_statistics()
            print(f"   ğŸ“š í‘œì¤€ìš©ì–´: {terms_stats.get('total_terms', 0):,}ê°œ ì—°ê²°ë¨")

        print("âœ… ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ")

    def search(self, query: str, k: int = 75):
        """ê³ ê¸‰ ê²€ìƒ‰ ì‹¤í–‰"""
        if not self.is_initialized:
            raise ValueError("ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        return self.search_engine.search(query, k)

    def generate_answer(self, query: str, search_results):
        """ê³ ê¸‰ ë‹µë³€ ìƒì„±"""
        return self.answer_generator.generate_answer(query, search_results)

    def save_results(self, query: str, results, answer: str):
        """ê²°ê³¼ ì €ì¥"""
        self.answer_generator.save_search_results(query, results, answer)

    def _get_k_value_choice(self, recommended_k: int, max_k: int) -> int:
        """Kê°’ ì„ íƒ (ê°œì„ ëœ ê°€ì´ë“œ)"""
        print("\nğŸ”§ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print(f"1. ê¶Œì¥ê°’ ({recommended_k}ê°œ) - ê· í˜•ì¡íŒ ë¶„ì„ (í‘œì¤€ìš©ì–´ì§‘ ìµœì í™”)")
        print(f"2. ìµœëŒ€ê°’ ({max_k}ê°œ) - ìµœëŒ€í•œ í¬ê´„ì  ë¶„ì„")
        print("3. ì§ì ‘ ì…ë ¥ (50~100)")

        if self.terms_manager:
            print("ğŸ’¡ í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°ë¨: ë” ì •í™•í•œ í™•ì¥ ê²€ìƒ‰ ê°€ëŠ¥")
        else:
            print("âš ï¸ í‘œì¤€ìš©ì–´ì§‘ ë¯¸ì—°ê²°: ê¸°ë³¸ ê²€ìƒ‰ë§Œ ê°€ëŠ¥")

        while True:
            choice = input("ì„ íƒ (1/2/3): ").strip()
            if choice == '1':
                return recommended_k
            elif choice == '2':
                return max_k
            elif choice == '3':
                try:
                    custom_k = int(input("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì…ë ¥ (50~100): "))
                    if 50 <= custom_k <= 100:
                        return custom_k
                    else:
                        print("50~100 ì‚¬ì´ì˜ ê°’ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                except ValueError:
                    print("ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                print("1, 2, ë˜ëŠ” 3ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def _get_display_options(self) -> dict:
        """í‘œì‹œ ì˜µì…˜ ì„¤ì • (ê°œì„ ëœ ì˜µì…˜)"""
        print("\nğŸ¨ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ìŠ¤ë§ˆíŠ¸ ì¹´í…Œê³ ë¦¬ + ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ (ê¸°ë³¸, ê¶Œì¥)")
        print("2. ì „í†µì ì¸ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ")
        print("3. ì™„ì „ ë¶„ì„ + í‘œì¤€ìš©ì–´ì§‘ í™œìš© (ëª¨ë“  ê¸°ëŠ¥)")
        print("4. í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¤‘ì‹¬ í‘œì‹œ")

        if self.terms_manager:
            print("ğŸ’¡ í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í™œìš© ê°€ëŠ¥")

        while True:
            choice = input("ì„ íƒ (1/2/3/4): ").strip()
            if choice == '1':
                return {
                    'show_categories': True,
                    'show_statistics': False,
                    'show_metrics': False,
                    'show_related_queries': True,
                    'traditional_view': False,
                    'advanced_suggestions': bool(self.terms_manager)
                }
            elif choice == '2':
                return {
                    'show_categories': False,
                    'show_statistics': False,
                    'show_metrics': False,
                    'show_related_queries': False,
                    'traditional_view': True,
                    'advanced_suggestions': False
                }
            elif choice == '3':
                return {
                    'show_categories': True,
                    'show_statistics': True,
                    'show_metrics': True,
                    'show_related_queries': True,
                    'traditional_view': False,
                    'advanced_suggestions': bool(self.terms_manager)
                }
            elif choice == '4':
                return {
                    'show_categories': False,
                    'show_statistics': False,
                    'show_metrics': True,
                    'show_related_queries': False,
                    'traditional_view': False,
                    'advanced_suggestions': False
                }
            else:
                print("1, 2, 3, ë˜ëŠ” 4ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def _process_query(self, query: str, k: int, display_options: dict):
        """ì¿¼ë¦¬ ì²˜ë¦¬ (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""
        print(f"\nğŸ” '{query}' ê³ ê¸‰ ê²€ìƒ‰ ì¤‘... (ê²°ê³¼ ìˆ˜: {k}ê°œ)")

        # ì¿¼ë¦¬ ì „ì²˜ë¦¬ (í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜)
        if self.terms_manager:
            # ì¿¼ë¦¬ í™•ì¥ ë¯¸ë¦¬ë³´ê¸°
            expanded_queries = self.terms_manager.expand_query(
                query, max_expansions=3)
            if len(expanded_queries) > 1:
                print(f"   ğŸ”„ í™•ì¥ ê²€ìƒ‰ì–´: {', '.join(expanded_queries[1:])}")

        # ê³ ê¸‰ ê²€ìƒ‰ ì‹¤í–‰
        search_results = self.search(query, k=k)

        if not search_results:
            print("âŒ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if self.terms_manager:
                # ìœ ì‚¬ ê²€ìƒ‰ì–´ ì œì•ˆ
                similar_terms = self.terms_manager.fuzzy_search(
                    query, threshold=0.3)
                if similar_terms:
                    print("ğŸ’¡ ìœ ì‚¬í•œ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”:")
                    for term, similarity in similar_terms[:3]:
                        print(f"   - {term} (ìœ ì‚¬ë„: {similarity:.3f})")
            return

        print(f"ğŸ“Š {len(search_results)}ê°œì˜ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        # ê³ ê¸‰ ë‹µë³€ ìƒì„±
        print("ğŸ¤– ê³ ê¸‰ AI ë‹µë³€ ìƒì„± ì¤‘...")
        answer = self.generate_answer(query, search_results)

        # ê²°ê³¼ í‘œì‹œ ë°©ì‹ì— ë”°ë¥¸ ì²˜ë¦¬
        if display_options.get('show_metrics', False):
            if display_options.get('show_categories', False):
                # ì™„ì „ ë¶„ì„ ëª¨ë“œ
                print("\n" + "=" * 60)
                if self.llm_manager and self.llm_manager.is_available():
                    print("ğŸ¤– AI ë‹µë³€ (í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ê·¼ê±° ë¬¸í—Œ ì£¼ì„ í¬í•¨):")
                    print("-" * 40)
                    print(answer)

                # ìë™ ì €ì¥
                self.save_results(query, search_results, answer)
                print("=" * 60)

                # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                self.answer_generator._display_categorized_results(
                    search_results)

                # ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í‘œì‹œ
                if display_options.get('show_related_queries', False):
                    self.answer_generator.display_related_queries(
                        query, search_results)

                # ìƒì„¸ í†µê³„ í‘œì‹œ
                if display_options.get('show_statistics', False):
                    self.answer_generator.display_category_statistics(
                        search_results)

                # ê³ ê¸‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                self.answer_generator.show_search_metrics(
                    query, search_results)

                # ìƒì„¸ ê²°ê³¼ ë³´ê¸° ì˜µì…˜
                show_details_input = input(
                    "\nğŸ“‹ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ì²´ ë‚´ìš©ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                if show_details_input in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
                    self.answer_generator._display_detailed_results(
                        search_results)

            else:
                # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¤‘ì‹¬ ëª¨ë“œ
                print("\n" + "=" * 50)
                if self.llm_manager and self.llm_manager.is_available():
                    print("ğŸ¤– AI ë‹µë³€:")
                    print("-" * 30)
                    print(answer)

                # ìë™ ì €ì¥
                self.save_results(query, search_results, answer)

                # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
                self.answer_generator.show_search_metrics(
                    query, search_results)

                # ìƒì„¸ ê²°ê³¼ ë³´ê¸° ì˜µì…˜
                show_details_input = input(
                    "\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ì˜ ìƒì„¸ ë‚´ìš©ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                if show_details_input in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
                    self.answer_generator._display_categorized_results(
                        search_results)

        elif display_options.get('show_categories', False):
            # ìŠ¤ë§ˆíŠ¸ ì¹´í…Œê³ ë¦¬ ëª¨ë“œ
            show_details = self.answer_generator.display_search_results(
                query, search_results, answer,
                show_related_queries=display_options.get('show_related_queries', True))

            # ìƒì„¸ í†µê³„ í‘œì‹œ (ì˜µì…˜)
            if display_options.get('show_statistics', False):
                self.answer_generator.display_category_statistics(
                    search_results)

        elif display_options.get('traditional_view', False):
            # ì „í†µì ì¸ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            show_details = self._display_traditional_results(
                query, search_results, answer)
            self.save_results(query, search_results, answer)

    def _handle_related_query_selection(self, query: str, search_results: List[Dict], k: int, display_options: dict) -> Optional[str]:
        """ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì„ íƒ ì²˜ë¦¬"""
        if not self.terms_manager:
            return None

        # í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ê³ ê¸‰ ì œì•ˆ
        advanced_suggestions = self.answer_generator.suggest_related_queries_advanced(
            query, search_results, self.terms_manager)

        if not advanced_suggestions:
            return None

        selected_query = self.answer_generator.get_user_choice_for_suggestions(
            advanced_suggestions)

        if selected_query and selected_query != query:
            print(f"\nğŸ”„ '{selected_query}'ë¡œ ê³ ê¸‰ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            self._process_query(selected_query, k, display_options)
            return selected_query

        return None

    def _handle_special_commands(self, query: str) -> bool:
        """íŠ¹ìˆ˜ ëª…ë ¹ì–´ ì²˜ë¦¬ (ê°œì„ ëœ ëª…ë ¹ì–´ ì¶”ê°€)"""
        if query.lower().startswith('help') or query == 'ë„ì›€ë§':
            self._show_help()
            return True
        elif query.lower().startswith('stats') or query == 'í†µê³„':
            self._show_system_stats()
            return True
        elif query.lower().startswith('config') or query == 'ì„¤ì •':
            self._show_config_menu()
            return True
        elif query.lower().startswith('metrics') or query == 'í’ˆì§ˆ':
            self._show_metrics_help()
            return True
        elif query.lower().startswith('related') or query == 'ê´€ë ¨':
            self._show_related_queries_help()
            return True
        elif query.lower().startswith('terms') or query == 'ìš©ì–´ì§‘':
            self._show_terms_manager_info()
            return True
        elif query.lower().startswith('advanced') or query == 'ê³ ê¸‰':
            self._show_advanced_features()
            return True

        return False

    def _show_terms_manager_info(self):
        """í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ì •ë³´ í‘œì‹œ"""
        print("\nğŸ“š í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê´€ë¦¬ì ì •ë³´")
        print("=" * 50)

        if self.terms_manager:
            stats = self.terms_manager.get_statistics()
            validation = self.terms_manager.validate_system_integrity()

            print("âœ… ì—°ê²° ìƒíƒœ: ì •ìƒ")
            print(f"ğŸ“Š ì´ ìš©ì–´ ìˆ˜: {stats.get('total_terms', 0):,}ê°œ")
            print(f"ğŸ” ê²€ìƒ‰ ì¸ë±ìŠ¤: {stats.get('search_index_size', 0):,}ê°œ")
            print(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {stats.get('categories', 0)}ê°œ")
            print(
                f"ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„: {stats.get('relationship_graph_nodes', 0):,}ê°œ ë…¸ë“œ, {stats.get('relationship_graph_edges', 0):,}ê°œ ì—£ì§€")
            print(f"ğŸ”¬ ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {stats.get('semantic_clusters', 0)}ê°œ")
            print(f"ğŸ§  ë„ë©”ì¸ ì§€ì‹ íŒ¨í„´: {stats.get('domain_knowledge_patterns', 0)}ê°œ")

            if 'graph_density' in stats:
                print(f"ğŸ“ˆ ê·¸ë˜í”„ ë°€ë„: {stats['graph_density']:.4f}")
                print(f"ğŸ”— í‰ê·  í´ëŸ¬ìŠ¤í„°ë§: {stats['average_clustering']:.4f}")

            if 'most_central_terms' in stats:
                print(f"â­ ì¤‘ì‹¬ì„± ë†’ì€ ìš©ì–´: {', '.join(stats['most_central_terms'])}")

            print(f"\nğŸ”§ ì‹œìŠ¤í…œ ë¬´ê²°ì„±:")
            print(
                f"   ê¸°ë³¸ ì¸ë±ìŠ¤: {'âœ…' if validation['basic_indexes_ok'] else 'âŒ'}")
            print(f"   ê´€ê³„ ê·¸ë˜í”„: {'âœ…' if validation['graph_ok'] else 'âŒ'}")
            print(f"   ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {'âœ…' if validation['clusters_ok'] else 'âŒ'}")
            print(
                f"   ë„ë©”ì¸ ì§€ì‹: {'âœ…' if validation['domain_knowledge_ok'] else 'âŒ'}")

            if validation['warnings']:
                print(f"\nâš ï¸ ê²½ê³ :")
                for warning in validation['warnings'][:3]:
                    print(f"   - {warning}")
        else:
            print("âŒ ì—°ê²° ìƒíƒœ: í‘œì¤€ìš©ì–´ì§‘ì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ í•´ê²° ë°©ë²•:")
            print("   1. hmedicalterms.json íŒŒì¼ í™•ì¸")
            print("   2. íŒŒì¼ ê²½ë¡œ í™•ì¸: /Users/radi/Projects/langchain/hmedicalterms.json")
            print("   3. ì‹œìŠ¤í…œ ì¬ì‹œì‘")

    def _show_advanced_features(self):
        """ê³ ê¸‰ ê¸°ëŠ¥ ì•ˆë‚´"""
        print("\nğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ì•ˆë‚´")
        print("=" * 40)

        print("ğŸ” ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥:")
        print("   â€¢ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê¸°ë°˜ ì§€ëŠ¥í˜• ì¿¼ë¦¬ í™•ì¥")
        print("   â€¢ ê´€ê³„ ê·¸ë˜í”„ ê¸°ë°˜ ì—°ê´€ ìš©ì–´ íƒìƒ‰")
        print("   â€¢ ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìœ ì‚¬ ìš©ì–´ ë°œê²¬")
        print("   â€¢ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë§¥ë½ì  ê²€ìƒ‰")

        print("\nğŸ¯ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ:")
        print("   â€¢ 6ë‹¨ê³„ í™•ì¥ ì „ëµ (ì§ì ‘ë§¤ì¹­â†’ê·¸ë˜í”„â†’ë„ë©”ì¸ì§€ì‹â†’í´ëŸ¬ìŠ¤í„°â†’ê³µê¸°ê´€ê³„â†’íŒ¨í„´)")
        print("   â€¢ ì¹´í…Œê³ ë¦¬ë³„ ì²´ê³„ì  ë¶„ë¥˜ (ì²˜ë°©, ë³‘ì¦, ì•½ì¬, ì´ë¡ )")
        print("   â€¢ ë‹¤ì°¨ì› ì ìˆ˜ ê¸°ë°˜ ìˆœìœ„ ë§¤ê¸°ê¸°")

        print("\nğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë¶„ì„:")
        print("   â€¢ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì„±ëŠ¥ ë©”íŠ¸ë¦­")
        print("   â€¢ ë‚´ìš© íƒ€ì…ë³„ ë‹¤ì–‘ì„± ë¶„ì„")
        print("   â€¢ ì¶œì²˜ ë° ëŒ€ë¶„ë¥˜ ì»¤ë²„ë¦¬ì§€ ë¶„ì„")
        print("   â€¢ ê²€ìƒ‰ ê°œì„  ì œì•ˆ ì‹œìŠ¤í…œ")

        print("\nğŸ”§ ì‹œìŠ¤í…œ ìµœì í™”:")
        print("   â€¢ ë™ì  íŒ¨í„´ ìƒì„± (í•˜ë“œì½”ë”© ì œê±°)")
        print("   â€¢ ëª¨ë¸ë³„ ì²­í¬ ìµœì í™”")
        print("   â€¢ ìºì‹œ ê¸°ë°˜ ê³ ì† ë¡œë”©")
        print("   â€¢ ì‹œìŠ¤í…œ ë¬´ê²°ì„± ìë™ ê²€ì¦")

    def _show_help(self):
        """ë„ì›€ë§ í‘œì‹œ (ê°œì„ ëœ ë²„ì „)"""
        print("\nğŸ“š ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ v3.0 (ì™„ì „ ê°œì„ íŒ) ë„ì›€ë§")
        print("=" * 60)
        print("ğŸ” ê²€ìƒ‰ ì˜ˆì‹œ:")
        print("   - è¡€è™› ì¹˜ë£Œë²•ì€?")
        print("   - å››å›å­æ¹¯ì˜ êµ¬ì„±ê³¼ íš¨ëŠ¥")
        print("   - è£œä¸­ç›Šæ°£æ¹¯ ê´€ë ¨ ë‚´ìš©")
        print("   - ì¸ì‚¼ì˜ íš¨ëŠ¥ê³¼ ì£¼ì¹˜")
        print()
        print("ğŸ› ï¸ íŠ¹ìˆ˜ ëª…ë ¹ì–´:")
        print("   - help ë˜ëŠ” ë„ì›€ë§: ì´ ë„ì›€ë§ í‘œì‹œ")
        print("   - stats ë˜ëŠ” í†µê³„: ì‹œìŠ¤í…œ í†µê³„ í‘œì‹œ")
        print("   - config ë˜ëŠ” ì„¤ì •: ì„¤ì • ë©”ë‰´")
        print("   - metrics ë˜ëŠ” í’ˆì§ˆ: ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ ì„¤ëª…")
        print("   - related ë˜ëŠ” ê´€ë ¨: ê´€ë ¨ ê²€ìƒ‰ì–´ ê¸°ëŠ¥ ì„¤ëª…")
        print("   - terms ë˜ëŠ” ìš©ì–´ì§‘: í‘œì¤€ìš©ì–´ì§‘ ì •ë³´")
        print("   - advanced ë˜ëŠ” ê³ ê¸‰: ê³ ê¸‰ ê¸°ëŠ¥ ì•ˆë‚´")
        print("   - quit, exit, ì¢…ë£Œ: ì‹œìŠ¤í…œ ì¢…ë£Œ")
        print()
        print("ğŸ†• v3.0 ìƒˆë¡œìš´ ê¸°ëŠ¥:")
        print("   - ğŸ”¥ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ì™„ì „ í†µí•©")
        print("   - ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„ ê¸°ë°˜ ì§€ëŠ¥í˜• ê²€ìƒ‰")
        print("   - ğŸ”¬ ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„")
        print("   - ğŸ§  ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ í™œìš©")
        print("   - ğŸ¯ 6ë‹¨ê³„ í™•ì¥ ì „ëµ")
        print("   - ğŸ“Š ê³ ê¸‰ ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­")
        print("   - ğŸ”§ í•˜ë“œì½”ë”© ì™„ì „ ì œê±°")
        print()
        print("ğŸ’¡ íŒ:")
        print("   - í•œìì™€ í•œê¸€ ëª¨ë‘ ê²€ìƒ‰ ê°€ëŠ¥")
        print("   - í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ì •í™•í•œ í™•ì¥ ê²€ìƒ‰")
        print("   - ê´€ë ¨ ê²€ìƒ‰ì–´ë¡œ ê¹Šì´ ìˆëŠ” íƒìƒ‰")
        print("   - ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ìœ¼ë¡œ ê²°ê³¼ ì‹ ë¢°ë„ í™•ì¸")

    def _show_system_stats(self):
        """ì‹œìŠ¤í…œ í†µê³„ í‘œì‹œ (ê°œì„ ëœ ë²„ì „)"""
        info = self.get_system_info()
        print("\nğŸ“Š ì™„ì „ ê°œì„ ëœ ì‹œìŠ¤í…œ í†µê³„")
        print("=" * 50)

        # ê¸°ë³¸ ì •ë³´
        print("ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì„±:")
        print(f"   ğŸ“š ì´ ì²­í¬ ìˆ˜: {info.get('chunks_count', 'N/A'):,}ê°œ")
        print(f"   ğŸ”¢ ì„ë² ë”© ì°¨ì›: {info.get('embeddings_shape', 'N/A')}")
        print(
            f"   ğŸ’¾ ìºì‹œ ìƒíƒœ: {'âœ… í™œì„±' if info.get('cache_info', {}).get('cache_complete', False) else 'âŒ ë¹„í™œì„±'}")
        print(f"   ğŸ“‚ ë°ì´í„° ê²½ë¡œ: {info['data_path']}")
        print(f"   ğŸ’¾ ê²°ê³¼ ì €ì¥: {info['save_path']}")

        # í‘œì¤€ìš©ì–´ì§‘ ì •ë³´
        print(f"\nğŸ“š í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘:")
        if info['terms_manager_available']:
            if self.terms_manager:
                stats = self.terms_manager.get_statistics()
                print(f"   âœ… ì—°ê²° ìƒíƒœ: ì •ìƒ")
                print(f"   ğŸ“Š ì´ ìš©ì–´: {stats.get('total_terms', 0):,}ê°œ")
                print(
                    f"   ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„: {stats.get('relationship_graph_nodes', 0):,}ê°œ ë…¸ë“œ")
                print(f"   ğŸ”¬ ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {stats.get('semantic_clusters', 0)}ê°œ")
                print(
                    f"   ğŸ§  ë„ë©”ì¸ ì§€ì‹: {stats.get('domain_knowledge_patterns', 0)}ê°œ íŒ¨í„´")
        else:
            print(f"   âŒ ì—°ê²° ìƒíƒœ: ë¯¸ì—°ê²°")

        # LLM ì •ë³´
        model_info = self.llm_manager.get_model_info()
        print(f"\nğŸ¤– AI ëª¨ë¸:")
        print(f"   ëª¨ë¸ëª…: {model_info['display_name']}")
        print(f"   ì—°ê²° ìƒíƒœ: {'âœ…' if model_info['is_connected'] else 'âŒ'}")
        print(f"   ìµœì  Kê°’: {model_info['optimal_k']}")
        print(f"   ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {model_info['max_context_tokens']:,} í† í°")

        # ê³ ê¸‰ ê¸°ëŠ¥ ìƒíƒœ
        print(f"\nğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ìƒíƒœ:")
        print(f"   ğŸ” ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: âœ… í™œì„±")
        print(f"   ğŸ¯ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ: âœ… í™œì„±")
        print(f"   ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­: âœ… í™œì„±")
        print(f"   ğŸ”§ í•˜ë“œì½”ë”© ì œê±°: âœ… ì™„ë£Œ")

        # íŒ¨í„´ ìºì‹œ ì •ë³´
        if hasattr(self.search_engine, 'get_pattern_cache_info'):
            pattern_info = self.search_engine.get_pattern_cache_info()
            print(
                f"   ğŸ·ï¸ ì²˜ë°© íŒ¨í„´: {pattern_info.get('prescription_suffixes_count', 0)}ê°œ")
            print(f"   ğŸŒ¿ ì•½ì¬ íŒ¨í„´: {pattern_info.get('major_herbs_count', 0)}ê°œ")
            print(
                f"   ğŸ“š ì´ë¡  ê°œë…: {pattern_info.get('theory_concepts_count', 0)}ê°œ")

    def _show_config_menu(self):
        """ì„¤ì • ë©”ë‰´ í‘œì‹œ (ê°œì„ ëœ ë²„ì „)"""
        print("\nâš™ï¸ ê³ ê¸‰ ì„¤ì • ë©”ë‰´")
        print("=" * 40)
        print("1. ìºì‹œ ì •ë³´ í™•ì¸")
        print("2. ìºì‹œ ì‚­ì œ")
        print("3. í‘œì¤€ìš©ì–´ì§‘ ìƒì„¸ ì •ë³´")
        print("4. ê´€ë ¨ ê²€ìƒ‰ì–´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        print("5. ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦")
        print("6. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("7. íŒ¨í„´ ìºì‹œ ì¬êµ¬ì¶•")
        print("8. ëŒì•„ê°€ê¸°")

        while True:
            choice = input("ì„ íƒ (1-8): ").strip()
            if choice == '1':
                cache_info = self.cache_manager.get_cache_info()
                print(f"\nğŸ’¾ ìºì‹œ ì •ë³´:")
                print(
                    f"   ìƒíƒœ: {'ì™„ì „' if cache_info['cache_complete'] else 'ë¶ˆì™„ì „'}")
                if 'chunks_count' in cache_info:
                    print(f"   ì²­í¬ ìˆ˜: {cache_info['chunks_count']:,}ê°œ")
                    print(f"   ìƒì„± ì‹œê°„: {cache_info.get('timestamp', 'N/A')}")
                    print(f"   í¬ê¸° ì •ë³´: {cache_info.get('size_info', {})}")
                break
            elif choice == '2':
                confirm = input("ì •ë§ë¡œ ìºì‹œë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
                if confirm in ['y', 'yes', 'ã…‡']:
                    self.cache_manager.clear_cache()
                    if self.terms_manager:
                        self.terms_manager.clear_cache()
                    print("ğŸ—‘ï¸ ëª¨ë“  ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìƒˆë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
                break
            elif choice == '3':
                self._show_terms_manager_info()
                break
            elif choice == '4':
                print("\nğŸ§ª ê´€ë ¨ ê²€ìƒ‰ì–´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
                test_query = input("í…ŒìŠ¤íŠ¸ìš© ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: è¡€è™›): ").strip()
                if test_query and self.is_initialized:
                    print("ğŸ”„ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
                    test_results = self.search(test_query, k=20)
                    if test_results:
                        print("âœ… ê²€ìƒ‰ ì™„ë£Œ! ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ:")
                        self.answer_generator.display_related_queries(
                            test_query, test_results)
                    else:
                        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            elif choice == '5':
                print("\nğŸ” ì‹œìŠ¤í…œ ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
                if self.terms_manager:
                    validation = self.terms_manager.validate_system_integrity()
                    print("í‘œì¤€ìš©ì–´ì§‘ ê²€ì¦ ê²°ê³¼:")
                    for key, value in validation.items():
                        if isinstance(value, bool):
                            print(f"   {key}: {'âœ…' if value else 'âŒ'}")
                        elif isinstance(value, list) and value:
                            print(f"   {key}: {len(value)}ê°œ í•­ëª©")

                if hasattr(self.document_processor, 'validate_terms_manager_connection'):
                    doc_validation = self.document_processor.validate_terms_manager_connection()
                    print(f"ë¬¸ì„œ ì²˜ë¦¬ê¸° ì—°ê²°: {'âœ…' if doc_validation else 'âŒ'}")

                print("âœ… ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ")
                break
            elif choice == '6':
                print("\nâš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
                self._run_performance_benchmark()
                break
            elif choice == '7':
                print("\nğŸ”„ íŒ¨í„´ ìºì‹œ ì¬êµ¬ì¶• ì¤‘...")
                if hasattr(self.search_engine, 'rebuild_patterns'):
                    self.search_engine.rebuild_patterns()
                if hasattr(self.document_processor, 'rebuild_dynamic_dictionary'):
                    self.document_processor.rebuild_dynamic_dictionary()
                print("âœ… íŒ¨í„´ ìºì‹œ ì¬êµ¬ì¶• ì™„ë£Œ")
                break
            elif choice == '8':
                break
            else:
                print("1-8 ì‚¬ì´ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def _run_performance_benchmark(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        import time

        test_queries = ['è¡€è™›', 'å››å›å­æ¹¯', 'äººåƒ', 'é™°è™›', 'è£œä¸­ç›Šæ°£æ¹¯']

        print("ğŸ“Š ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬:")
        total_time = 0

        for query in test_queries:
            start_time = time.time()
            results = self.search(query, k=20)
            end_time = time.time()

            query_time = end_time - start_time
            total_time += query_time

            print(f"   {query}: {len(results)}ê°œ ê²°ê³¼, {query_time:.3f}ì´ˆ")

        avg_time = total_time / len(test_queries)
        print(f"\ní‰ê·  ê²€ìƒ‰ ì‹œê°„: {avg_time:.3f}ì´ˆ")
        print(f"ì´ˆë‹¹ ì²˜ë¦¬ ê°€ëŠ¥: {1 / avg_time:.1f} ì¿¼ë¦¬")

        if self.terms_manager:
            print("\nğŸ“š ìš©ì–´ì§‘ í™•ì¥ ì„±ëŠ¥:")
            expansion_time = 0
            for query in test_queries:
                start_time = time.time()
                expansions = self.terms_manager.expand_query(
                    query, max_expansions=10)
                end_time = time.time()

                exp_time = end_time - start_time
                expansion_time += exp_time
                print(f"   {query}: {len(expansions)}ê°œ í™•ì¥, {exp_time:.3f}ì´ˆ")

            avg_exp_time = expansion_time / len(test_queries)
            print(f"\ní‰ê·  í™•ì¥ ì‹œê°„: {avg_exp_time:.3f}ì´ˆ")

    def _show_metrics_help(self):
        """ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ ë„ì›€ë§ (ê°œì„ ëœ ë²„ì „)"""
        print("\nğŸ“Š ê³ ê¸‰ ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì„¤ëª…")
        print("=" * 50)

        print("\nğŸ” ê¸°ë³¸ ì§€í‘œ:")
        print("   â€¢ ì²˜ë°© ì •ë³´: ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì²˜ë°© ê´€ë ¨ ë¬¸ì„œ ìˆ˜")
        print("   â€¢ ì´ë¡  ë‚´ìš©: ì´ë¡ ì  ë°°ê²½ì„ ë‹´ì€ ë¬¸ì„œ ìˆ˜")
        print("   â€¢ ì¶œì²˜ ë‹¤ì–‘ì„±: í™œìš©ëœ ì›ë¬¸ íŒŒì¼ì˜ ì¢…ë¥˜")
        print("   â€¢ í‰ê·  ê´€ë ¨ë„: ê²€ìƒ‰ ê²°ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜")

        print("\nğŸ“ˆ ê³ ê¸‰ ë¶„ì„:")
        print("   â€¢ ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±: ì²˜ë°©/ì´ë¡ /ë³‘ì¦/ì•½ë¬¼ ë“±ì˜ ê· í˜•")
        print("   â€¢ ê´€ë ¨ë„ ë¶„í¬: ê³ /ì¤‘/ì €í’ˆì§ˆ ê²°ê³¼ì˜ ë¹„ìœ¨")
        print("   â€¢ ëŒ€ë¶„ë¥˜/ì¤‘ë¶„ë¥˜ ë‹¤ì–‘ì„±: ë™ì˜ë³´ê° êµ¬ì¡°ë³„ ì»¤ë²„ë¦¬ì§€")
        print("   â€¢ ì§ì ‘ ë§¤ì¹­ë¥ : ê²€ìƒ‰ì–´ê°€ ì›ë¬¸ì— ì§ì ‘ í¬í•¨ëœ ë¹„ìœ¨")
        print("   â€¢ í‘œì¤€ìš©ì–´ì§‘ í™œìš©ë¥ : í‘œì¤€ìš©ì–´ ê¸°ë°˜ í™•ì¥ ì„±ê³µë¥ ")

        print("\nğŸ¯ í’ˆì§ˆ ë“±ê¸‰:")
        print("   â€¢ S+ (ìµœê³ ê¸‰): í‘œì¤€ìš©ì–´ì§‘ ì™„ì „ í™œìš©, ì™„ë²½í•œ ë‹¤ì–‘ì„±")
        print("   â€¢ S (ìµœìš°ìˆ˜): ë§¤ìš° í¬ê´„ì ì´ê³  ì •í™•í•œ ê²€ìƒ‰")
        print("   â€¢ A (ìš°ìˆ˜): ê· í˜•ì¡íŒ ì¢‹ì€ ê²€ìƒ‰ ê²°ê³¼")
        print("   â€¢ B (ì–‘í˜¸): ì ì ˆí•˜ë‚˜ ì¼ë¶€ ê°œì„  ì—¬ì§€")
        print("   â€¢ C (ë³´í†µ): ê¸°ë³¸ì  ê²°ê³¼, ê°œì„  í•„ìš”")
        print("   â€¢ D (ë¯¸í¡): ê²€ìƒ‰ ì „ëµ ì¬ê³  í•„ìš”")

        print("\nğŸ’¡ í™œìš© íŒ:")
        print("   â€¢ ë“±ê¸‰ì´ ë‚®ìœ¼ë©´ í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ì •í™•í•œ í•œì í‘œê¸° í™•ì¸")
        print("   â€¢ ì¶œì²˜ ë‹¤ì–‘ì„±ì´ ë‚®ìœ¼ë©´ ë” ì¼ë°˜ì ì¸ ìš©ì–´ ì‚¬ìš©")
        print("   â€¢ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆì„ í™œìš©í•œ ì—°ê´€ íƒìƒ‰")
        print("   â€¢ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë§¥ë½ì  ê²€ìƒ‰ í™œìš©")

    def _show_related_queries_help(self):
        """ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ë„ì›€ë§ (ê°œì„ ëœ ë²„ì „)"""
        print("\nğŸ” ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ê¸°ëŠ¥ ì„¤ëª…")
        print("=" * 50)

        print("\nğŸ’¡ ê¸°ëŠ¥ ê°œìš”:")
        print("   â€¢ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê¸°ë°˜ ì§€ëŠ¥í˜• ê´€ë ¨ ê²€ìƒ‰ì–´ ìë™ ì œì•ˆ")
        print("   â€¢ 6ë‹¨ê³„ í™•ì¥ ì „ëµì„ í†µí•œ ê¹Šì´ ìˆëŠ” ì—°ê´€ íƒìƒ‰")
        print("   â€¢ ê´€ê³„ ê·¸ë˜í”„ ê¸°ë°˜ ì˜ë¯¸ì  ì—°ê²° ë¶„ì„")
        print("   â€¢ ì¹´í…Œê³ ë¦¬ë³„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜ëœ ì œì•ˆì‚¬í•­ ì œê³µ")

        print("\nğŸ·ï¸ ì œì•ˆ ì¹´í…Œê³ ë¦¬:")
        print("   â€¢ ğŸ”¥ í•µì‹¬ ì²˜ë°©: í‘œì¤€ìš©ì–´ì§‘ì—ì„œ ì¶”ì¶œí•œ ê´€ë ¨ ì²˜ë°©ë“¤")
        print("   â€¢ ğŸ©º ê´€ë ¨ ë³‘ì¦: ê³„ì¸µêµ¬ì¡° ê¸°ë°˜ ê´€ë ¨ ì¦ìƒì´ë‚˜ ë³‘ì¦ë“¤")
        print("   â€¢ ğŸ’Š ì£¼ìš” ì•½ì¬: ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ê´€ë ¨ ì•½ì¬ë“¤")
        print("   â€¢ ğŸ“š ê´€ë ¨ ê°œë…: ì˜ë¯¸ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì´ë¡ ì´ë‚˜ ê°œë…ë“¤")
        print("   â€¢ ğŸ¯ ë§ì¶¤ ì œì•ˆ: ê³µê¸° ê´€ê³„ ë¶„ì„ ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ")

        print("\nğŸš€ 6ë‹¨ê³„ í™•ì¥ ì „ëµ:")
        print("   1. ì§ì ‘ ë§¤ì¹­: í‘œì¤€ìš©ì–´ì§‘ ì§ì ‘ ê²€ìƒ‰")
        print("   2. ê´€ê³„ ê·¸ë˜í”„: NetworkX ê¸°ë°˜ ë…¸ë“œ íƒìƒ‰")
        print("   3. ë„ë©”ì¸ ì§€ì‹: ì„ìƒ ì§€ì‹ ë² ì´ìŠ¤ í™œìš©")
        print("   4. ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì•Œê³ ë¦¬ì¦˜")
        print("   5. ê³µê¸° ê´€ê³„: ìš©ì–´ ê°„ ë™ì‹œ ì¶œí˜„ ë¶„ì„")
        print("   6. íŒ¨í„´ ë§¤ì¹­: í˜•íƒœì†Œ ë° ì ‘ì‚¬ ë¶„ì„")

        print("\nğŸ”„ ì‚¬ìš© ë°©ë²•:")
        print("   1. ê²€ìƒ‰ í›„ ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ëª©ë¡ í™•ì¸")
        print("   2. ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì—¬ ë°”ë¡œ í•´ë‹¹ ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰")
        print("   3. ìƒˆë¡œìš´ ê²€ìƒ‰ì–´ë¥¼ ì§ì ‘ ì…ë ¥í•˜ì—¬ ê²€ìƒ‰")
        print("   4. Enterë¡œ ê´€ë ¨ ê²€ìƒ‰ì–´ ê±´ë„ˆë›°ê¸°")

        print("\nâœ¨ ê³ ê¸‰ í™œìš© íŒ:")
        print("   â€¢ ì²˜ë°© ê²€ìƒ‰ í›„ â†’ êµ¬ì„± ì•½ì¬ë‚˜ ê´€ë ¨ ë³‘ì¦ ìë™ íƒìƒ‰")
        print("   â€¢ ë³‘ì¦ ê²€ìƒ‰ í›„ â†’ ì¹˜ë£Œ ì²˜ë°©ì´ë‚˜ ê°ë³„ì§„ë‹¨ ì§€ëŠ¥ ì¶”ì²œ")
        print("   â€¢ ì•½ì¬ ê²€ìƒ‰ í›„ â†’ ë°°í•©ê¸ˆê¸°ë‚˜ íš¨ëŠ¥ ë¹„êµ ì œì•ˆ")
        print("   â€¢ ì´ë¡  ê²€ìƒ‰ í›„ â†’ ì„ìƒ ì‘ìš©ì´ë‚˜ êµ¬ì²´ì  ì‚¬ë¡€ ì—°ê²°")

    def _display_traditional_results(self, query: str, results: List[Dict], answer: str) -> bool:
        """ì „í†µì ì¸ ë°©ì‹ì˜ ê²°ê³¼ í‘œì‹œ"""
        print("\n" + "=" * 50)

        if self.llm_manager and self.llm_manager.is_available():
            print("ğŸ¤– AI ë‹µë³€:")
            print("-" * 30)
            print(answer)
        else:
            print("âš ï¸ AI ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")

        print("=" * 50)
        print("ğŸ” ê²€ìƒ‰ ê²°ê³¼:")
        print("-" * 30)

        # ìƒìœ„ 20ê°œë§Œ ë¯¸ë¦¬ë³´ê¸°
        for i, result in enumerate(results[:20]):
            print(f"\n[ë¬¸ì„œ {i + 1}] (ìœ ì‚¬ë„: {result['score']:.3f})")
            print(f"ì¶œì²˜: {result['metadata']['source_file']}")
            if result['metadata'].get('BB'):
                print(f"ëŒ€ë¶„ë¥˜: {result['metadata']['BB']}")
            if result['metadata'].get('CC'):
                print(f"ì¤‘ë¶„ë¥˜: {result['metadata']['CC']}")
            print(f"ë‚´ìš©: {result['content'][:200]}...")
            print("-" * 20)

        print("=" * 50)

        # ìƒì„¸ ê²°ê³¼ ë³´ê¸° ì˜µì…˜
        show_details_input = input(
            "\nğŸ“‹ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ì²´ ë‚´ìš©ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        show_details = show_details_input in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']

        if show_details:
            self.answer_generator._display_detailed_results(results)

        return show_details

    def interactive_chat(self):
        """ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""
        if not self.is_initialized:
            print("âŒ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        llm_manager = self.llm_manager
        model_info = llm_manager.get_model_info()

        # ëª¨ë¸ë³„ ìµœì í™”ëœ Kê°’ ì„¤ì •
        recommended_k = 75  # GPT-4o-mini í‘œì¤€ ê¶Œì¥ê°’
        max_k = 100        # ìµœëŒ€ê°’

        print("\n" + "=" * 70)
        print("ğŸ¥ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ v3.0 (ì™„ì „ ê°œì„ íŒ)ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
        print(f"ğŸ¤– ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: {model_info['display_name']}")
        print(f"ğŸ“Š ê¶Œì¥ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {recommended_k}ê°œ (ìµœëŒ€ {max_k}ê°œ)")

        # ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        if self.terms_manager:
            stats = self.terms_manager.get_statistics()
            print(f"ğŸ“š í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘: {stats.get('total_terms', 0):,}ê°œ ìš©ì–´ ì—°ê²°ë¨")
            print(
                f"ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„: {stats.get('relationship_graph_nodes', 0):,}ê°œ ë…¸ë“œ")
        else:
            print("âš ï¸ í‘œì¤€ìš©ì–´ì§‘: ê¸°ë³¸ ëª¨ë“œ (ì¼ë¶€ ê¸°ëŠ¥ ì œí•œ)")

        print("\nğŸš€ v3.0 ì™„ì „ ê°œì„  ê¸°ëŠ¥:")
        print("   â€¢ ğŸ”¥ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ì™„ì „ í†µí•©")
        print("   â€¢ ğŸ•¸ï¸ ê´€ê³„ ê·¸ë˜í”„ ê¸°ë°˜ ì§€ëŠ¥í˜• ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ")
        print("   â€¢ ğŸ”¬ ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„° ë¶„ì„")
        print("   â€¢ ğŸ§  ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ í™œìš©")
        print("   â€¢ ğŸ“Š ê³ ê¸‰ ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­")
        print("   â€¢ ğŸ”§ í•˜ë“œì½”ë”© ì™„ì „ ì œê±°")
        print("\nğŸ’¡ ì¤‘ì˜í•™ ê´€ë ¨ ì§ˆë¬¸ì„ í•œêµ­ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
        print("ğŸ†˜ ë„ì›€ë§: 'help' ë˜ëŠ” 'ë„ì›€ë§' ì…ë ¥")
        print("ğŸ“š ìš©ì–´ì§‘ ì •ë³´: 'terms' ë˜ëŠ” 'ìš©ì–´ì§‘' ì…ë ¥")
        print("ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥: 'advanced' ë˜ëŠ” 'ê³ ê¸‰' ì…ë ¥")
        print("ğŸšª ì¢…ë£Œí•˜ë ¤ë©´ 'quit', 'exit', 'ì¢…ë£Œ'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

        # Kê°’ ì„¤ì •
        selected_k = self._get_k_value_choice(recommended_k, max_k)
        print(f"âœ… ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {selected_k}ê°œë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # í‘œì‹œ ì˜µì…˜ ì„¤ì •
        display_options = self._get_display_options()
        print("=" * 70 + "\n")

        # ë©”ì¸ ì±„íŒ… ë£¨í”„
        while True:
            try:
                query = input("ğŸ¤” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

                if not query:
                    continue

                if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    print("ğŸ‘‹ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                # íŠ¹ìˆ˜ ëª…ë ¹ì–´ ì²˜ë¦¬
                if self._handle_special_commands(query):
                    continue

                # ê³ ê¸‰ ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
                self._process_query(query, selected_k, display_options)

                # ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ì„ íƒ ì²˜ë¦¬
                if display_options.get('show_related_queries', False):
                    while True:
                        print("\n" + "ğŸ”" * 30)
                        related_choice = input(
                            "ğŸ”„ ê´€ë ¨ ê²€ìƒ‰ì–´ë¡œ ê³„ì† ê²€ìƒ‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n/ë²ˆí˜¸ ì…ë ¥): ").strip()

                        if related_choice.lower() in ['n', 'no', 'ã„´', 'ì•„ë‹ˆì˜¤', 'ì•„ë‹ˆìš”']:
                            break
                        elif related_choice.lower() in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
                            # ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ë‹¤ì‹œ í‘œì‹œ
                            recent_results = self.search(query, k=selected_k)
                            if recent_results:
                                if self.terms_manager:
                                    categorized_suggestions = self.answer_generator.suggest_related_queries_advanced(
                                        query, recent_results, self.terms_manager)
                                else:
                                    categorized_suggestions = self.answer_generator.suggest_related_queries(
                                        query, recent_results)

                                if categorized_suggestions:
                                    print("\nğŸ’¡ ê³ ê¸‰ ê´€ë ¨ ê²€ìƒ‰ì–´ ëª©ë¡:")
                                    suggestion_count = 1
                                    all_suggestions = []

                                    for category, suggestions in categorized_suggestions.items():
                                        if suggestions:
                                            print(f"\n{category}:")
                                            for suggestion in suggestions:
                                                print(
                                                    f"   {suggestion_count}. {suggestion}")
                                                all_suggestions.append(
                                                    suggestion)
                                                suggestion_count += 1

                                    choice_input = input(
                                        f"\nì„ íƒ (1-{len(all_suggestions)} ë˜ëŠ” ì§ì ‘ ì…ë ¥): ").strip()

                                    if choice_input.isdigit() and 1 <= int(choice_input) <= len(all_suggestions):
                                        new_query = all_suggestions[int(
                                            choice_input) - 1]
                                        print(
                                            f"âœ… '{new_query}'ë¡œ ê³ ê¸‰ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                                        self._process_query(
                                            new_query, selected_k, display_options)
                                        query = new_query  # ë‹¤ìŒ ê´€ë ¨ ê²€ìƒ‰ì„ ìœ„í•´ query ì—…ë°ì´íŠ¸
                                    elif choice_input:
                                        print(
                                            f"âœ… '{choice_input}'ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                                        self._process_query(
                                            choice_input, selected_k, display_options)
                                        query = choice_input  # ë‹¤ìŒ ê´€ë ¨ ê²€ìƒ‰ì„ ìœ„í•´ query ì—…ë°ì´íŠ¸
                                    else:
                                        break
                                else:
                                    print("ğŸ’­ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    break
                            else:
                                break
                        elif related_choice.isdigit():
                            # ì§ì ‘ ë²ˆí˜¸ ì…ë ¥ ì²˜ë¦¬
                            recent_results = self.search(query, k=selected_k)
                            if recent_results:
                                if self.terms_manager:
                                    categorized_suggestions = self.answer_generator.suggest_related_queries_advanced(
                                        query, recent_results, self.terms_manager)
                                else:
                                    categorized_suggestions = self.answer_generator.suggest_related_queries(
                                        query, recent_results)

                                all_suggestions = []
                                for suggestions in categorized_suggestions.values():
                                    all_suggestions.extend(suggestions)

                                choice_num = int(related_choice)
                                if 1 <= choice_num <= len(all_suggestions):
                                    new_query = all_suggestions[choice_num - 1]
                                    print(f"âœ… '{new_query}'ë¡œ ê³ ê¸‰ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                                    self._process_query(
                                        new_query, selected_k, display_options)
                                    query = new_query
                                else:
                                    print(
                                        f"âŒ 1-{len(all_suggestions)} ë²”ìœ„ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            break
                        else:
                            print("y, n, ë˜ëŠ” ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

                # ê³„ì† ê²€ìƒ‰í• ì§€ í™•ì¸
                if not self.answer_generator.get_continue_choice():
                    print("ğŸ‘‹ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    def check_directory_structure(self):
        """ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸ ë° ìƒì„±"""
        required_dirs = [
            self.data_path,
            self.cache_path,
            self.save_path,
            self.data_path.parent / "Results"  # Results ìƒìœ„ ë””ë ‰í† ë¦¬
        ]

        missing_dirs = []
        for dir_path in required_dirs:
            if not dir_path.exists():
                missing_dirs.append(str(dir_path))
                dir_path.mkdir(parents=True, exist_ok=True)

        if missing_dirs:
            print(f"ğŸ“ ìƒì„±ëœ ë””ë ‰í† ë¦¬: {', '.join(missing_dirs)}")

        # ë™ì˜ë³´ê° ì›ë¬¸ íŒŒì¼ í™•ì¸
        dybg_files = list(self.data_path.rglob("*.txt"))
        if not dybg_files:
            print("âš ï¸ ë™ì˜ë³´ê° ì›ë¬¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ğŸ“‚ ë‹¤ìŒ ê²½ë¡œì— ë™ì˜ë³´ê° í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë³µì‚¬í•´ì£¼ì„¸ìš”:")
            print(f"   {self.data_path}")
            return False

        print(f"âœ… {len(dybg_files)}ê°œì˜ ë™ì˜ë³´ê° ì›ë¬¸ íŒŒì¼ í™•ì¸ë¨")
        return True

    def get_system_info(self):
        """ì‹œìŠ¤í…œ ì •ë³´ ë°˜í™˜ (ê°œì„ ëœ ë²„ì „)"""
        info = {
            'initialized': self.is_initialized,
            'data_path': str(self.data_path),
            'cache_path': str(self.cache_path),
            'save_path': str(self.save_path),
            'data_hash': self.data_hash,
            'terms_manager_available': self.terms_manager is not None,
            'cache_info': self.cache_manager.get_cache_info(),
            'related_queries_enabled': True,
            'search_metrics_enabled': True,
            'advanced_features_enabled': True,
            'hardcoding_removed': True
        }

        # í‘œì¤€ìš©ì–´ì§‘ ì •ë³´
        if self.terms_manager:
            terms_stats = self.terms_manager.get_statistics()
            info['terms_manager_stats'] = terms_stats

            validation = self.terms_manager.validate_system_integrity()
            info['terms_manager_validation'] = validation

        # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì •ë³´
        if hasattr(self.document_processor, 'get_processing_statistics'):
            proc_stats = self.document_processor.get_processing_statistics()
            info['document_processor_stats'] = proc_stats

        # ê²€ìƒ‰ ì—”ì§„ ì •ë³´
        if hasattr(self.search_engine, 'get_pattern_cache_info'):
            pattern_info = self.search_engine.get_pattern_cache_info()
            info['search_engine_patterns'] = pattern_info

        if self.is_initialized and hasattr(self.search_engine, 'chunks'):
            info['chunks_count'] = len(self.search_engine.chunks)
            if hasattr(self.search_engine, 'embeddings'):
                info['embeddings_shape'] = self.search_engine.embeddings.shape
            if hasattr(self.search_engine, 'faiss_index'):
                info['faiss_index_count'] = self.search_engine.faiss_index.ntotal

        return info

    def export_system_report(self, output_path: str = None) -> str:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸°"""
        if output_path is None:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.save_path / f"system_report_{timestamp}.txt"

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ v3.0 (ì™„ì „ ê°œì„ íŒ) ìƒíƒœ ë¦¬í¬íŠ¸\n")
                f.write("=" * 80 + "\n")
                f.write(
                    f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                # ì‹œìŠ¤í…œ ì •ë³´
                info = self.get_system_info()
                f.write("ğŸ—ï¸ ì‹œìŠ¤í…œ ê¸°ë³¸ ì •ë³´\n")
                f.write("-" * 40 + "\n")
                f.write(f"ì´ˆê¸°í™” ìƒíƒœ: {'ì™„ë£Œ' if info['initialized'] else 'ë¯¸ì™„ë£Œ'}\n")
                f.write(f"ë°ì´í„° ê²½ë¡œ: {info['data_path']}\n")
                f.write(f"ìºì‹œ ê²½ë¡œ: {info['cache_path']}\n")
                f.write(f"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {info['save_path']}\n")
                f.write(
                    f"í•˜ë“œì½”ë”© ì œê±°: {'âœ… ì™„ë£Œ' if info['hardcoding_removed'] else 'âŒ'}\n")

                # í‘œì¤€ìš©ì–´ì§‘ ì •ë³´
                f.write(f"\nğŸ“š í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                if info['terms_manager_available']:
                    stats = info.get('terms_manager_stats', {})
                    validation = info.get('terms_manager_validation', {})

                    f.write(f"ì—°ê²° ìƒíƒœ: âœ… ì •ìƒ\n")
                    f.write(f"ì´ ìš©ì–´ ìˆ˜: {stats.get('total_terms', 0):,}ê°œ\n")
                    f.write(
                        f"ê´€ê³„ ê·¸ë˜í”„: {stats.get('relationship_graph_nodes', 0):,}ê°œ ë…¸ë“œ, {stats.get('relationship_graph_edges', 0):,}ê°œ ì—£ì§€\n")
                    f.write(f"ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {stats.get('semantic_clusters', 0)}ê°œ\n")
                    f.write(
                        f"ë„ë©”ì¸ ì§€ì‹ íŒ¨í„´: {stats.get('domain_knowledge_patterns', 0)}ê°œ\n")

                    f.write(f"\në¬´ê²°ì„± ê²€ì¦:\n")
                    f.write(
                        f"  ê¸°ë³¸ ì¸ë±ìŠ¤: {'âœ…' if validation.get('basic_indexes_ok', False) else 'âŒ'}\n")
                    f.write(
                        f"  ê´€ê³„ ê·¸ë˜í”„: {'âœ…' if validation.get('graph_ok', False) else 'âŒ'}\n")
                    f.write(
                        f"  ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: {'âœ…' if validation.get('clusters_ok', False) else 'âŒ'}\n")
                    f.write(
                        f"  ë„ë©”ì¸ ì§€ì‹: {'âœ…' if validation.get('domain_knowledge_ok', False) else 'âŒ'}\n")
                else:
                    f.write(f"ì—°ê²° ìƒíƒœ: âŒ ë¯¸ì—°ê²°\n")

                # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì •ë³´
                f.write(f"\nğŸ“„ ë¬¸ì„œ ì²˜ë¦¬ê¸° ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                if 'document_processor_stats' in info:
                    proc_stats = info['document_processor_stats']
                    f.write(
                        f"í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°: {'âœ…' if proc_stats.get('terms_manager_connected', False) else 'âŒ'}\n")
                    f.write(
                        f"ë™ì  TCM ìš©ì–´: {proc_stats.get('dynamic_terms_count', 0)}ê°œ\n")
                    f.write(
                        f"ì²˜ë°© íŒ¨í„´: {proc_stats.get('prescription_patterns_count', 0)}ê°œ\n")
                    f.write(
                        f"ì•½ì¬ íŒ¨í„´: {proc_stats.get('herb_patterns_count', 0)}ê°œ\n")
                    f.write(
                        f"í´ë°± ëª¨ë“œ: {'âŒ' if proc_stats.get('fallback_mode', True) else 'âœ…'}\n")

                # ê²€ìƒ‰ ì—”ì§„ ì •ë³´
                f.write(f"\nğŸ” ê²€ìƒ‰ ì—”ì§„ ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                if 'search_engine_patterns' in info:
                    pattern_info = info['search_engine_patterns']
                    f.write(
                        f"í‘œì¤€ìš©ì–´ì§‘ ì—°ê²°: {'âœ…' if pattern_info.get('terms_manager_connected', False) else 'âŒ'}\n")
                    f.write(
                        f"ì²˜ë°© ì ‘ë¯¸ì‚¬: {pattern_info.get('prescription_suffixes_count', 0)}ê°œ\n")
                    f.write(
                        f"ì¦ìƒ ì ‘ë¯¸ì‚¬: {pattern_info.get('symptom_suffixes_count', 0)}ê°œ\n")
                    f.write(
                        f"ì£¼ìš” ì•½ì¬: {pattern_info.get('major_herbs_count', 0)}ê°œ\n")
                    f.write(
                        f"ì´ë¡  ê°œë…: {pattern_info.get('theory_concepts_count', 0)}ê°œ\n")

                if info['initialized']:
                    f.write(f"\nì²­í¬ ìˆ˜: {info.get('chunks_count', 0):,}ê°œ\n")
                    f.write(f"ì„ë² ë”© ì°¨ì›: {info.get('embeddings_shape', 'N/A')}\n")
                    f.write(
                        f"FAISS ì¸ë±ìŠ¤: {info.get('faiss_index_count', 0):,}ê°œ\n")

                # LLM ì •ë³´
                model_info = self.llm_manager.get_model_info()
                f.write(f"\nğŸ¤– AI ëª¨ë¸ ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                f.write(f"ëª¨ë¸ëª…: {model_info['display_name']}\n")
                f.write(
                    f"ì—°ê²° ìƒíƒœ: {'âœ…' if model_info['is_connected'] else 'âŒ'}\n")
                f.write(f"ìµœì  Kê°’: {model_info['optimal_k']}\n")
                f.write(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {model_info['max_context_tokens']:,} í† í°\n")

                # ìºì‹œ ì •ë³´
                cache_info = info['cache_info']
                f.write(f"\nğŸ’¾ ìºì‹œ ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                f.write(
                    f"ìºì‹œ ì™„ì„±ë„: {'ì™„ì „' if cache_info.get('cache_complete', False) else 'ë¶ˆì™„ì „'}\n")
                if 'chunks_count' in cache_info:
                    f.write(f"ìºì‹œëœ ì²­í¬: {cache_info['chunks_count']:,}ê°œ\n")
                    f.write(f"ìƒì„± ì‹œê°„: {cache_info.get('timestamp', 'N/A')}\n")

                # ê³ ê¸‰ ê¸°ëŠ¥ ìƒíƒœ
                f.write(f"\nğŸš€ ê³ ê¸‰ ê¸°ëŠ¥ ìƒíƒœ\n")
                f.write("-" * 40 + "\n")
                f.write(
                    f"ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ: {'âœ…' if info['related_queries_enabled'] else 'âŒ'}\n")
                f.write(
                    f"ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­: {'âœ…' if info['search_metrics_enabled'] else 'âŒ'}\n")
                f.write(
                    f"ê³ ê¸‰ ê¸°ëŠ¥: {'âœ…' if info['advanced_features_enabled'] else 'âŒ'}\n")
                f.write(f"ë™ì  íŒ¨í„´ ì‹œìŠ¤í…œ: âœ…\n")
                f.write(f"ê´€ê³„ ê·¸ë˜í”„ ë¶„ì„: âœ…\n")
                f.write(f"ì˜ë¯¸ í´ëŸ¬ìŠ¤í„°: âœ…\n")
                f.write(f"ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤: âœ…\n")

            print(f"ğŸ“„ ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            return str(output_path)

        except Exception as e:
            print(f"âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def run_system_diagnostics(self):
        """ì‹œìŠ¤í…œ ì§„ë‹¨ ì‹¤í–‰"""
        print("\nğŸ” ì™„ì „ ê°œì„ ëœ ì‹œìŠ¤í…œ ì§„ë‹¨ ì‹¤í–‰ ì¤‘...")

        diagnostics = {
            'overall_health': 'healthy',
            'issues': [],
            'recommendations': [],
            'performance_metrics': {}
        }

        # 1. í‘œì¤€ìš©ì–´ì§‘ ì§„ë‹¨
        if self.terms_manager:
            validation = self.terms_manager.validate_system_integrity()
            if not validation['basic_indexes_ok']:
                diagnostics['issues'].append("í‘œì¤€ìš©ì–´ì§‘ ê¸°ë³¸ ì¸ë±ìŠ¤ ì˜¤ë¥˜")
                diagnostics['overall_health'] = 'warning'

            if validation['errors']:
                diagnostics['issues'].extend(validation['errors'])
                diagnostics['overall_health'] = 'critical'
        else:
            diagnostics['issues'].append("í‘œì¤€ìš©ì–´ì§‘ì´ ì—°ê²°ë˜ì§€ ì•ŠìŒ")
            diagnostics['recommendations'].append(
                "hmedicalterms.json íŒŒì¼ í™•ì¸ í•„ìš”")
            diagnostics['overall_health'] = 'warning'

        # 2. LLM ì—°ê²° ì§„ë‹¨
        if not self.llm_manager.is_available():
            diagnostics['issues'].append("LLM ì—°ê²° ì‹¤íŒ¨")
            diagnostics['recommendations'].append("OpenAI API í‚¤ í™•ì¸ í•„ìš”")
            diagnostics['overall_health'] = 'critical'

        # 3. ìºì‹œ ì‹œìŠ¤í…œ ì§„ë‹¨
        cache_info = self.cache_manager.get_cache_info()
        if not cache_info.get('cache_complete', False):
            diagnostics['issues'].append("ìºì‹œ ë¶ˆì™„ì „")
            diagnostics['recommendations'].append("ì‹œìŠ¤í…œ ì¬ì´ˆê¸°í™” ê¶Œì¥")

        # 4. ì„±ëŠ¥ ì§„ë‹¨
        if self.is_initialized:
            import time
            start_time = time.time()
            test_results = self.search("è¡€è™›", k=10)
            search_time = time.time() - start_time

            diagnostics['performance_metrics']['search_time'] = search_time
            diagnostics['performance_metrics']['result_count'] = len(
                test_results)

            if search_time > 5.0:
                diagnostics['issues'].append("ê²€ìƒ‰ ì‘ë‹µ ì‹œê°„ ëŠë¦¼")
                diagnostics['recommendations'].append("ìºì‹œ ì¬êµ¬ì¶• ë˜ëŠ” ì¸ë±ìŠ¤ ìµœì í™” í•„ìš”")

        # 5. ì „ì²´ ê±´ê°•ë„ í‰ê°€
        if len(diagnostics['issues']) == 0:
            diagnostics['overall_health'] = 'excellent'
        elif len(diagnostics['issues']) <= 2 and diagnostics['overall_health'] != 'critical':
            diagnostics['overall_health'] = 'good'
        elif diagnostics['overall_health'] != 'critical':
            diagnostics['overall_health'] = 'warning'

        # ê²°ê³¼ ì¶œë ¥
        health_colors = {
            'excellent': 'ğŸŸ¢',
            'good': 'ğŸŸ¢',
            'healthy': 'ğŸŸ¡',
            'warning': 'ğŸŸ¡',
            'critical': 'ğŸ”´'
        }

        print(
            f"\n{health_colors[diagnostics['overall_health']]} ì‹œìŠ¤í…œ ê±´ê°•ë„: {diagnostics['overall_health'].upper()}")

        if diagnostics['issues']:
            print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in diagnostics['issues']:
                print(f"   - {issue}")

        if diagnostics['recommendations']:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in diagnostics['recommendations']:
                print(f"   - {rec}")

        if diagnostics['performance_metrics']:
            print(f"\nğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
            for metric, value in diagnostics['performance_metrics'].items():
                if metric == 'search_time':
                    print(f"   ê²€ìƒ‰ ì‹œê°„: {value:.3f}ì´ˆ")
                else:
                    print(f"   {metric}: {value}")

        print("âœ… ì‹œìŠ¤í…œ ì§„ë‹¨ ì™„ë£Œ")
        return diagnostics


def main():
    """ë©”ì¸ í•¨ìˆ˜ (ì™„ì „ ê°œì„ ëœ ë²„ì „)"""
    try:
        print("ğŸš€ ë™ì˜ë³´ê° RAG ì‹œìŠ¤í…œ v3.0 (ì™„ì „ ê°œì„ íŒ) ì‹œì‘")
        print("=" * 70)
        print("ğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        print("   â€¢ ğŸ”¥ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ì™„ì „ í†µí•© (7,105ê°œ ìš©ì–´)")
        print("   â€¢ ğŸ•¸ï¸ NetworkX ê¸°ë°˜ ê´€ê³„ ê·¸ë˜í”„ (ìš©ì–´ ê°„ ì—°ê´€ì„± ë¶„ì„)")
        print("   â€¢ ğŸ”¬ ì˜ë¯¸ì  í´ëŸ¬ìŠ¤í„°ë§ (ì»¤ë®¤ë‹ˆí‹° íƒì§€ ì•Œê³ ë¦¬ì¦˜)")
        print("   â€¢ ğŸ§  ë„ë©”ì¸ ì§€ì‹ ë² ì´ìŠ¤ (ì„ìƒ ì¤‘ì‹¬ ì²´ê³„ì  ì§€ì‹)")
        print("   â€¢ ğŸ¯ 6ë‹¨ê³„ ì§€ëŠ¥í˜• í™•ì¥ ì „ëµ")
        print("   â€¢ ğŸ“Š ê³ ê¸‰ ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­")
        print("   â€¢ ğŸ”§ í•˜ë“œì½”ë”© ì™„ì „ ì œê±°")
        print("   â€¢ âš¡ ë™ì  íŒ¨í„´ ìƒì„± ì‹œìŠ¤í…œ")

        print("\nğŸ” ê³ ê¸‰ ê²€ìƒ‰ ê¸°ëŠ¥:")
        print("   â€¢ í‘œì¤€ìš©ì–´ì§‘ ê¸°ë°˜ ì •í™•í•œ ìš©ì–´ ë§¤ì¹­")
        print("   â€¢ ê´€ê³„ ê·¸ë˜í”„ íƒìƒ‰ì„ í†µí•œ ì—°ê´€ ìš©ì–´ ë°œê²¬")
        print("   â€¢ ì˜ë¯¸ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ìœ ì‚¬ ê°œë… íƒìƒ‰")
        print("   â€¢ ë„ë©”ì¸ ì§€ì‹ í™œìš© ë§¥ë½ì  ê²€ìƒ‰")
        print("   â€¢ ê³µê¸° ê´€ê³„ ë¶„ì„ ê¸°ë°˜ ì¶”ì²œ")
        print("   â€¢ íŒ¨í„´ ë§¤ì¹­ì„ í†µí•œ í˜•íƒœì  ìœ ì‚¬ì„± ë°œê²¬")

        # ì‹œì‘ ì˜µì…˜ ì„ íƒ
        print("\nğŸ”§ ì‹œì‘ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ê³ ì† ìºì‹œ ë¡œë“œ (ê¶Œì¥)")
        print("2. ì™„ì „ ì¬êµ¬ì¶• (ì´ˆê¸° ì„¤ì • ë˜ëŠ” ë°ì´í„° ë³€ê²½ì‹œ)")
        print("3. ì‹œìŠ¤í…œ ì§„ë‹¨ í›„ ê²°ì •")

        while True:
            choice = input("ì„ íƒ (1/2/3): ").strip()
            if choice == '1':
                force_rebuild = False
                break
            elif choice == '2':
                force_rebuild = True
                break
            elif choice == '3':
                # ê°„ë‹¨í•œ ì‚¬ì „ ì§„ë‹¨
                print("\nğŸ” ì‚¬ì „ ì‹œìŠ¤í…œ ì§„ë‹¨ ì¤‘...")
                rag_system = DonguiRAGSystemImproved()
                diagnostics = rag_system.run_system_diagnostics()

                if diagnostics['overall_health'] in ['excellent', 'good', 'healthy']:
                    print("ğŸ’¡ ì‹œìŠ¤í…œ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ìºì‹œ ë¡œë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
                    force_rebuild = False
                else:
                    print("ğŸ’¡ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì™„ì „ ì¬êµ¬ì¶•ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                    force_rebuild = True
                break
            else:
                print("1, 2, ë˜ëŠ” 3ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì™„ì „ ê°œì„ ëœ ë²„ì „)
        if 'rag_system' not in locals():
            rag_system = DonguiRAGSystemImproved()

        rag_system.initialize_system(force_rebuild=force_rebuild)

        # ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„± (ì˜µì…˜)
        print("\nğŸ“„ ì‹œìŠ¤í…œ ìƒíƒœ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
        report_choice = input().strip().lower()
        if report_choice in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
            report_path = rag_system.export_system_report()
            if report_path:
                print(f"âœ… ì‹œìŠ¤í…œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_path}")

        # ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì‹œì‘
        rag_system.interactive_chat()

    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("   1. OpenAI API í‚¤ í™•ì¸ (.env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜)")
        print("   2. í•„ìˆ˜ ëª¨ë“ˆ ì„¤ì¹˜ í™•ì¸:")
        print("      - document_processor_improved.py")
        print("      - search_engine_improved.py")
        print("      - answer_generator_improved.py")
        print("      - medical_terms_manager_improved.py")
        print("   3. í‘œì¤€ìš©ì–´ì§‘ íŒŒì¼ í™•ì¸ (hmedicalterms.json)")
        print("   4. ë°ì´í„° ê²½ë¡œ í™•ì¸ ë° ê¶Œí•œ ì„¤ì •")
        print("   5. Python ì˜ì¡´ì„± ì„¤ì¹˜ (requirements.txt)")
        sys.exit(1)


if __name__ == "__main__":
    main()
