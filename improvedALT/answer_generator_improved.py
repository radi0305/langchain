#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë‹µë³€ ìƒì„± ëª¨ë“ˆ - answer_generator.py (ê°œì„ ëœ ë²„ì „ - í•˜ë“œì½”ë”© ì œê±°)
LLMì„ ì´ìš©í•œ ë‹µë³€ ìƒì„±ê³¼ ê²°ê³¼ ì €ì¥ì„ ë‹´ë‹¹
í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê¸°ë°˜ìœ¼ë¡œ ë™ì  íŒ¨í„´ ìƒì„± ë° ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ
"""

import os
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Set
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings("ignore")


class AnswerGenerator:
    def __init__(self, llm_manager=None, save_path: str = "/Users/radi/Projects/langchainDATA/Results/DYBGsearch", terms_manager=None):
        """ë‹µë³€ ìƒì„±ê¸° ì´ˆê¸°í™” (ê°œì„ ëœ ë²„ì „)"""
        self.llm_manager = llm_manager
        self.save_path = Path(save_path)
        self.save_path.mkdir(parents=True, exist_ok=True)

        # í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ì¶”ê°€
        self.terms_manager = terms_manager

        # ê´€ë ¨ ê²€ìƒ‰ì–´ ì¶”ì¶œì„ ìœ„í•œ íŒ¨í„´ë“¤
        self.prescription_patterns = [
            r'([ä¸€-é¾¯]{2,6}[æ¹¯æ•£ä¸¸è†])',  # ì²˜ë°©ëª… íŒ¨í„´
            r'([ä¸€-é¾¯]{3,8})'           # ì¼ë°˜ ì²˜ë°©ëª…
        ]

        self.symptom_patterns = [
            r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',    # ì¦ìƒ/ë³‘ì¦ íŒ¨í„´
            r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',     # í—ˆì‹¤ íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4}[ç—›])',       # í†µì¦ íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4}[ç†±å¯’])',     # í•œì—´ íŒ¨í„´
        ]

        self.herb_patterns = [
            r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒèŒ¯è‹“èŠªæœ®])',  # ì•½ì¬ëª… íŒ¨í„´
            r'([ä¸€-é¾¯]{2,4})',                        # ì¼ë°˜ ì•½ì¬ëª…
        ]

    def set_terms_manager(self, terms_manager):
        """í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ì„¤ì •"""
        self.terms_manager = terms_manager
        # ìºì‹œ ë¬´íš¨í™”
        self._invalidate_cache()

    def _invalidate_cache(self):
        """íŒ¨í„´ ìºì‹œ ë¬´íš¨í™”"""
        self._prescription_patterns_cache = None
        self._symptom_patterns_cache = None
        self._herb_patterns_cache = None
        self._cache_timestamp = None

    def _is_cache_valid(self) -> bool:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸"""
        if self._cache_timestamp is None:
            return False

        from datetime import timedelta
        now = datetime.now()
        cache_age = now - self._cache_timestamp
        return cache_age < timedelta(hours=self._cache_validity_hours)

    def _get_prescription_patterns(self) -> List[str]:
        """ì²˜ë°© íŒ¨í„´ ë™ì  ìƒì„± (ìš©ì–´ì§‘ ê¸°ë°˜)"""
        if self._prescription_patterns_cache and self._is_cache_valid():
            return self._prescription_patterns_cache

        patterns = []

        try:
            if self.terms_manager:
                # ìš©ì–´ì§‘ì—ì„œ ì²˜ë°© ë¶„ë¥˜ ì¶”ì¶œ
                prescriptions = self.terms_manager.search_by_category('ì²˜ë°©')

                # ì²˜ë°© ì¢…ë¥˜ë³„ íŒ¨í„´ ë¶„ì„
                suffixes = set()
                for prescription in prescriptions:
                    hanja_name = prescription.get('ìš©ì–´ëª…_í•œì', '')
                    if hanja_name:
                        # ì²˜ë°© ì ‘ë¯¸ì‚¬ ì¶”ì¶œ
                        if hanja_name.endswith(('æ¹¯', 'æ•£', 'ä¸¸', 'è†', 'é£®', 'ä¸¹', 'éœ²')):
                            suffixes.add(hanja_name[-1])

                # ë™ì  íŒ¨í„´ ìƒì„±
                for suffix in suffixes:
                    patterns.append(f'([ä¸€-é¾¯]{{2,8}}{suffix})')

                # ì¼ë°˜ì ì¸ ì²˜ë°©ëª… íŒ¨í„´ë„ ì¶”ê°€
                patterns.append(r'([ä¸€-é¾¯]{3,8}æ–¹)')
                patterns.append(r'([ä¸€-é¾¯]{3,8}åŠ‘)')

            # í´ë°±: ê¸°ë³¸ íŒ¨í„´
            if not patterns:
                patterns = [
                    r'([ä¸€-é¾¯]{2,6}[æ¹¯æ•£ä¸¸è†])',
                    r'([ä¸€-é¾¯]{3,8})'
                ]

        except Exception as e:
            print(f"âš ï¸ ì²˜ë°© íŒ¨í„´ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± íŒ¨í„´
            patterns = [
                r'([ä¸€-é¾¯]{2,6}[æ¹¯æ•£ä¸¸è†])',
                r'([ä¸€-é¾¯]{3,8})'
            ]

        # ìºì‹œ ì €ì¥
        self._prescription_patterns_cache = patterns
        self._cache_timestamp = datetime.now()

        return patterns

    def _get_symptom_patterns(self) -> List[str]:
        """ì¦ìƒ/ë³‘ì¦ íŒ¨í„´ ë™ì  ìƒì„± (ìš©ì–´ì§‘ ê¸°ë°˜)"""
        if self._symptom_patterns_cache and self._is_cache_valid():
            return self._symptom_patterns_cache

        patterns = []

        try:
            if self.terms_manager:
                # ìš©ì–´ì§‘ì—ì„œ ë³‘ì¦ ë¶„ë¥˜ ì¶”ì¶œ
                symptoms = self.terms_manager.search_by_category('ë³‘ì¦')

                # ë³‘ì¦ ì ‘ë¯¸ì‚¬ ë¶„ì„
                suffixes = set()
                for symptom in symptoms:
                    hanja_name = symptom.get('ìš©ì–´ëª…_í•œì', '')
                    if hanja_name:
                        # ë³‘ì¦ ì ‘ë¯¸ì‚¬ ì¶”ì¶œ
                        if hanja_name.endswith(('è­‰', 'ç—…', 'ç—‡', 'ç—›', 'è™›', 'å¯¦', 'ç†±', 'å¯’')):
                            suffixes.add(hanja_name[-1])

                # ë™ì  íŒ¨í„´ ìƒì„±
                for suffix in suffixes:
                    if suffix in ['è™›', 'å¯¦']:
                        patterns.append(f'([ä¸€-é¾¯]{{1,4}}{suffix})')
                    elif suffix in ['ç—›']:
                        patterns.append(f'([ä¸€-é¾¯]{{2,4}}{suffix})')
                    else:
                        patterns.append(f'([ä¸€-é¾¯]{{2,5}}{suffix})')

            # í´ë°±: ê¸°ë³¸ íŒ¨í„´
            if not patterns:
                patterns = [
                    r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',
                    r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',
                    r'([ä¸€-é¾¯]{2,4}[ç—›])',
                    r'([ä¸€-é¾¯]{2,4}[ç†±å¯’])'
                ]

        except Exception as e:
            print(f"âš ï¸ ì¦ìƒ íŒ¨í„´ ìƒì„± ì‹¤íŒ¨: {e}")
            patterns = [
                r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',
                r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',
                r'([ä¸€-é¾¯]{2,4}[ç—›])',
                r'([ä¸€-é¾¯]{2,4}[ç†±å¯’])'
            ]

        # ìºì‹œ ì €ì¥
        self._symptom_patterns_cache = patterns
        if not self._cache_timestamp:
            self._cache_timestamp = datetime.now()

        return patterns

    def _get_herb_patterns(self) -> List[str]:
        """ì•½ì¬ íŒ¨í„´ ë™ì  ìƒì„± (ìš©ì–´ì§‘ ê¸°ë°˜)"""
        if self._herb_patterns_cache and self._is_cache_valid():
            return self._herb_patterns_cache

        patterns = []

        try:
            if self.terms_manager:
                # ìš©ì–´ì§‘ì—ì„œ ì•½ë¬¼ ë¶„ë¥˜ ì¶”ì¶œ
                herbs = self.terms_manager.search_by_category('ì•½ë¬¼')

                # ì•½ì¬ëª… íŠ¹ì„± ë¶„ì„
                common_chars = set()
                for herb in herbs[:100]:  # ìƒìœ„ 100ê°œë§Œ ë¶„ì„
                    hanja_name = herb.get('ìš©ì–´ëª…_í•œì', '')
                    if hanja_name and len(hanja_name) >= 2:
                        # ë§ˆì§€ë§‰ ê¸€ì ìˆ˜ì§‘ (ì•½ì¬ íŠ¹ì„±)
                        common_chars.add(hanja_name[-1])

                # ë¹ˆë„ ë†’ì€ ì•½ì¬ íŠ¹ì„± ê¸€ìë“¤ë¡œ íŒ¨í„´ ìƒì„±
                herb_chars = ['åƒ', 'èŠ', 'æ­¸', 'èŠ', 'åœ°', 'é»ƒ',
                              'èŒ¯', 'è‹“', 'èŠª', 'æœ®', 'è‰', 'çš®', 'ä»', 'å­']

                for char in herb_chars:
                    if char in common_chars:
                        patterns.append(f'([ä¸€-é¾¯]{{2,4}}{char})')

                # ì¼ë°˜ì ì¸ ì•½ì¬ íŒ¨í„´
                patterns.append(r'([ä¸€-é¾¯]{2,4})')

            # í´ë°±: ê¸°ë³¸ íŒ¨í„´
            if not patterns:
                patterns = [
                    r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒèŒ¯è‹“èŠªæœ®])',
                    r'([ä¸€-é¾¯]{2,4})'
                ]

        except Exception as e:
            print(f"âš ï¸ ì•½ì¬ íŒ¨í„´ ìƒì„± ì‹¤íŒ¨: {e}")
            patterns = [
                r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒèŒ¯è‹“èŠªæœ®])',
                r'([ä¸€-é¾¯]{2,4})'
            ]

        # ìºì‹œ ì €ì¥
        self._herb_patterns_cache = patterns
        if not self._cache_timestamp:
            self._cache_timestamp = datetime.now()

        return patterns

    def _get_major_herbs_from_terms(self) -> List[str]:
        """ìš©ì–´ì§‘ì—ì„œ ì£¼ìš” ì•½ì¬ ì¶”ì¶œ"""
        try:
            if not self.terms_manager:
                return self._get_fallback_herbs()

            herbs = self.terms_manager.search_by_category('ì•½ë¬¼')
            major_herbs = []

            # ìƒìœ„ 50ê°œ ì•½ì¬ ì¶”ì¶œ
            for herb in herbs[:50]:
                hanja_name = herb.get('ìš©ì–´ëª…_í•œì', '')
                if hanja_name:
                    major_herbs.append(hanja_name)

            return major_herbs if major_herbs else self._get_fallback_herbs()

        except Exception as e:
            print(f"âš ï¸ ìš©ì–´ì§‘ì—ì„œ ì•½ì¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_herbs()

    def _get_key_concepts_from_terms(self) -> List[str]:
        """ìš©ì–´ì§‘ì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ"""
        try:
            if not self.terms_manager:
                return self._get_fallback_concepts()

            concepts = []

            # ìƒë¦¬, ì´ë¡  ë¶„ë¥˜ì—ì„œ ì¶”ì¶œ
            for category in ['ìƒë¦¬', 'ì´ë¡ ', 'ë³€ì¦']:
                terms = self.terms_manager.search_by_category(category)
                for term in terms[:20]:  # ê° ì¹´í…Œê³ ë¦¬ë‹¹ 20ê°œ
                    hanja_name = term.get('ìš©ì–´ëª…_í•œì', '')
                    if hanja_name:
                        concepts.append(hanja_name)

            return concepts if concepts else self._get_fallback_concepts()

        except Exception as e:
            print(f"âš ï¸ ìš©ì–´ì§‘ì—ì„œ ê°œë… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_concepts()

    def _get_symptom_keywords_from_terms(self) -> List[str]:
        """ìš©ì–´ì§‘ì—ì„œ ì¦ìƒ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            if not self.terms_manager:
                return self._get_fallback_symptoms()

            symptoms = self.terms_manager.search_by_category('ë³‘ì¦')
            symptom_keywords = []

            for symptom in symptoms[:30]:  # ìƒìœ„ 30ê°œ
                hanja_name = symptom.get('ìš©ì–´ëª…_í•œì', '')
                if hanja_name:
                    symptom_keywords.append(hanja_name)

            return symptom_keywords if symptom_keywords else self._get_fallback_symptoms()

        except Exception as e:
            print(f"âš ï¸ ìš©ì–´ì§‘ì—ì„œ ì¦ìƒ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return self._get_fallback_symptoms()

    def _get_fallback_herbs(self) -> List[str]:
        """í´ë°±ìš© ê¸°ë³¸ ì•½ì¬ ë¦¬ìŠ¤íŠ¸"""
        return [
            'äººåƒ', 'ç•¶æ­¸', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°é»ƒ', 'ç”Ÿåœ°é»ƒ', 'é»ƒèŠª', 'ç™½æœ®',
            'èŒ¯è‹“', 'ç”˜è‰', 'é™³çš®', 'åŠå¤', 'æ³å¯¦', 'åšæœ´', 'æ¡”æ¢—', 'æä»',
            'éº¥é–€å†¬', 'äº”å‘³å­', 'å±±è—¥', 'èŒ¯ç¥', 'é å¿—', 'çŸ³è–è’²', 'æœ±ç ‚', 'é¾éª¨',
            'ç‰¡è £', 'é…¸æ£—ä»', 'æŸå­ä»', 'é˜¿è† ', 'åœ°éª¨çš®', 'çŸ¥æ¯', 'é»ƒæŸ', 'å±±èŒ±è¸'
        ]

    def _get_fallback_concepts(self) -> List[str]:
        """í´ë°±ìš© ê¸°ë³¸ ê°œë… ë¦¬ìŠ¤íŠ¸"""
        return [
            'é™°é™½', 'äº”è¡Œ', 'è‡Ÿè…‘', 'æ°£è¡€', 'ç¶“çµ¡', 'ç²¾æ°£ç¥', 'å›è‡£ä½ä½¿',
            'å››è±¡', 'å…«ç¶±', 'å…­ç¶“', 'ç‡Ÿè¡›', 'ä¸‰ç„¦', 'å‘½é–€', 'å…ƒæ°£', 'çœŸé™°',
            'ç«ç¥', 'æº«è£œ', 'æ»‹é™°', 'ç†æ°£', 'æ´»è¡€', 'åŒ–ç—°', 'ç¥›æ¿•', 'æ¸…ç†±'
        ]

    def _get_fallback_symptoms(self) -> List[str]:
        """í´ë°±ìš© ê¸°ë³¸ ì¦ìƒ ë¦¬ìŠ¤íŠ¸"""
        return [
            'é©šæ‚¸', 'å¥å¿˜', 'çœ©æšˆ', 'å¤±çœ ', 'è™›å‹', 'è¡€è™›', 'æ°£è™›', 'é™°è™›',
            'é™½è™›', 'è„¾èƒƒè™›', 'å¿ƒæ‚¸', 'ä¸å¯', 'é ­ç—›', 'è…¹ç—›', 'èƒ¸ç—›'
        ]

    def generate_answer(self, query: str, search_results: List[Dict]) -> str:
        """ë‹µë³€ ìƒì„± (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ ê°•í™”)"""
        if not self.llm_manager or not self.llm_manager.is_available():
            return "LLMì´ ì—°ê²°ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ë¬¸ì„œ ë²ˆí˜¸ì™€ í•¨ê»˜)
        context_parts = []
        for i, result in enumerate(search_results):
            # ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ëª…í™•íˆ í¬í•¨
            context_parts.append(
                f"[ë¬¸ì„œ {i + 1}]\nì¶œì²˜: {result['metadata'].get('source_file', 'unknown')}\në‚´ìš©: {result['content']}")

        # LLM ê´€ë¦¬ìë¥¼ í†µí•œ ì»¨í…ìŠ¤íŠ¸ ìµœì í™”
        optimized_context_parts = self.llm_manager.optimize_context_for_model(
            context_parts)
        context = '\n\n'.join(optimized_context_parts)

        # ê°•í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = self._get_enhanced_system_prompt()

        # ê°•í™”ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        user_prompt = self._get_enhanced_user_prompt(
            query, context, len(search_results))

        # ë©”ì‹œì§€ êµ¬ì„± ë° ì‘ë‹µ ìƒì„±
        try:
            from langchain_core.messages import SystemMessage, HumanMessage
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
        except ImportError:
            # í´ë°±: ê¸°ë³¸ ë©”ì‹œì§€ í˜•ì‹
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

        return self.llm_manager.generate_response(messages)

    def _extract_prescriptions_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        prescriptions = []
        prescription_counts = Counter()

        for result in results:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì²˜ë°©ëª… ì§ì ‘ ì¶”ì¶œ
            if result['metadata'].get('prescription_name'):
                prescription_counts[result['metadata']
                                    ['prescription_name']] += 3

            # ë‚´ìš©ì—ì„œ ì²˜ë°©ëª… íŒ¨í„´ ë§¤ì¹­ (ë™ì  íŒ¨í„´ ì‚¬ìš©)
            content = result['content']
            patterns = self._get_prescription_patterns()

            for pattern in patterns:
                try:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        if len(match) >= 3:  # ìµœì†Œ 3ê¸€ì ì´ìƒ
                            prescription_counts[match] += 1
                except re.error:
                    continue

        # ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ í•­ëª© ë°˜í™˜
        return [name for name, count in prescription_counts.most_common(6) if count >= 2]

    def _extract_symptoms_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¦ìƒ/ë³‘ì¦ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        symptoms = []
        symptom_counts = Counter()

        for result in results:
            content = result['content']

            # ì¦ìƒ/ë³‘ì¦ íŒ¨í„´ ë§¤ì¹­ (ë™ì  íŒ¨í„´ ì‚¬ìš©)
            patterns = self._get_symptom_patterns()

            for pattern in patterns:
                try:
                    matches = re.findall(pattern, content)
                    for match in matches:
                        if len(match) >= 2:
                            symptom_counts[match] += 1
                except re.error:
                    continue

            # ìš©ì–´ì§‘ ê¸°ë°˜ ì¦ìƒ í‚¤ì›Œë“œ ë§¤ì¹­
            symptom_keywords = self._get_symptom_keywords_from_terms()
            for keyword in symptom_keywords:
                if keyword in content:
                    symptom_counts[keyword] += 2

        return [symptom for symptom, count in symptom_counts.most_common(8) if count >= 2]

    def _extract_herbs_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì•½ì¬ëª… ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        herbs = []
        herb_counts = Counter()

        # ìš©ì–´ì§‘ì—ì„œ ì£¼ìš” ì•½ì¬ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        major_herbs = self._get_major_herbs_from_terms()

        for result in results:
            content = result['content']

            # ì£¼ìš” ì•½ì¬ ê²€ìƒ‰
            for herb in major_herbs:
                if herb in content:
                    # ì²˜ë°© êµ¬ì„±ì— ë‚˜ì˜¤ë©´ ê°€ì¤‘ì¹˜ ë¶€ì—¬
                    if any(keyword in content for keyword in ['å³', 'å³çˆ²æœ«', 'å³å‰‰', 'å³çˆ²']):
                        herb_counts[herb] += 3
                    else:
                        herb_counts[herb] += 1

        return [herb for herb, count in herb_counts.most_common(8) if count >= 2]

    def _extract_concepts_from_results(self, results: List[Dict]) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì´ë¡ /ê°œë… ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        concepts = []
        concept_counts = Counter()

        # ìš©ì–´ì§‘ì—ì„œ í•µì‹¬ ê°œë…ë“¤ ê°€ì ¸ì˜¤ê¸°
        key_concepts = self._get_key_concepts_from_terms()

        for result in results:
            content = result['content']
            bb = result['metadata'].get('BB', '')
            cc = result['metadata'].get('CC', '')

            # ëŒ€ë¶„ë¥˜/ì¤‘ë¶„ë¥˜ì—ì„œ ê°œë… ì¶”ì¶œ
            if bb and bb not in ['', 'unknown']:
                concept_counts[bb] += 2
            if cc and cc not in ['', 'unknown']:
                concept_counts[cc] += 1

            # í•µì‹¬ ê°œë… ë§¤ì¹­
            for concept in key_concepts:
                if concept in content:
                    concept_counts[concept] += 1

        return [concept for concept, count in concept_counts.most_common(5) if count >= 2]

    def _get_contextual_suggestions(self, query: str, results: List[Dict]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§ì¶¤ ì œì•ˆ (ìš©ì–´ì§‘ ì—°ë™ ê°œì„ )"""
        suggestions = []

        # 1. ìš©ì–´ì§‘ ê¸°ë°˜ ì¿¼ë¦¬ ë¶„ì„
        try:
            if self.terms_manager:
                # ì¿¼ë¦¬ì˜ ìš©ì–´ì§‘ ì •ë³´ ì¡°íšŒ
                query_info = self.terms_manager.get_term_info(query)
                if query_info:
                    category = query_info.get('ë¶„ë¥˜', '')

                    # ë¶„ë¥˜ë³„ ë§ì¶¤ ì œì•ˆ
                    if category == 'ë³‘ì¦':
                        suggestions.extend(['ì¹˜ë£Œë°©ë²•', 'ê°ë³„ì§„ë‹¨', 'ë³‘ë¦¬ê¸°ì „'])
                    elif category == 'ì²˜ë°©':
                        suggestions.extend(['ê°€ê°ë°©', 'ë°°í•©ê¸ˆê¸°', 'ìš©ë²•ìš©ëŸ‰'])
                    elif category == 'ì•½ë¬¼':
                        suggestions.extend(['ì•½ì„±', 'ê·€ê²½', 'íš¨ëŠ¥ì£¼ì¹˜', 'ë°°í•©'])
                    elif category in ['ìƒë¦¬', 'ì´ë¡ ']:
                        suggestions.extend(['ì„ìƒì‘ìš©', 'ê´€ë ¨ì´ë¡ ', 'ì‹¤ìš©ë°©ë²•'])

                # ê´€ë ¨ ìš©ì–´ ì¶”ê°€
                related_terms = self.terms_manager.get_related_terms(query)
                suggestions.extend(related_terms[:3])

        except Exception as e:
            print(f"âš ï¸ ìš©ì–´ì§‘ ê¸°ë°˜ ì œì•ˆ ì‹¤íŒ¨: {e}")

        # 2. ì¿¼ë¦¬ ìœ í˜• ë¶„ì„ ê¸°ë°˜ ì œì•ˆ (í´ë°±)
        if 'è™›' in query:
            suggestions.extend(['è£œç›Š', 'æº«é™½', 'æ»‹é™°', 'ç›Šæ°£'])
        elif 'æ¹¯' in query:
            suggestions.extend(['åŠ æ¸›æ–¹', 'ë°°í•©ê¸ˆê¸°', 'ìš©ë²•ìš©ëŸ‰'])
        elif 'ç—…' in query or 'è­‰' in query:
            suggestions.extend(['æ²»ç™‚æ–¹ë²•', 'ê°ë³„ì§„ë‹¨', 'ë³‘ë¦¬ê¸°ì „'])
        elif any(herb in query for herb in ['äººåƒ', 'ç•¶æ­¸', 'å·èŠ']):
            suggestions.extend(['ì•½ì„±', 'ê·€ê²½', 'íš¨ëŠ¥ì£¼ì¹˜', 'ë°°í•©'])

        # 3. ê²€ìƒ‰ ê²°ê³¼ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì œì•ˆ
        source_files = set()
        bb_categories = set()

        for result in results:
            source_file = result['metadata'].get('source_file', '')
            bb = result['metadata'].get('BB', '')

            if source_file:
                # íŒŒì¼ëª…ì—ì„œ ê´€ë ¨ ì£¼ì œ ì¶”ì¶œ
                if 'ë‚´ê²½í¸' in source_file:
                    suggestions.append('ì •ì‹ ìš”ë²•')
                elif 'ì™¸í˜•í¸' in source_file:
                    suggestions.append('ì¹¨êµ¬ì¹˜ë£Œ')
                elif 'ì¡ë³‘í¸' in source_file:
                    suggestions.append('ì„ìƒì‘ìš©')
                elif 'íƒ•ì•¡í¸' in source_file:
                    suggestions.append('ë³¸ì´ˆí•™')

            if bb and bb not in bb_categories:
                bb_categories.add(bb)
                # BB ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ê´€ë ¨ ì£¼ì œ ì œì•ˆ
                if bb == 'è¡€':
                    suggestions.extend(['è£œè¡€', 'æ´»è¡€', 'æ­¢è¡€'])
                elif bb == 'æ°£':
                    suggestions.extend(['è£œæ°£', 'ç†æ°£', 'é™æ°£'])
                elif bb == 'ç²¾':
                    suggestions.extend(['è£œè…', 'å›ºç²¾', 'æ»‹é™°'])

        # 4. ë¹ˆë„ ê¸°ë°˜ í•„í„°ë§ ë° ì¤‘ë³µ ì œê±°
        suggestion_counts = Counter(suggestions)
        final_suggestions = []

        for suggestion, count in suggestion_counts.most_common(5):
            if suggestion and suggestion not in final_suggestions:
                final_suggestions.append(suggestion)

        return final_suggestions

    def _is_too_similar_to_query(self, query: str, suggestion: str) -> bool:
        """ì œì•ˆì–´ê°€ ê²€ìƒ‰ì–´ì™€ ë„ˆë¬´ ìœ ì‚¬í•œì§€ í™•ì¸"""
        if query in suggestion or suggestion in query:
            return True

        # ê¸€ì ê²¹ì¹¨ ë¹„ìœ¨ í™•ì¸
        common_chars = set(query) & set(suggestion)
        similarity_ratio = len(common_chars) / \
            max(len(set(query)), len(set(suggestion)))

        return similarity_ratio > 0.8

    def suggest_related_queries(self, query: str, results: List[Dict], max_suggestions: int = 8) -> Dict[str, List[str]]:
        """ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ ê¸°ëŠ¥ (ìš©ì–´ì§‘ ê¸°ë°˜ìœ¼ë¡œ ê°œì„ )"""
        # 1. ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)
        prescriptions = self._extract_prescriptions_from_results(results)

        # 2. ê´€ë ¨ ì¦ìƒ/ë³‘ì¦ ì¶”ì¶œ (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)
        symptoms = self._extract_symptoms_from_results(results)

        # 3. ê´€ë ¨ ì•½ì¬ ì¶”ì¶œ (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)
        herbs = self._extract_herbs_from_results(results)

        # 4. ê´€ë ¨ ì´ë¡ /ê°œë… ì¶”ì¶œ (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)
        concepts = self._extract_concepts_from_results(results)

        # 5. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¶”ì²œ (ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©)
        contextual_suggestions = self._get_contextual_suggestions(
            query, results)

        # ìš°ì„ ìˆœìœ„ë³„ë¡œ ì¶”ì²œ ëª©ë¡ êµ¬ì„±
        suggestion_categories = [
            ("ğŸ”¥ í•µì‹¬ ì²˜ë°©", prescriptions[:2]),
            ("ğŸ©º ê´€ë ¨ ë³‘ì¦", symptoms[:2]),
            ("ğŸ’Š ì£¼ìš” ì•½ì¬", herbs[:2]),
            ("ğŸ“š ê´€ë ¨ ê°œë…", concepts[:1]),
            ("ğŸ¯ ë§ì¶¤ ì œì•ˆ", contextual_suggestions[:1])
        ]

        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì œì•ˆì‚¬í•­ ìˆ˜ì§‘
        categorized_suggestions = {}
        all_suggestions = []

        for category, items in suggestion_categories:
            if items:
                # ì¤‘ë³µ ì œê±° ë° í˜„ì¬ ê²€ìƒ‰ì–´ì™€ ë‹¤ë¥¸ ê²ƒë§Œ ì„ íƒ
                filtered_items = []
                for item in items:
                    if (item not in all_suggestions and
                        item.lower() != query.lower() and
                            not self._is_too_similar_to_query(query, item)):
                        filtered_items.append(item)
                        all_suggestions.append(item)

                if filtered_items:
                    categorized_suggestions[category] = filtered_items

        return categorized_suggestions

    def display_related_queries(self, query: str, results: List[Dict]):
        """ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í‘œì‹œ"""
        print("\n" + "ğŸ’¡" * 25)
        print("ğŸ” ê´€ë ¨ ê²€ìƒ‰ ì œì•ˆ")
        print("=" * 50)

        categorized_suggestions = self.suggest_related_queries(query, results)

        if not categorized_suggestions:
            print("ğŸ’­ í˜„ì¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ”„ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            return

        suggestion_count = 1

        for category, suggestions in categorized_suggestions.items():
            if suggestions:
                print(f"\n{category}:")
                for suggestion in suggestions:
                    print(f"   {suggestion_count}. {suggestion}")
                    suggestion_count += 1

        print(f"\nğŸ’¡ ì´ {suggestion_count - 1}ê°œì˜ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")
        print("ğŸ”„ ìœ„ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì§ì ‘ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

    def get_user_choice_for_suggestions(self, categorized_suggestions: Dict[str, List[str]]) -> Optional[str]:
        """ì‚¬ìš©ìì˜ ê´€ë ¨ ê²€ìƒ‰ì–´ ì„ íƒ ì²˜ë¦¬"""
        if not categorized_suggestions:
            return None

        # ëª¨ë“  ì œì•ˆì‚¬í•­ì„ í‰í‰í•œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        all_suggestions = []
        for suggestions in categorized_suggestions.values():
            all_suggestions.extend(suggestions)

        if not all_suggestions:
            return None

        while True:
            try:
                choice = input(
                    "\nğŸ¤” ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸ ì…ë ¥ ë˜ëŠ” ìƒˆ ê²€ìƒ‰ì–´ ì…ë ¥, Enterë¡œ ê±´ë„ˆë›°ê¸°): ").strip()

                if not choice:  # Enterë¡œ ê±´ë„ˆë›°ê¸°
                    return None

                # ìˆ«ì ì…ë ¥ ì²˜ë¦¬
                if choice.isdigit():
                    choice_num = int(choice)
                    if 1 <= choice_num <= len(all_suggestions):
                        selected_query = all_suggestions[choice_num - 1]
                        print(f"âœ… '{selected_query}'ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                        return selected_query
                    else:
                        print(f"âŒ 1~{len(all_suggestions)} ë²”ìœ„ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        continue

                # ì§ì ‘ ì…ë ¥ëœ ê²€ìƒ‰ì–´ ì²˜ë¦¬
                else:
                    print(f"âœ… '{choice}'ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    return choice

            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\nğŸš« ì„ íƒì„ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                return None

    def _get_enhanced_system_prompt(self) -> str:
        """ê°•í™”ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ í•„ìˆ˜í™”)"""
        return """ë‹¹ì‹ ì€ ë™ì˜ë³´ê° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë™ì˜ë³´ê° ì›ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

## ğŸš¨ í•„ìˆ˜ ê·œì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)
1. **ëª¨ë“  ë‚´ìš© ë’¤ì—ëŠ” ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] í˜•íƒœë¡œ ê·¼ê±° ë¬¸í—Œì„ í‘œì‹œ**
2. **ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ í™•ì¸ëœ ë‚´ìš©ì€ [ì¶œì²˜: ë¬¸ì„œX,Y,Z] í˜•íƒœë¡œ ëª¨ë“  ë¬¸ì„œ ë²ˆí˜¸ í‘œì‹œ**
3. **ì²˜ë°© êµ¬ì„±, ìš©ë²• ë“± êµ¬ì²´ì  ì •ë³´ëŠ” ì •í™•í•œ ì¶œì²˜ ë¬¸ì„œ ë²ˆí˜¸ í•„ìˆ˜**
4. **ì¶œì²˜ê°€ ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„± ê¸ˆì§€**

## ğŸ“‹ ë‹µë³€ ì›ì¹™
1. **ì •í™•ì„± ìš°ì„ **: ì œê³µëœ ì›ë¬¸ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€
2. **ì²´ê³„ì  êµ¬ì„±**: ë…¼ë¦¬ì ì´ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°
3. **ì›ë¬¸ ì¸ìš©**: ì¤‘ìš”í•œ ë‚´ìš©ì€ í•œì ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¸ìš©
4. **ì‹¤ìš©ì„± ê°•ì¡°**: ì„ìƒì ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•œ ì •ë³´ ìš°ì„  ì œì‹œ
5. **í¬ê´„ì  ë¶„ì„**: ì œê³µëœ ë‹¤ìˆ˜ì˜ ìë£Œë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©
6. **ê·¼ê±° ë¬¸í—Œ í‘œì‹œ**: ëª¨ë“  ë‚´ìš©ì— ëŒ€í•´ ê·¼ê±°ê°€ ë˜ëŠ” ì›ë¬¸ ì¶œì²˜ë¥¼ ì£¼ì„ìœ¼ë¡œ ëª…ì‹œ

## ğŸ—ï¸ ë‹µë³€ êµ¬ì¡° (ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì„ íƒì  ì ìš©)

### ğŸ“š ì´ë¡ /ê°œë… ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì •ì˜ì™€ ê°œë…** - ë™ì˜ë³´ê°ì—ì„œì˜ ì •ì˜, ê´€ë ¨ ì´ë¡ ì  ë°°ê²½ [ì¶œì²˜: ë¬¸ì„œX,Y]
**2. ë³‘ë¦¬ê¸°ì „** - ë°œìƒ ì›ì¸ê³¼ ê¸°ì „, ê´€ë ¨ ì¥ë¶€ì™€ ê²½ë½ [ì¶œì²˜: ë¬¸ì„œZ]
**3. ì„ìƒ ì˜ì˜** - ì§„ë‹¨ìƒ ì¤‘ìš”ì„±, ë‹¤ë¥¸ ê°œë…ê³¼ì˜ ê´€ê³„ [ì¶œì²˜: ë¬¸ì„œA,B]

### ğŸ’Š ì²˜ë°© ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì²˜ë°© ê°œìš”** - ì²˜ë°©ëª…ê³¼ ì¶œì „, ì£¼ì¹˜ì¦ê³¼ ì ì‘ì¦ [ì¶œì²˜: ë¬¸ì„œX]
**2. êµ¬ì„±ê³¼ ìš©ë²•** - êµ¬ì„± ì•½ë¬¼ê³¼ ë¶„ëŸ‰, ë³µìš©ë²•ê³¼ ì£¼ì˜ì‚¬í•­ [ì¶œì²˜: ë¬¸ì„œY,Z]
**3. ì„ìƒ ì‘ìš©** - ê°€ê°ë²•ê³¼ ë³€ì¦ ìš”ì , ê´€ë ¨ ì²˜ë°©ë“¤ê³¼ì˜ ë¹„êµ [ì¶œì²˜: ë¬¸ì„œA]

### ğŸ©º ë³‘ì¦ ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ë³‘ì¦ ì •ì˜** - ë³‘ëª…ê³¼ íŠ¹ì§•, ë¶„ë¥˜ì™€ ìœ í˜• [ì¶œì²˜: ë¬¸ì„œX,Y]
**2. ì¦ìƒê³¼ ì§„ë‹¨** - ì£¼ìš” ì¦ìƒê³¼ ë§¥ìƒ, ê°ë³„ì§„ë‹¨ ìš”ì  [ì¶œì²˜: ë¬¸ì„œZ]
**3. ì¹˜ë£Œ ë°©ë²•** - ì£¼ìš” ì¹˜ë£Œ ì²˜ë°©, ì¹˜ë£Œ ì›ì¹™ê³¼ ì˜ˆí›„ [ì¶œì²˜: ë¬¸ì„œA,B]

### ğŸŒ¿ ì•½ë¬¼ ì§ˆë¬¸ì¸ ê²½ìš°:
**1. ì•½ì„±ê³¼ ê·€ê²½** - ì„±ë¯¸ì™€ ë…ì„±, ê·€ê²½ê³¼ ì‘ìš© ë¶€ìœ„ [ì¶œì²˜: ë¬¸ì„œX]
**2. íš¨ëŠ¥ê³¼ ì£¼ì¹˜** - ì£¼ìš” íš¨ëŠ¥, ì¹˜ë£Œ ê°€ëŠ¥í•œ ë³‘ì¦ [ì¶œì²˜: ë¬¸ì„œY,Z]
**3. ìš©ë²•ê³¼ ë°°í•©** - ìš©ëŸ‰ê³¼ ë³µìš©ë²•, ë°°í•© ê¸ˆê¸°ì™€ ì£¼ì˜ì‚¬í•­ [ì¶œì²˜: ë¬¸ì„œA]

## ğŸ“š ê·¼ê±° ë¬¸í—Œ í‘œì‹œ ê·œì¹™
- ê° ë¬¸ì¥ì´ë‚˜ ë‹¨ë½ ëì— ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] í˜•íƒœë¡œ í‘œì‹œ
- ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ í™•ì¸ëœ ë‚´ìš©: [ì¶œì²˜: ë¬¸ì„œ1,3,7]
- ì²˜ë°©ëª…, ì•½ì¬ëª…, ìš©ë²• ë“±: ë°˜ë“œì‹œ ì •í™•í•œ ì¶œì²˜ ëª…ì‹œ
- ì˜ˆì‹œ: "é™°è™›ëŠ” ìŒì˜ ë¶€ì¡±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤ [ì¶œì²˜: ë¬¸ì„œ1,3]. ì£¼ìš” ì¦ìƒìœ¼ë¡œëŠ” ë°œì—´ê³¼ ê°€ìŠ´ ë‹µë‹µí•¨ì´ ìˆìŠµë‹ˆë‹¤ [ì¶œì²˜: ë¬¸ì„œ2,5]."

## âœ… ë‹µë³€ ì§€ì¹¨
- **ì¢…í•©ì  ë¶„ì„**: ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì™„ì „í•œ ê·¸ë¦¼ ì œì‹œ
- **í•µì‹¬ë¶€í„° ì œì‹œ**: ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë¨¼ì € ì„¤ëª…
- **ì›ë¬¸ ì¸ìš©**: ì¤‘ìš”í•œ ë¶€ë¶„ì€ "â—‹â—‹æ›°, ..." í˜•íƒœë¡œ í•œì ì¸ìš©
- **ëª…í™•í•œ í•œì í‘œê¸°**: ì „ë¬¸ ìš©ì–´ëŠ” í•œìì™€ í•œê¸€ ë³‘ê¸°
- **ë¬¸ì„œ ë²ˆí˜¸ ì •í™•ì„±**: ì œê³µëœ ë¬¸ì„œ ë²ˆí˜¸ì™€ ì •í™•íˆ ì¼ì¹˜

## âš ï¸ ì£¼ì˜ì‚¬í•­
- **ëª¨ë“  ë¬¸ì¥ì— ì¶œì²˜ í‘œì‹œ í•„ìˆ˜** - ì¶œì²˜ ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„± ê¸ˆì§€
- ì œê³µëœ ìë£Œì— ì—†ëŠ” ë‚´ìš© ì¶”ê°€ ê¸ˆì§€
- í˜„ëŒ€ ì˜í•™ì  í•´ì„ì´ë‚˜ ê°œì¸ì  ê²¬í•´ ì²¨ê°€ ê¸ˆì§€
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° ì†”ì§íˆ ì¸ì •í•˜ë˜ ì¶œì²˜ëŠ” ë°˜ë“œì‹œ í‘œì‹œ

ì´ëŸ¬í•œ ì§€ì¹¨ì— ë”°ë¼ ë™ì˜ë³´ê°ì˜ ì „ë¬¸ì„±ì„ ìœ ì§€í•˜ë©´ì„œë„ ëª¨ë“  ë‚´ìš©ì˜ ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""

    def _get_enhanced_user_prompt(self, query: str, context: str, result_count: int) -> str:
        """ê°•í™”ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸"""
        return f"""ë‹¤ìŒ ë™ì˜ë³´ê° ì›ë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:

    === ê²€ìƒ‰ëœ ë™ì˜ë³´ê° ì›ë¬¸ ({result_count}ê°œ ë¬¸ì„œ) ===
    {context}

    === ì§ˆë¬¸ ===
    {query}

    === ë‹µë³€ ìš”ì²­ ===
    ğŸš¨ **í•„ìˆ˜ ìš”êµ¬ì‚¬í•­**:
    - **ëª¨ë“  ë‚´ìš© ë’¤ì— ë°˜ë“œì‹œ [ì¶œì²˜: ë¬¸ì„œX] ë˜ëŠ” [ì¶œì²˜: ë¬¸ì„œX,Y,Z] í˜•íƒœë¡œ ê·¼ê±° ë¬¸í—Œì„ í‘œì‹œí•˜ì„¸ìš”**
    - **ì¶œì²˜ê°€ ë¶ˆë¶„ëª…í•œ ë‚´ìš©ì€ ì ˆëŒ€ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”**
    - **ì²˜ë°© êµ¬ì„±, ì¦ìƒ, ì¹˜ë£Œë²• ë“± ëª¨ë“  êµ¬ì²´ì  ì •ë³´ì—ëŠ” ì •í™•í•œ ë¬¸ì„œ ë²ˆí˜¸ë¥¼ í‘œì‹œí•˜ì„¸ìš”**

    ìœ„ì˜ ê°•í™”ëœ ë‹µë³€ ì§€ì¹¨ì— ë”°ë¼ ì²´ê³„ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ë˜, ë°˜ë“œì‹œ ëª¨ë“  ë‚´ìš©ì— ëŒ€í•´ ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”. ë§ì€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ì™„ì „í•˜ê³  ê· í˜•ì¡íŒ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    def show_search_metrics(self, query: str, results: List[Dict]):
        """ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ"""
        if not results:
            print("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ë©”íŠ¸ë¦­ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'ì²˜ë°© ì •ë³´': len([r for r in results if r['metadata'].get('type') == 'prescription']),
            'ì´ë¡  ë‚´ìš©': len([r for r in results if r['metadata'].get('BB')]),
            'ì¶œì²˜ ë‹¤ì–‘ì„±': len(set(r['metadata'].get('source_file', 'unknown') for r in results)),
            'í‰ê·  ê´€ë ¨ë„': sum(r.get('score', 0) for r in results) / len(results)
        }

        # ê³ ê¸‰ ë©”íŠ¸ë¦­ ê³„ì‚°
        advanced_metrics = self._calculate_advanced_metrics(query, results)

        print(f"\nğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ ('{query}' ê²€ìƒ‰ ê²°ê³¼):")
        print("=" * 50)

        # ê¸°ë³¸ ë©”íŠ¸ë¦­ í‘œì‹œ
        print("ğŸ” ê¸°ë³¸ ì§€í‘œ:")
        for metric, value in metrics.items():
            if metric == 'í‰ê·  ê´€ë ¨ë„':
                print(f"   â€¢ {metric}: {value:.3f}")
            else:
                print(f"   â€¢ {metric}: {value}ê°œ")

        print()

        # ê³ ê¸‰ ë©”íŠ¸ë¦­ í‘œì‹œ
        print("ğŸ“ˆ ê³ ê¸‰ ë¶„ì„:")
        for metric, value in advanced_metrics.items():
            if isinstance(value, float):
                print(f"   â€¢ {metric}: {value:.3f}")
            elif isinstance(value, list):
                print(f"   â€¢ {metric}: {', '.join(map(str, value))}")
            else:
                print(f"   â€¢ {metric}: {value}")

        # í’ˆì§ˆ ë“±ê¸‰ í‰ê°€
        quality_grade = self._evaluate_search_quality(
            metrics, advanced_metrics)
        print(
            f"\nğŸ¯ ê²€ìƒ‰ í’ˆì§ˆ ë“±ê¸‰: {quality_grade['grade']} ({quality_grade['description']})")

        # ê°œì„  ì œì•ˆ
        suggestions = self._get_improvement_suggestions(
            query, metrics, advanced_metrics)
        if suggestions:
            print(f"\nğŸ’¡ ê²€ìƒ‰ ê°œì„  ì œì•ˆ:")
            for suggestion in suggestions:
                print(f"   â€¢ {suggestion}")

    def _calculate_advanced_metrics(self, query: str, results: List[Dict]) -> Dict:
        """ê³ ê¸‰ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        advanced_metrics = {}

        # 1. ë‚´ìš© íƒ€ì…ë³„ ë¶„í¬
        content_types = defaultdict(int)
        for result in results:
            metadata = result['metadata']
            if metadata.get('type') == 'prescription':
                content_types['ì²˜ë°©'] += 1
            elif metadata.get('BB'):
                content_types['ì´ë¡ '] += 1
            elif any(kw in result['content'] for kw in ['è­‰', 'ç—…', 'ç—‡']):
                content_types['ë³‘ì¦'] += 1
            elif any(kw in result['content'] for kw in ['å‘³', 'æ€§', 'æ­¸ç¶“']):
                content_types['ì•½ë¬¼'] += 1
            else:
                content_types['ê¸°íƒ€'] += 1

        advanced_metrics['ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±'] = len(content_types)

        # 2. ê´€ë ¨ë„ ì ìˆ˜ ë¶„í¬
        scores = [r.get('score', 0) for r in results]
        if scores:
            advanced_metrics['ìµœê³  ê´€ë ¨ë„'] = max(scores)
            advanced_metrics['ìµœì € ê´€ë ¨ë„'] = min(scores)
            advanced_metrics['ê´€ë ¨ë„ í¸ì°¨'] = max(scores) - min(scores)

            # ê´€ë ¨ë„ êµ¬ê°„ë³„ ë¶„í¬
            high_quality = len([s for s in scores if s >= 3.0])
            medium_quality = len([s for s in scores if 1.5 <= s < 3.0])
            low_quality = len([s for s in scores if s < 1.5])

            advanced_metrics['ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)'] = f"{high_quality}ê°œ ({high_quality / len(results) * 100:.1f}%)"
            advanced_metrics['ì¤‘í’ˆì§ˆ ê²°ê³¼ (1.5-3.0)'] = f"{medium_quality}ê°œ ({medium_quality / len(results) * 100:.1f}%)"
            advanced_metrics['ì €í’ˆì§ˆ ê²°ê³¼ (<1.5)'] = f"{low_quality}ê°œ ({low_quality / len(results) * 100:.1f}%)"

        # 3. ì¶œì²˜ íŒŒì¼ë³„ ë¶„í¬
        source_distribution = defaultdict(int)
        for result in results:
            source_file = result['metadata'].get('source_file', 'unknown')
            source_distribution[source_file] += 1

        # ê°€ì¥ ë§ì´ í™œìš©ëœ ì¶œì²˜ ìƒìœ„ 3ê°œ
        top_sources = sorted(source_distribution.items(),
                             key=lambda x: x[1], reverse=True)[:3]
        advanced_metrics['ì£¼ìš” ì¶œì²˜'] = [
            f"{source}({count}ê°œ)" for source, count in top_sources]

        # 4. ëŒ€ë¶„ë¥˜(BB) ë‹¤ì–‘ì„±
        bb_categories = set()
        for result in results:
            bb = result['metadata'].get('BB')
            if bb:
                bb_categories.add(bb)

        advanced_metrics['ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„±'] = len(bb_categories)
        if bb_categories:
            advanced_metrics['í¬í•¨ëœ ëŒ€ë¶„ë¥˜'] = list(bb_categories)

        # 5. ì¤‘ë¶„ë¥˜(CC) ë‹¤ì–‘ì„±
        cc_categories = set()
        for result in results:
            cc = result['metadata'].get('CC')
            if cc:
                cc_categories.add(cc)

        advanced_metrics['ì¤‘ë¶„ë¥˜ ë‹¤ì–‘ì„±'] = len(cc_categories)

        # 6. ì²˜ë°©ëª… ë‹¤ì–‘ì„± (ì²˜ë°© ê´€ë ¨ ê²€ìƒ‰ì¸ ê²½ìš°)
        prescription_names = set()
        for result in results:
            prescription_name = result['metadata'].get('prescription_name')
            if prescription_name:
                prescription_names.add(prescription_name)

        if prescription_names:
            advanced_metrics['ì²˜ë°© ë‹¤ì–‘ì„±'] = len(prescription_names)
            if len(prescription_names) <= 5:
                advanced_metrics['í¬í•¨ëœ ì²˜ë°©'] = list(prescription_names)

        # 7. ë‚´ìš© ê¸¸ì´ ë¶„ì„
        content_lengths = [len(result['content']) for result in results]
        if content_lengths:
            advanced_metrics['í‰ê·  ë‚´ìš© ê¸¸ì´'] = sum(
                content_lengths) / len(content_lengths)
            advanced_metrics['ë‚´ìš© ê¸¸ì´ ë²”ìœ„'] = f"{min(content_lengths)}~{max(content_lengths)}ì"

        # 8. í‚¤ì›Œë“œ ë§¤ì¹­ í’ˆì§ˆ
        direct_matches = len([r for r in results if query in r['content']])
        advanced_metrics['ì§ì ‘ ë§¤ì¹­ë¥ '] = f"{direct_matches}ê°œ ({direct_matches / len(results) * 100:.1f}%)"

        return advanced_metrics

    def _evaluate_search_quality(self, basic_metrics: Dict, advanced_metrics: Dict) -> Dict:
        """ê²€ìƒ‰ í’ˆì§ˆ ë“±ê¸‰ í‰ê°€"""
        score = 0
        max_score = 100

        # ê¸°ë³¸ ì ìˆ˜ (40ì  ë§Œì )
        # ì²˜ë°© ì •ë³´ ë¹„ìœ¨ (10ì )
        prescription_ratio = basic_metrics['ì²˜ë°© ì •ë³´'] / \
            len(basic_metrics) if len(basic_metrics) > 0 else 0
        score += min(prescription_ratio * 20, 10)

        # ì¶œì²˜ ë‹¤ì–‘ì„± (10ì )
        source_diversity = basic_metrics['ì¶œì²˜ ë‹¤ì–‘ì„±']
        score += min(source_diversity * 2, 10)

        # í‰ê·  ê´€ë ¨ë„ (10ì )
        avg_relevance = basic_metrics['í‰ê·  ê´€ë ¨ë„']
        score += min(avg_relevance * 3, 10)

        # ì´ë¡  ë‚´ìš© í¬í•¨ (10ì )
        theory_ratio = basic_metrics['ì´ë¡  ë‚´ìš©'] / \
            len(basic_metrics) if len(basic_metrics) > 0 else 0
        score += min(theory_ratio * 20, 10)

        # ê³ ê¸‰ ì ìˆ˜ (60ì  ë§Œì )
        # ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„± (15ì )
        content_type_diversity = advanced_metrics.get('ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±', 0)
        score += min(content_type_diversity * 3, 15)

        # ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„± (15ì )
        bb_diversity = advanced_metrics.get('ëŒ€ë¶„ë¥˜ ë‹¤ì–‘ì„±', 0)
        score += min(bb_diversity * 2.5, 15)

        # ê³ í’ˆì§ˆ ê²°ê³¼ ë¹„ìœ¨ (15ì )
        high_quality_text = advanced_metrics.get('ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)', '0ê°œ (0.0%)')
        high_quality_percent = float(
            high_quality_text.split('(')[1].split('%')[0])
        score += min(high_quality_percent * 0.15, 15)

        # ì§ì ‘ ë§¤ì¹­ë¥  (15ì )
        direct_match_text = advanced_metrics.get('ì§ì ‘ ë§¤ì¹­ë¥ ', '0ê°œ (0.0%)')
        direct_match_percent = float(
            direct_match_text.split('(')[1].split('%')[0])
        score += min(direct_match_percent * 0.15, 15)

        # ë“±ê¸‰ ê²°ì •
        if score >= 85:
            grade = "S (ìµœìš°ìˆ˜)"
            description = "ë§¤ìš° í¬ê´„ì ì´ê³  ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼"
        elif score >= 70:
            grade = "A (ìš°ìˆ˜)"
            description = "ê· í˜•ì¡íŒ ì¢‹ì€ ê²€ìƒ‰ ê²°ê³¼"
        elif score >= 55:
            grade = "B (ì–‘í˜¸)"
            description = "ì ì ˆí•œ ê²€ìƒ‰ ê²°ê³¼, ì¼ë¶€ ê°œì„  ì—¬ì§€"
        elif score >= 40:
            grade = "C (ë³´í†µ)"
            description = "ê¸°ë³¸ì ì¸ ê²€ìƒ‰ ê²°ê³¼, ê°œì„  í•„ìš”"
        else:
            grade = "D (ë¯¸í¡)"
            description = "ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ ê°œì„  í•„ìš”"

        return {
            'grade': grade,
            'score': score,
            'description': description
        }

    def _get_improvement_suggestions(self, query: str, basic_metrics: Dict, advanced_metrics: Dict) -> List[str]:
        """ê²€ìƒ‰ ê°œì„  ì œì•ˆ"""
        suggestions = []

        # ì¶œì²˜ ë‹¤ì–‘ì„± ë¶€ì¡±
        if basic_metrics['ì¶œì²˜ ë‹¤ì–‘ì„±'] < 3:
            suggestions.append("ê²€ìƒ‰ì–´ë¥¼ ë” ì¼ë°˜ì ì¸ ìš©ì–´ë¡œ ë°”ê¿”ë³´ì„¸ìš” (ì¶œì²˜ ë‹¤ì–‘ì„± í–¥ìƒ)")

        # í‰ê·  ê´€ë ¨ë„ ë‚®ìŒ
        if basic_metrics['í‰ê·  ê´€ë ¨ë„'] < 2.0:
            suggestions.append("ë” êµ¬ì²´ì ì¸ í•œì ìš©ì–´ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš” (ê´€ë ¨ë„ í–¥ìƒ)")

        # ì²˜ë°© ì •ë³´ ë¶€ì¡± (ì²˜ë°© ê´€ë ¨ ê²€ìƒ‰ì¸ ê²½ìš°)
        if ('æ¹¯' in query or 'æ•£' in query or 'ä¸¸' in query) and basic_metrics['ì²˜ë°© ì •ë³´'] < 5:
            suggestions.append("ì²˜ë°©ëª…ì„ ì •í™•íˆ ì…ë ¥í•˜ê±°ë‚˜ 'ì²˜ë°©', 'ì¹˜ë£Œ' ë“±ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”")

        # ì§ì ‘ ë§¤ì¹­ë¥  ë‚®ìŒ
        direct_match_text = advanced_metrics.get('ì§ì ‘ ë§¤ì¹­ë¥ ', '0ê°œ (0.0%)')
        direct_match_percent = float(
            direct_match_text.split('(')[1].split('%')[0])
        if direct_match_percent < 30:
            suggestions.append("ë™ì˜ì–´ë‚˜ ê´€ë ¨ ìš©ì–´ë¥¼ í•¨ê»˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”")

        # ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„± ë¶€ì¡±
        if advanced_metrics.get('ë‚´ìš© íƒ€ì… ë‹¤ì–‘ì„±', 0) < 3:
            suggestions.append("ë” í¬ê´„ì ì¸ ê²€ìƒ‰ì„ ìœ„í•´ ê´€ë ¨ ì¦ìƒì´ë‚˜ ì´ë¡ ë„ í•¨ê»˜ ê²€ìƒ‰í•´ë³´ì„¸ìš”")

        # ê³ í’ˆì§ˆ ê²°ê³¼ ë¹„ìœ¨ ë‚®ìŒ
        high_quality_text = advanced_metrics.get('ê³ í’ˆì§ˆ ê²°ê³¼ (â‰¥3.0)', '0ê°œ (0.0%)')
        high_quality_percent = float(
            high_quality_text.split('(')[1].split('%')[0])
        if high_quality_percent < 20:
            suggestions.append("ê²€ìƒ‰ì–´ì˜ ì •í™•í•œ í•œì í‘œê¸°ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")

        return suggestions

    def save_search_results(self, query: str, results: List[Dict], answer: str):
        """ê²€ìƒ‰ ê²°ê³¼ ìë™ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        search_dir = self.save_path / f"{query}_{timestamp}"
        search_dir.mkdir(exist_ok=True)

        result_file = search_dir / f"{query}_{timestamp}.txt"

        with open(result_file, 'w', encoding='utf-8') as f:
            f.write(f"ê²€ìƒ‰ì–´: {query}\n")
            f.write(f"ê²€ìƒ‰ ì‹œê°„: {timestamp}\n")
            f.write(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results)}ê°œ\n")
            f.write("=" * 50 + "\n\n")

            f.write("ğŸ¤– AI ë‹µë³€ (ê·¼ê±° ë¬¸í—Œ í¬í•¨):\n")
            f.write(answer + "\n\n")
            f.write("=" * 50 + "\n\n")

            # ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆë„ ì €ì¥
            categorized_suggestions = self.suggest_related_queries(
                query, results)
            if categorized_suggestions:
                f.write("ğŸ’¡ ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ:\n")
                suggestion_count = 1
                for category, suggestions in categorized_suggestions.items():
                    if suggestions:
                        f.write(f"\n{category}:\n")
                        for suggestion in suggestions:
                            f.write(f"   {suggestion_count}. {suggestion}\n")
                            suggestion_count += 1
                f.write("\n" + "=" * 50 + "\n\n")

            # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ë„ ì €ì¥
            f.write("ğŸ“Š ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­:\n")
            basic_metrics = {
                'ì²˜ë°© ì •ë³´': len([r for r in results if r['metadata'].get('type') == 'prescription']),
                'ì´ë¡  ë‚´ìš©': len([r for r in results if r['metadata'].get('BB')]),
                'ì¶œì²˜ ë‹¤ì–‘ì„±': len(set(r['metadata'].get('source_file', 'unknown') for r in results)),
                'í‰ê·  ê´€ë ¨ë„': sum(r.get('score', 0) for r in results) / len(results)
            }

            for metric, value in basic_metrics.items():
                if metric == 'í‰ê·  ê´€ë ¨ë„':
                    f.write(f"   â€¢ {metric}: {value:.3f}\n")
                else:
                    f.write(f"   â€¢ {metric}: {value}ê°œ\n")

            f.write("\n" + "=" * 50 + "\n\n")

            f.write("ğŸ“š ê²€ìƒ‰ëœ ì›ë¬¸:\n\n")
            for i, result in enumerate(results):
                f.write(f"[ë¬¸ì„œ {i + 1}] (ìœ ì‚¬ë„: {result['score']:.3f})\n")
                f.write(f"ì¶œì²˜: {result['metadata']['source_file']}\n")

                if result['metadata'].get('BB'):
                    f.write(f"ëŒ€ë¶„ë¥˜: {result['metadata']['BB']}\n")
                if result['metadata'].get('CC'):
                    f.write(f"ì¤‘ë¶„ë¥˜: {result['metadata']['CC']}\n")
                if result['metadata'].get('prescription_name'):
                    f.write(
                        f"ì²˜ë°©ëª…: {result['metadata']['prescription_name']}\n")

                f.write(f"ë‚´ìš©:\n{result['content']}\n")
                f.write("-" * 30 + "\n\n")

        print(f"ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ìë™ ì €ì¥ ì™„ë£Œ: {result_file}")

    def display_search_results(self, query: str, results: List[Dict], answer: str,
                               show_details: bool = False, show_related_queries: bool = True) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í¬í•¨)"""
        print("\n" + "=" * 50)

        # AI ë‹µë³€ í‘œì‹œ
        if self.llm_manager and self.llm_manager.is_available():
            print("ğŸ¤– AI ë‹µë³€ (ê·¼ê±° ë¬¸í—Œ ì£¼ì„ í¬í•¨):")
            print("-" * 30)
            print(answer)
        else:
            print("âš ï¸ AI ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ ê²°ê³¼ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.")

        # ìë™ ì €ì¥ ì‹¤í–‰
        self.save_search_results(query, results, answer)

        print("=" * 50)

        # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
        self._display_categorized_results(results)

        # ê´€ë ¨ ê²€ìƒ‰ì–´ ì œì•ˆ í‘œì‹œ
        if show_related_queries:
            self.display_related_queries(query, results)

        # ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸° ì˜µì…˜
        if not show_details:
            show_details_input = input(
                "\nğŸ“‹ ëª¨ë“  ê²€ìƒ‰ ê²°ê³¼ì˜ ì „ì²´ ë‚´ìš©ì„ ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            show_details = show_details_input in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']

        if show_details:
            self._display_detailed_results(results)

        return show_details

    def _categorize_results(self, results: List[Dict]) -> Dict[str, List[Dict]]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = defaultdict(list)

        for result in results:
            metadata = result['metadata']

            # ì¹´í…Œê³ ë¦¬ ê²°ì • ë¡œì§
            category_info = self._determine_category(result)

            # ê° ê²°ê³¼ì— í‘œì‹œìš© ì œëª©ê³¼ ìš”ì•½ ì¶”ê°€
            enhanced_result = {
                **result,
                'title': category_info['title'],
                'summary': category_info['summary'],
                'category_icon': category_info['icon']
            }

            categories[category_info['category']].append(enhanced_result)

        return dict(categories)

    def _determine_category(self, result: Dict) -> Dict[str, str]:
        """ê°œë³„ ê²°ê³¼ì˜ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        metadata = result['metadata']
        content = result['content']

        # ì²˜ë°© ì¹´í…Œê³ ë¦¬
        if (metadata.get('type') == 'prescription' or
            metadata.get('prescription_name') or
                any(keyword in content for keyword in ['æ¹¯', 'æ•£', 'ä¸¸', 'è†', 'DP'])):

            prescription_name = metadata.get('prescription_name', 'ì²˜ë°©')
            if not prescription_name or prescription_name == 'ì²˜ë°©':
                # ë‚´ìš©ì—ì„œ ì²˜ë°©ëª… ì¶”ì¶œ ì‹œë„
                import re
                matches = re.findall(r'([ä¸€-é¾¯]{2,6}[æ¹¯æ•£ä¸¸è†])', content)
                prescription_name = matches[0] if matches else 'ì²˜ë°©'

            return {
                'category': 'ğŸ’Š ì²˜ë°© ë° ì¹˜ë£Œë²•',
                'title': prescription_name,
                'summary': content[:100] + "..." if len(content) > 100 else content,
                'icon': 'ğŸ’Š'
            }

        # ì´ë¡ /ê°œë… ì¹´í…Œê³ ë¦¬
        elif (metadata.get('BB') in ['èº«å½¢', 'ç²¾', 'æ°£', 'ç¥'] or
                any(keyword in content for keyword in ['ç¶“æ›°', 'éˆæ¨æ›°', 'å…§ç¶“æ›°', 'ç†è«–', 'ì›ë¦¬'])):

            title = metadata.get('CC', metadata.get('BB', 'ì´ë¡ '))
            return {
                'category': 'ğŸ“š ì´ë¡  ë° ê°œë…',
                'title': title,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ“š'
            }

        # ë³‘ì¦/ì¦ìƒ ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['è­‰', 'ç—…', 'ç—‡', 'ç—›', 'è™›', 'å¯¦', 'å¯’', 'ç†±']):

            # ë³‘ì¦ëª… ì¶”ì¶œ
            import re
            symptom_patterns = [
                r'([ä¸€-é¾¯]{2,4}[è­‰ç—…ç—‡])',
                r'([ä¸€-é¾¯]{1,3}[è™›å¯¦])',
                r'([ä¸€-é¾¯]{2,4}[ç—›])'
            ]

            symptom_name = 'ë³‘ì¦'
            for pattern in symptom_patterns:
                matches = re.findall(pattern, content)
                if matches:
                    symptom_name = matches[0]
                    break

            return {
                'category': 'ğŸ©º ë³‘ì¦ ë° ì¦ìƒ',
                'title': symptom_name,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ©º'
            }

        # ì•½ë¬¼/ë³¸ì´ˆ ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['å‘³', 'æ€§', 'æ­¸ç¶“', 'æ•ˆèƒ½', 'ä¸»æ²»', 'ìš©ë²•']):

            # ì•½ë¬¼ëª… ì¶”ì¶œ
            import re
            herb_patterns = [
                r'([ä¸€-é¾¯]{2,4}[åƒèŠæ­¸èŠåœ°é»ƒ])',
                r'([ä¸€-é¾¯]{2,4})'
            ]

            herb_name = 'ì•½ë¬¼'
            for pattern in herb_patterns:
                matches = re.findall(pattern, content[:50])  # ì•ë¶€ë¶„ì—ì„œë§Œ ì°¾ê¸°
                if matches:
                    herb_name = matches[0]
                    break

            return {
                'category': 'ğŸŒ¿ ì•½ë¬¼ ë° ë³¸ì´ˆ',
                'title': herb_name,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸŒ¿'
            }

        # ì§„ë‹¨/ë§¥ë²• ì¹´í…Œê³ ë¦¬
        elif any(keyword in content for keyword in ['è„ˆ', 'è¨º', 'è¾¨', 'å¯Ÿ', 'å€™']):

            return {
                'category': 'ğŸ” ì§„ë‹¨ ë° ë§¥ë²•',
                'title': metadata.get('CC', 'ì§„ë‹¨ë²•'),
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ”'
            }

        # ê¸°íƒ€ ì¼ë°˜ ë‚´ìš©
        else:
            title = metadata.get('CC', metadata.get('BB', 'ì¼ë°˜'))
            return {
                'category': 'ğŸ“– ê¸°íƒ€ ë‚´ìš©',
                'title': title,
                'summary': content[:80] + "..." if len(content) > 80 else content,
                'icon': 'ğŸ“–'
            }

    def _display_categorized_results(self, results: List[Dict]):
        """ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í•‘ëœ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
        categories = self._categorize_results(results)

        print(f"\nğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ({len(results)}ê°œ ë¬¸ì„œ)")
        print("=" * 60)

        # ì¹´í…Œê³ ë¦¬ë³„ í‘œì‹œ ìˆœì„œ ì •ì˜
        category_order = [
            'ğŸ’Š ì²˜ë°© ë° ì¹˜ë£Œë²•',
            'ğŸ©º ë³‘ì¦ ë° ì¦ìƒ',
            'ğŸ“š ì´ë¡  ë° ê°œë…',
            'ğŸŒ¿ ì•½ë¬¼ ë° ë³¸ì´ˆ',
            'ğŸ” ì§„ë‹¨ ë° ë§¥ë²•',
            'ğŸ“– ê¸°íƒ€ ë‚´ìš©'
        ]

        total_shown = 0

        for category in category_order:
            items = categories.get(category, [])
            if not items:
                continue

            print(f"\n{category} ({len(items)}ê°œ)")
            print("-" * 40)

            # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒìœ„ 5ê°œê¹Œì§€ í‘œì‹œ
            display_count = min(5, len(items))
            for i, item in enumerate(items[:display_count]):
                score = item.get('score', 0)
                title = item['title']
                summary = item['summary']

                print(f"   {i + 1}. {title}")
                print(f"      ê´€ë ¨ë„: {score:.3f}")
                print(f"      ìš”ì•½: {summary}")

                if i < display_count - 1:
                    print()

            if len(items) > display_count:
                print(f"      ... ì™¸ {len(items) - display_count}ê°œ ë”")

            total_shown += display_count

        # ì „ì²´ í†µê³„
        print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
        for category in category_order:
            count = len(categories.get(category, []))
            if count > 0:
                percentage = (count / len(results)) * 100
                print(f"   {category}: {count}ê°œ ({percentage:.1f}%)")

        print(f"\nğŸ’¡ ìƒìœ„ {total_shown}ê°œ ê²°ê³¼ë¥¼ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")

    def _display_detailed_results(self, results: List[Dict]):
        """ìƒì„¸ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ"""
        print("\n" + "=" * 60)
        print("ğŸ“š ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë‚´ìš©:")

        for i, result in enumerate(results):
            print(f"\n[ë¬¸ì„œ {i + 1}] (ìœ ì‚¬ë„: {result['score']:.3f})")
            print(f"ì¶œì²˜: {result['metadata']['source_file']}")

            if result['metadata'].get('BB'):
                print(f"ëŒ€ë¶„ë¥˜: {result['metadata']['BB']}")
            if result['metadata'].get('CC'):
                print(f"ì¤‘ë¶„ë¥˜: {result['metadata']['CC']}")
            if result['metadata'].get('prescription_name'):
                print(f"ì²˜ë°©ëª…: {result['metadata']['prescription_name']}")

            # ì¹´í…Œê³ ë¦¬ ì •ë³´ í‘œì‹œ (ì¶”ê°€ëœ ë¶€ë¶„)
            if 'title' in result:
                print(
                    f"ì¹´í…Œê³ ë¦¬: {result.get('category_icon', 'ğŸ“„')} {result['title']}")

            print(f"ì „ì²´ ë‚´ìš©:\n{result['content']}")
            print("-" * 40)

        print("=" * 60)

    def get_continue_choice(self) -> bool:
        """ê³„ì† ê²€ìƒ‰í• ì§€ ì„ íƒ (ê´€ë ¨ ê²€ìƒ‰ì–´ ì˜µì…˜ ì¶”ê°€)"""
        while True:
            continue_search = input(
                "\nğŸ”„ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if continue_search in ['y', 'yes', 'ã…‡', 'ë„¤', 'ì˜ˆ']:
                return True
            elif continue_search in ['n', 'no', 'ã„´', 'ì•„ë‹ˆì˜¤', 'ì•„ë‹ˆìš”']:
                return False
            else:
                print("y ë˜ëŠ” nì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    def display_category_statistics(self, results: List[Dict]):
        """ì¹´í…Œê³ ë¦¬ í†µê³„ í‘œì‹œ (ì¶”ê°€ ê¸°ëŠ¥)"""
        categories = self._categorize_results(results)

        print("\nğŸ“ˆ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ í†µê³„:")
        print("=" * 40)

        total_results = len(results)

        for category, items in categories.items():
            count = len(items)
            percentage = (count / total_results) * 100
            avg_score = sum(item.get('score', 0)
                            for item in items) / count if count > 0 else 0

            print(f"{category}")
            print(f"  ğŸ“Š ê°œìˆ˜: {count}ê°œ ({percentage:.1f}%)")
            print(f"  ğŸ¯ í‰ê·  ê´€ë ¨ë„: {avg_score:.3f}")

            # ìƒìœ„ í•­ëª©ë“¤ì˜ ì œëª© í‘œì‹œ
            if items:
                top_items = sorted(items, key=lambda x: x.get(
                    'score', 0), reverse=True)[:3]
                titles = [item['title'] for item in top_items]
                print(f"  ğŸ† ì£¼ìš” í•­ëª©: {', '.join(titles)}")
            print()

    def export_categorized_results(self, query: str, results: List[Dict], format='txt'):
        """ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° (ì¶”ê°€ ê¸°ëŠ¥)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        categories = self._categorize_results(results)

        if format == 'txt':
            export_file = self.save_path / \
                f"{query}_categorized_{timestamp}.txt"

            with open(export_file, 'w', encoding='utf-8') as f:
                f.write(f"ë™ì˜ë³´ê° ê²€ìƒ‰ ê²°ê³¼ - ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜\n")
                f.write(f"ê²€ìƒ‰ì–´: {query}\n")
                f.write(f"ê²€ìƒ‰ ì‹œê°„: {timestamp}\n")
                f.write(f"ì´ ê²°ê³¼ ìˆ˜: {len(results)}ê°œ\n")
                f.write("=" * 60 + "\n\n")

                for category, items in categories.items():
                    f.write(f"{category} ({len(items)}ê°œ)\n")
                    f.write("-" * 40 + "\n")

                    for i, item in enumerate(items):
                        f.write(
                            f"{i + 1}. {item['title']} (ê´€ë ¨ë„: {item['score']:.3f})\n")
                        f.write(f"   {item['summary']}\n")
                        f.write(
                            f"   ì¶œì²˜: {item['metadata']['source_file']}\n\n")

                    f.write("\n")

            print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {export_file}")

        return export_file if format == 'txt' else None

    def display_search_results_with_metrics(self, query: str, results: List[Dict], answer: str,
                                            show_metrics: bool = True, show_related_queries: bool = True) -> bool:
        """ë©”íŠ¸ë¦­ í¬í•¨ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ í¬í•¨)"""

        # ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ê´€ë ¨ ê²€ìƒ‰ì–´ í¬í•¨)
        show_details = self.display_search_results(
            query, results, answer, show_related_queries=show_related_queries)

        # ê²€ìƒ‰ í’ˆì§ˆ ë©”íŠ¸ë¦­ í‘œì‹œ
        if show_metrics:
            self.show_search_metrics(query, results)

        return show_details
