#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í‘œì¤€ í•œì˜í•™ ìš©ì–´ì§‘ ê´€ë¦¬ì - medical_terms_manager.py (ë°ì´í„° ë””ë ‰í† ë¦¬ ë¶„ë¦¬ ë²„ì „)
ëŒ€í•œí•œì˜í•™íšŒ í‘œì¤€í•œì˜í•™ìš©ì–´ì§‘ ê¸°ë°˜ ì§€ëŠ¥í˜• ì¿¼ë¦¬ í™•ì¥ ì‹œìŠ¤í…œ
"""

import json
import pickle
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set, Optional
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings("ignore")


class MedicalTermsManager:
    """í‘œì¤€ í•œì˜í•™ ìš©ì–´ì§‘ ê¸°ë°˜ ê´€ë¦¬ì"""

    def __init__(self,
                 terms_file: str = "/Users/radi/Projects/langchain/hmedicalterms.json",
                 cache_path: str = "/Users/radi/Projects/langchainDATA/RAWDATA/DYBG/cache"):
        """í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.terms_file = Path(terms_file)
        self.cache_path = Path(cache_path)
        self.cache_path.mkdir(parents=True, exist_ok=True)

        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        self.cache_file = self.cache_path / 'medical_terms_index.pkl'

        # ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        self.terms_data = []
        self.search_index = {}
        self.category_index = {}
        self.synonym_index = {}
        self.hierarchical_index = {}

        # ë¡œë”© ì‹œë„
        self._load_or_build_index()

    def _load_or_build_index(self):
        """ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        try:
            if self._should_rebuild_cache():
                print("ğŸ“š í‘œì¤€ìš©ì–´ì§‘ ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
                self._build_index()
                self._save_cache()
                print("âœ… í‘œì¤€ìš©ì–´ì§‘ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            else:
                print("ğŸ“š í‘œì¤€ìš©ì–´ì§‘ ìºì‹œì—ì„œ ë¡œë”© ì¤‘...")
                self._load_cache()
                print("âœ… í‘œì¤€ìš©ì–´ì§‘ ìºì‹œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ í‘œì¤€ìš©ì–´ì§‘ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            print("ğŸ“š ê¸°ë³¸ ì¸ë±ìŠ¤ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
            self._initialize_basic_index()

    def _should_rebuild_cache(self) -> bool:
        """ìºì‹œ ì¬ìƒì„± í•„ìš” ì—¬ë¶€ í™•ì¸"""
        if not self.cache_file.exists():
            return True

        if not self.terms_file.exists():
            print(f"âš ï¸ í‘œì¤€ìš©ì–´ì§‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.terms_file}")
            return False

        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ë¹„êµ
        try:
            cache_mtime = self.cache_file.stat().st_mtime
            terms_mtime = self.terms_file.stat().st_mtime
            return terms_mtime > cache_mtime
        except Exception:
            return True

    def _build_index(self):
        """í‘œì¤€ìš©ì–´ì§‘ ì¸ë±ìŠ¤ ìƒì„±"""
        if not self.terms_file.exists():
            print(f"âš ï¸ í‘œì¤€ìš©ì–´ì§‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.terms_file}")
            self._initialize_basic_index()
            return

        try:
            with open(self.terms_file, 'r', encoding='utf-8') as f:
                self.terms_data = json.load(f)

            print(f"ğŸ“Š {len(self.terms_data)}ê°œ ìš©ì–´ ë¡œë“œ ì™„ë£Œ")

            # ê°ì¢… ì¸ë±ìŠ¤ êµ¬ì¶•
            self._build_search_index()
            self._build_category_index()
            self._build_synonym_index()
            self._build_hierarchical_index()

        except Exception as e:
            print(f"âš ï¸ í‘œì¤€ìš©ì–´ì§‘ íŒŒì‹± ì‹¤íŒ¨: {e}")
            self._initialize_basic_index()

    def _build_search_index(self):
        """ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.search_index = {}

        for term_data in self.terms_data:
            # ê¸°ë³¸ ìš©ì–´ëª…
            term_name = term_data.get('ìš©ì–´ëª…', '')
            if term_name:
                self.search_index[term_name] = term_data

            # í•œìëª…
            hanja_name = term_data.get('ìš©ì–´ëª…_í•œì', '')
            if hanja_name and hanja_name != term_name:
                self.search_index[hanja_name] = term_data

            # ë™ì˜ì–´
            synonyms = term_data.get('ë™ì˜ì–´', [])
            for synonym in synonyms:
                if synonym:
                    self.search_index[synonym] = term_data

            # ê²€ìƒ‰í‚¤ì›Œë“œ
            keywords = term_data.get('ê²€ìƒ‰í‚¤ì›Œë“œ', [])
            for keyword in keywords:
                if keyword and keyword not in self.search_index:
                    self.search_index[keyword] = term_data

    def _build_category_index(self):
        """ë¶„ë¥˜ë³„ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.category_index = defaultdict(list)

        for term_data in self.terms_data:
            category = term_data.get('ë¶„ë¥˜', 'ê¸°íƒ€')
            self.category_index[category].append(term_data)

    def _build_synonym_index(self):
        """ë™ì˜ì–´ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.synonym_index = {}

        for term_data in self.terms_data:
            term_name = term_data.get('ìš©ì–´ëª…', '')
            synonyms = term_data.get('ë™ì˜ì–´', [])

            if term_name and synonyms:
                all_terms = [term_name] + synonyms
                # ê° ìš©ì–´ì— ëŒ€í•´ ë‹¤ë¥¸ ëª¨ë“  ìš©ì–´ë¥¼ ë™ì˜ì–´ë¡œ ë“±ë¡
                for term in all_terms:
                    if term:
                        related = [t for t in all_terms if t != term]
                        self.synonym_index[term] = related

    def _build_hierarchical_index(self):
        """ê³„ì¸µêµ¬ì¡° ì¸ë±ìŠ¤ êµ¬ì¶•"""
        self.hierarchical_index = {}

        for term_data in self.terms_data:
            term_name = term_data.get('ìš©ì–´ëª…', '')
            hierarchy = term_data.get('ê³„ì¸µêµ¬ì¡°', {})

            if term_name and hierarchy:
                self.hierarchical_index[term_name] = {
                    'parents': hierarchy.get('ìƒìœ„ê°œë…', []),
                    'children': hierarchy.get('í•˜ìœ„ê°œë…', [])
                }

    def _save_cache(self):
        """ìºì‹œ ì €ì¥"""
        try:
            cache_data = {
                'terms_data': self.terms_data,
                'search_index': self.search_index,
                'category_index': dict(self.category_index),
                'synonym_index': self.synonym_index,
                'hierarchical_index': self.hierarchical_index,
                'timestamp': self._get_current_timestamp()
            }

            with open(self.cache_file, 'wb') as f:
                pickle.dump(cache_data, f)

        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _load_cache(self):
        """ìºì‹œ ë¡œë“œ"""
        try:
            with open(self.cache_file, 'rb') as f:
                cache_data = pickle.load(f)

            self.terms_data = cache_data.get('terms_data', [])
            self.search_index = cache_data.get('search_index', {})
            self.category_index = cache_data.get('category_index', {})
            self.synonym_index = cache_data.get('synonym_index', {})
            self.hierarchical_index = cache_data.get('hierarchical_index', {})

        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._initialize_basic_index()

    def _initialize_basic_index(self):
        """ê¸°ë³¸ ì¸ë±ìŠ¤ ì´ˆê¸°í™” (í´ë°±)"""
        print("ğŸ“š ê¸°ë³¸ ì¤‘ì˜í•™ ìš©ì–´ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")

        basic_terms = [
            {'ìš©ì–´ëª…': 'í˜ˆí—ˆ', 'ìš©ì–´ëª…_í•œì': 'è¡€è™›', 'ë¶„ë¥˜': 'ë³‘ì¦', 'ë™ì˜ì–´': [
                'í˜ˆë¶€ì¡±'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['í˜ˆí—ˆ', 'í˜ˆë¶€ì¡±', 'è¡€è™›']},
            {'ìš©ì–´ëª…': 'ê¸°í—ˆ', 'ìš©ì–´ëª…_í•œì': 'æ°£è™›', 'ë¶„ë¥˜': 'ë³‘ì¦', 'ë™ì˜ì–´': [
                'ê¸°ë¶€ì¡±'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ê¸°í—ˆ', 'ê¸°ë¶€ì¡±', 'æ°£è™›']},
            {'ìš©ì–´ëª…': 'ìŒí—ˆ', 'ìš©ì–´ëª…_í•œì': 'é™°è™›', 'ë¶„ë¥˜': 'ë³‘ì¦', 'ë™ì˜ì–´': [
                'ìŒë¶€ì¡±'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ìŒí—ˆ', 'ìŒë¶€ì¡±', 'é™°è™›']},
            {'ìš©ì–´ëª…': 'ì–‘í—ˆ', 'ìš©ì–´ëª…_í•œì': 'é™½è™›', 'ë¶„ë¥˜': 'ë³‘ì¦', 'ë™ì˜ì–´': [
                'ì–‘ë¶€ì¡±'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ì–‘í—ˆ', 'ì–‘ë¶€ì¡±', 'é™½è™›']},
            {'ìš©ì–´ëª…': 'ì‚¬ë¬¼íƒ•', 'ìš©ì–´ëª…_í•œì': 'å››ç‰©æ¹¯', 'ë¶„ë¥˜': 'ì²˜ë°©',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ì‚¬ë¬¼íƒ•', 'å››ç‰©æ¹¯']},
            {'ìš©ì–´ëª…': 'ì‚¬êµ°ìíƒ•', 'ìš©ì–´ëª…_í•œì': 'å››å›å­æ¹¯', 'ë¶„ë¥˜': 'ì²˜ë°©',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ì‚¬êµ°ìíƒ•', 'å››å›å­æ¹¯']},
            {'ìš©ì–´ëª…': 'ìœ¡êµ°ìíƒ•', 'ìš©ì–´ëª…_í•œì': 'å…­å›å­æ¹¯', 'ë¶„ë¥˜': 'ì²˜ë°©',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ìœ¡êµ°ìíƒ•', 'å…­å›å­æ¹¯']},
            {'ìš©ì–´ëª…': 'ë³´ì¤‘ìµê¸°íƒ•', 'ìš©ì–´ëª…_í•œì': 'è£œä¸­ç›Šæ°£æ¹¯', 'ë¶„ë¥˜': 'ì²˜ë°©',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë³´ì¤‘ìµê¸°íƒ•', 'è£œä¸­ç›Šæ°£æ¹¯']},
            {'ìš©ì–´ëª…': 'ë‹¹ê·€ë³´í˜ˆíƒ•', 'ìš©ì–´ëª…_í•œì': 'ç•¶æ­¸è£œè¡€æ¹¯', 'ë¶„ë¥˜': 'ì²˜ë°©',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë‹¹ê·€ë³´í˜ˆíƒ•', 'ç•¶æ­¸è£œè¡€æ¹¯']},
            {'ìš©ì–´ëª…': 'ì¸ì‚¼', 'ìš©ì–´ëª…_í•œì': 'äººåƒ', 'ë¶„ë¥˜': 'ì•½ë¬¼', 'ë™ì˜ì–´': [
                'ê³ ë ¤ì‚¼', 'í™ì‚¼'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ì¸ì‚¼', 'äººåƒ', 'ê³ ë ¤ì‚¼', 'í™ì‚¼']},
            {'ìš©ì–´ëª…': 'ë‹¹ê·€', 'ìš©ì–´ëª…_í•œì': 'ç•¶æ­¸', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë‹¹ê·€', 'ç•¶æ­¸']},
            {'ìš©ì–´ëª…': 'ì²œê¶', 'ìš©ì–´ëª…_í•œì': 'å·èŠ', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ì²œê¶', 'å·èŠ']},
            {'ìš©ì–´ëª…': 'ë°±ì‘ì•½', 'ìš©ì–´ëª…_í•œì': 'ç™½èŠè—¥', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': ['ë°±ì‘'], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë°±ì‘ì•½', 'ç™½èŠè—¥', 'ë°±ì‘']},
            {'ìš©ì–´ëª…': 'ìˆ™ì§€í™©', 'ìš©ì–´ëª…_í•œì': 'ç†Ÿåœ°é»ƒ', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ìˆ™ì§€í™©', 'ç†Ÿåœ°é»ƒ']},
            {'ìš©ì–´ëª…': 'í™©ê¸°', 'ìš©ì–´ëª…_í•œì': 'é»ƒèŠª', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['í™©ê¸°', 'é»ƒèŠª']},
            {'ìš©ì–´ëª…': 'ë°±ì¶œ', 'ìš©ì–´ëª…_í•œì': 'ç™½æœ®', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë°±ì¶œ', 'ç™½æœ®']},
            {'ìš©ì–´ëª…': 'ë³µë ¹', 'ìš©ì–´ëª…_í•œì': 'èŒ¯è‹“', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ë³µë ¹', 'èŒ¯è‹“']},
            {'ìš©ì–´ëª…': 'ê°ì´ˆ', 'ìš©ì–´ëª…_í•œì': 'ç”˜è‰', 'ë¶„ë¥˜': 'ì•½ë¬¼',
                'ë™ì˜ì–´': [], 'ê²€ìƒ‰í‚¤ì›Œë“œ': ['ê°ì´ˆ', 'ç”˜è‰']},
        ]

        self.terms_data = basic_terms
        self._build_search_index()
        self._build_category_index()
        self._build_synonym_index()
        self._build_hierarchical_index()

    def _get_current_timestamp(self):
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        return datetime.now().isoformat()

    def expand_query(self, query: str, max_expansions: int = 10) -> List[str]:
        """
        ì§€ëŠ¥í˜• ì¿¼ë¦¬ í™•ì¥
        6ë‹¨ê³„ í™•ì¥ ì „ëµ: ì§ì ‘ë§¤ì¹­ â†’ ë™ì˜ì–´ â†’ ë¶€ë¶„ë§¤ì¹­ â†’ ê³„ì¸µêµ¬ì¡° â†’ ì¹´í…Œê³ ë¦¬ â†’ ê¸°ë³¸ë§¤í•‘
        """
        expansions = set([query])  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ set ì‚¬ìš©

        try:
            # 1ë‹¨ê³„: ì§ì ‘ ë§¤ì¹­
            if query in self.search_index:
                term_data = self.search_index[query]

                # ë™ì˜ì–´ ì¶”ê°€
                synonyms = term_data.get('ë™ì˜ì–´', [])
                for synonym in synonyms[:3]:  # ìƒìœ„ 3ê°œë§Œ
                    if synonym:
                        expansions.add(synonym)

                # í•œì/í•œê¸€ëª… ìƒí˜¸ ì¶”ê°€
                hanja = term_data.get('ìš©ì–´ëª…_í•œì', '')
                hangul = term_data.get('ìš©ì–´ëª…', '')

                if hanja and hanja != query:
                    expansions.add(hanja)
                if hangul and hangul != query:
                    expansions.add(hangul)

                # ê²€ìƒ‰í‚¤ì›Œë“œ ì¶”ê°€
                keywords = term_data.get('ê²€ìƒ‰í‚¤ì›Œë“œ', [])
                for keyword in keywords[:2]:  # ìƒìœ„ 2ê°œë§Œ
                    if keyword and keyword != query:
                        expansions.add(keyword)

            # 2ë‹¨ê³„: ë™ì˜ì–´ ê¸°ë°˜ í™•ì¥
            if query in self.synonym_index:
                related_terms = self.synonym_index[query]
                for term in related_terms[:2]:  # ìƒìœ„ 2ê°œë§Œ
                    if term:
                        expansions.add(term)

            # 3ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
            partial_matches = []
            for term in self.search_index.keys():
                if (query in term or term in query) and term != query:
                    # ê¸¸ì´ ì°¨ì´ê°€ ë„ˆë¬´ í¬ì§€ ì•Šì€ ê²ƒë§Œ
                    if abs(len(term) - len(query)) <= 3:
                        partial_matches.append(term)

            # ë¶€ë¶„ ë§¤ì¹­ ê²°ê³¼ë¥¼ ê´€ë ¨ì„±ìœ¼ë¡œ ì •ë ¬
            partial_matches.sort(key=lambda x: abs(len(x) - len(query)))
            for match in partial_matches[:3]:  # ìƒìœ„ 3ê°œë§Œ
                expansions.add(match)

            # 4ë‹¨ê³„: ê³„ì¸µêµ¬ì¡° ê¸°ë°˜ í™•ì¥
            if query in self.hierarchical_index:
                hierarchy = self.hierarchical_index[query]

                # ìƒìœ„ê°œë… ì¶”ê°€
                parents = hierarchy.get('parents', [])
                for parent in parents[:2]:  # ìƒìœ„ 2ê°œë§Œ
                    if parent:
                        expansions.add(parent)

                # í•˜ìœ„ê°œë… ì¶”ê°€ (1ê°œë§Œ)
                children = hierarchy.get('children', [])
                if children:
                    expansions.add(children[0])

            # 5ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í™•ì¥
            query_category = None
            if query in self.search_index:
                query_category = self.search_index[query].get('ë¶„ë¥˜')

                if query_category and query_category in self.category_index:
                    category_terms = self.category_index[query_category]

                    # ê°™ì€ ì¹´í…Œê³ ë¦¬ì˜ ë‹¤ë¥¸ ìš©ì–´ ì¶”ê°€ (2ê°œë§Œ)
                    added_from_category = 0
                    for term_data in category_terms:
                        if added_from_category >= 2:
                            break

                        term_name = term_data.get('ìš©ì–´ëª…', '')
                        if term_name and term_name != query and term_name not in expansions:
                            expansions.add(term_name)
                            added_from_category += 1

            # 6ë‹¨ê³„: ê¸°ë³¸ ë§¤í•‘ (í•œì˜í•™ ë„ë©”ì¸ ì§€ì‹)
            basic_expansions = self._get_basic_domain_expansions(query)
            for basic_exp in basic_expansions[:2]:  # ìƒìœ„ 2ê°œë§Œ
                expansions.add(basic_exp)

            # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ê¸¸ì´ ì œí•œ
            result_list = list(expansions)

            # í’ˆì§ˆ í•„í„°ë§ (2ê¸€ì ì´ìƒ, ì˜ë¯¸ìˆëŠ” ìš©ì–´)
            filtered_result = []
            for term in result_list:
                if len(term) >= 2 and self._is_meaningful_term(term):
                    filtered_result.append(term)

            # ê¸¸ì´ ì œí•œ
            return filtered_result[:max_expansions]

        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return [query]

    def _get_basic_domain_expansions(self, query: str) -> List[str]:
        """ê¸°ë³¸ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ í™•ì¥"""
        basic_mappings = {
            # í—ˆì¦ ê´€ë ¨
            'è¡€è™›': ['è£œè¡€', 'ç•¶æ­¸', 'å››ç‰©æ¹¯', 'é™°è¡€ä¸è¶³'],
            'æ°£è™›': ['è£œæ°£', 'äººåƒ', 'é»ƒèŠª', 'å››å›å­æ¹¯'],
            'é™°è™›': ['æ»‹é™°', 'è£œé™°', 'å…­å‘³åœ°é»ƒæ¹¯', 'ç”Ÿåœ°é»ƒ'],
            'é™½è™›': ['æº«é™½', 'è£œé™½', 'è…æ°£ä¸¸', 'é™„å­'],

            # ì²˜ë°© ê´€ë ¨
            'å››ç‰©æ¹¯': ['ç•¶æ­¸', 'å·èŠ', 'ç™½èŠ', 'ç†Ÿåœ°é»ƒ', 'è£œè¡€'],
            'å››å›å­æ¹¯': ['äººåƒ', 'ç™½æœ®', 'èŒ¯è‹“', 'ç”˜è‰', 'è£œæ°£'],
            'å…­å›å­æ¹¯': ['å››å›å­æ¹¯', 'é™³çš®', 'åŠå¤', 'åŒ–ç—°'],
            'è£œä¸­ç›Šæ°£æ¹¯': ['é»ƒèŠª', 'äººåƒ', 'ç•¶æ­¸', 'å‡éº»', 'è£œæ°£å‡é™½'],

            # ì•½ë¬¼ ê´€ë ¨
            'äººåƒ': ['è£œæ°£', 'å¤§è£œå…ƒæ°£', 'å¾©è„ˆ', 'ç”Ÿæ´¥'],
            'ç•¶æ­¸': ['è£œè¡€', 'æ´»è¡€', 'èª¿ç¶“', 'å››ç‰©æ¹¯'],
            'é»ƒèŠª': ['è£œæ°£', 'å‡é™½', 'å›ºè¡¨', 'åˆ©æ°´'],

            # ì¦ìƒ ê´€ë ¨
            'å¤±çœ ': ['ä¸å¯', 'å¿ƒç¥ä¸å®‰', 'é¤Šå¿ƒå®‰ç¥'],
            'çœ©æšˆ': ['é ­æšˆ', 'è‚é™½ä¸Šäº¢', 'ç—°æ¿ä¸­é˜»'],
            'å¿ƒæ‚¸': ['é©šæ‚¸', 'å¿ƒç¥ä¸å¯§', 'å¿ƒæ°£ä¸è¶³'],
        }

        return basic_mappings.get(query, [])

    def _is_meaningful_term(self, term: str) -> bool:
        """ì˜ë¯¸ìˆëŠ” ìš©ì–´ì¸ì§€ íŒë‹¨"""
        if len(term) < 2:
            return False

        # ë‹¨ìˆœ ë°˜ë³µ ë¬¸ì ì œì™¸
        if len(set(term)) == 1:
            return False

        # íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° ì œì™¸
        if not any('\u4e00' <= char <= '\u9fff' or char.isalpha() for char in term):
            return False

        return True

    def split_query_intelligently(self, query: str) -> List[str]:
        """ì§€ëŠ¥ì  ì¿¼ë¦¬ ë¶„í• """
        parts = [query]

        try:
            # ê¸¸ì´ë³„ ë¶„í•  ì „ëµ
            if len(query) >= 4:
                # 4ê¸€ì ì´ìƒ: 2ê¸€ìì”© ë¶„í•  + 3ê¸€ìì”© ë¶„í• 
                for i in range(len(query) - 1):
                    if i + 2 <= len(query):
                        part = query[i:i + 2]
                        parts.append(part)

                for i in range(len(query) - 2):
                    if i + 3 <= len(query):
                        part = query[i:i + 3]
                        parts.append(part)

            elif len(query) == 3:
                # 3ê¸€ì: ì• 2ê¸€ì, ë’¤ 2ê¸€ì ì¶”ê°€
                parts.append(query[:2])
                parts.append(query[1:])

            # ì¤‘ë³µ ì œê±° ë° ì˜ë¯¸ìˆëŠ” ë¶€ë¶„ë§Œ ì„ íƒ
            unique_parts = []
            for part in parts:
                if part not in unique_parts and self._is_meaningful_term(part):
                    unique_parts.append(part)

            return unique_parts

        except Exception as e:
            print(f"âš ï¸ ì¿¼ë¦¬ ë¶„í•  ì‹¤íŒ¨: {e}")
            return [query]

    def get_related_terms(self, query: str) -> List[str]:
        """ê´€ë ¨ ìš©ì–´ ë°˜í™˜"""
        related = []

        try:
            if query in self.search_index:
                term_data = self.search_index[query]

                # ë™ì˜ì–´ ì¶”ê°€
                synonyms = term_data.get('ë™ì˜ì–´', [])
                related.extend(synonyms[:3])

                # ê°™ì€ ë¶„ë¥˜ì˜ ë‹¤ë¥¸ ìš©ì–´ë“¤
                category = term_data.get('ë¶„ë¥˜', '')
                if category in self.category_index:
                    category_terms = self.category_index[category]
                    for cat_term in category_terms[:5]:
                        term_name = cat_term.get('ìš©ì–´ëª…', '')
                        if term_name and term_name != query and term_name not in related:
                            related.append(term_name)

                # ê³„ì¸µêµ¬ì¡° ê´€ë ¨ ìš©ì–´
                if query in self.hierarchical_index:
                    hierarchy = self.hierarchical_index[query]
                    parents = hierarchy.get('parents', [])
                    children = hierarchy.get('children', [])

                    related.extend(parents[:2])
                    related.extend(children[:2])

            # ê¸°ë³¸ ë„ë©”ì¸ í™•ì¥ë„ ì¶”ê°€
            domain_related = self._get_basic_domain_expansions(query)
            related.extend(domain_related[:3])

            # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
            unique_related = []
            for term in related:
                if term and term not in unique_related and term != query:
                    unique_related.append(term)

            return unique_related[:10]

        except Exception as e:
            print(f"âš ï¸ ê´€ë ¨ ìš©ì–´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def get_term_info(self, term: str) -> Optional[Dict]:
        """íŠ¹ì • ìš©ì–´ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        try:
            if term in self.search_index:
                return self.search_index[term]
            return None
        except Exception as e:
            print(f"âš ï¸ ìš©ì–´ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def search_by_category(self, category: str, limit: int = 20) -> List[Dict]:
        """ë¶„ë¥˜ë³„ ìš©ì–´ ê²€ìƒ‰"""
        try:
            if category in self.category_index:
                terms = self.category_index[category]
                return terms[:limit]
            return []
        except Exception as e:
            print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def fuzzy_search(self, query: str, threshold: float = 0.6) -> List[str]:
        """ìœ ì‚¬ ìš©ì–´ ê²€ìƒ‰"""
        matches = []

        try:
            for term in self.search_index.keys():
                if term == query:
                    continue

                # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ë¬¸ì ê²¹ì¹¨ ë¹„ìœ¨)
                common_chars = set(query) & set(term)
                similarity = len(common_chars) / max(len(query), len(term))

                if similarity >= threshold:
                    matches.append((term, similarity))

            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            matches.sort(key=lambda x: x[1], reverse=True)
            return [match[0] for match in matches[:10]]

        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def get_statistics(self) -> Dict:
        """ìš©ì–´ì§‘ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            stats = {
                'total_terms': len(self.terms_data),
                'search_index_size': len(self.search_index),
                'categories': len(self.category_index),
                'terms_with_synonyms': len(self.synonym_index),
                'terms_with_hierarchy': len(self.hierarchical_index)
            }

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            category_distribution = {}
            for category, terms in self.category_index.items():
                category_distribution[category] = len(terms)

            stats['category_distribution'] = category_distribution
            return stats

        except Exception as e:
            print(f"âš ï¸ í†µê³„ ì •ë³´ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}

    def clear_cache(self):
        """ìºì‹œ íŒŒì¼ ì‚­ì œ"""
        try:
            if self.cache_file.exists():
                self.cache_file.unlink()
                print("ğŸ—‘ï¸ í‘œì¤€ìš©ì–´ì§‘ ìºì‹œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print("ğŸ’­ ì‚­ì œí•  ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")

    def rebuild_index(self):
        """ê°•ì œë¡œ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
        try:
            print("ğŸ”„ í‘œì¤€ìš©ì–´ì§‘ ì¸ë±ìŠ¤ ê°•ì œ ì¬êµ¬ì¶• ì¤‘...")
            self._build_index()
            self._save_cache()
            print("âœ… ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• ì‹¤íŒ¨: {e}")


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_terms_manager() -> MedicalTermsManager:
    """í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return MedicalTermsManager()


def test_terms_manager():
    """í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜"""
    print("ğŸ§ª í‘œì¤€ìš©ì–´ì§‘ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸")

    manager = MedicalTermsManager()

    # í†µê³„ ì •ë³´ ì¶œë ¥
    stats = manager.get_statistics()
    print(f"ğŸ“Š ì´ ìš©ì–´ ìˆ˜: {stats.get('total_terms', 0):,}ê°œ")
    print(f"ğŸ” ê²€ìƒ‰ ì¸ë±ìŠ¤: {stats.get('search_index_size', 0):,}ê°œ")
    print(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {stats.get('categories', 0)}ê°œ")

    # ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸
    test_queries = ['è¡€è™›', 'å››å›å­æ¹¯', 'äººåƒ', 'é™°è™›']

    for query in test_queries:
        print(f"\nğŸ” '{query}' ì¿¼ë¦¬ í™•ì¥ í…ŒìŠ¤íŠ¸:")
        expansions = manager.expand_query(query)
        print(f"   í™•ì¥ ê²°ê³¼: {expansions}")

        related = manager.get_related_terms(query)
        if related:
            print(f"   ê´€ë ¨ ìš©ì–´: {related[:5]}")


if __name__ == "__main__":
    test_terms_manager()
